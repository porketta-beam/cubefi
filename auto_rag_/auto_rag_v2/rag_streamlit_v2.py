import streamlit as st
import os
import shutil
from pathlib import Path
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import koreanize_matplotlib
from datasets import Dataset

# Langchain imports
from langchain_community.document_loaders import TextLoader, PyPDFLoader
from langchain_openai.embeddings import OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import ChatOpenAI
from langchain.chains import create_retrieval_chain
from langchain_core.prompts import ChatPromptTemplate

# RAGAS imports
from ragas.metrics import (
    faithfulness,
    answer_relevancy,
    context_precision,
    context_recall
)
from ragas.evaluation import evaluate

# Load environment variables
from dotenv import load_dotenv
import os

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ì˜ .env íŒŒì¼ ê²½ë¡œ ì„¤ì •
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
env_path = os.path.join(project_root, '.env')

load_dotenv(dotenv_path=env_path, override=True)

# LangSmith ì„¤ì • í™•ì¸
print(f"LangSmith API Key loaded: {'Yes' if os.getenv('LANGSMITH_API_KEY') else 'No'}")
print(f"LangSmith Project: {os.getenv('LANGSMITH_PROJECT', 'Not set')}")

# LangSmith ê°•ì œ ì´ˆê¸°í™” (Streamlit í™˜ê²½ì—ì„œ í•„ìš”)
if os.getenv('LANGSMITH_API_KEY'):
    from langsmith import Client
    try:
        langsmith_client = Client()
        print(f"LangSmith client initialized successfully")
    except Exception as e:
        print(f"LangSmith client initialization failed: {e}")

from typing import List, Dict, Any
from mod import (
    ChromaDBManager,
    RawDataSyncManager,
    RAGSystemManager,
    QuestionGenerationManager,
    EvaluationManager,
    ChatInterfaceManager,
    VisualizationUtils,
    WorkflowStatusManager,
    ElasticsearchManager,
    HybridSearchManager
)
# LangChain ë„¤ì´í‹°ë¸Œ ìë™ ì¶”ì  ì‚¬ìš©

# Matplotlib í•œê¸€ ë° ìŒìˆ˜ ê¹¨ì§ ë°©ì§€ ì„¤ì •
plt.rcParams['axes.unicode_minus'] = False

# Set page config
st.set_page_config(
    page_title="RAG System with RAGAS Evaluation",
    page_icon="ğŸ¤–",
    layout="wide"
)

# Document loading and splitting function
def load_and_split_document(file_path: str, chunk_size: int = 500, chunk_overlap: int = 100) -> list:
    """íŒŒì¼ì„ ë¡œë“œí•˜ê³  ì²­í¬ë¡œ ë¶„í• """
    try:
        file_extension = Path(file_path).suffix.lower()
        
        # íŒŒì¼ íƒ€ì…ì— ë”°ë¥¸ ë¡œë” ì„ íƒ
        if file_extension == '.txt':
            loader = TextLoader(file_path, encoding='utf-8')
        elif file_extension == '.pdf':
            loader = PyPDFLoader(file_path)
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_extension}")
        
        # í…ìŠ¤íŠ¸ ë¶„í• ê¸° ì„¤ì •
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap
        )
        
        # ë¬¸ì„œ ë¡œë“œ ë° ë¶„í• 
        documents = loader.load_and_split(text_splitter)
        
        return documents
        
    except Exception as e:
        st.error(f"íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ ({os.path.basename(file_path)}): {str(e)}")
        return []


# Initialize session state
if 'db' not in st.session_state:
    st.session_state.db = None
if 'documents' not in st.session_state:
    st.session_state.documents = None
if 'evaluation_results' not in st.session_state:
    st.session_state.evaluation_results = None
if 'generated_questions' not in st.session_state:
    st.session_state.generated_questions = []
if 'edited_questions' not in st.session_state:
    st.session_state.edited_questions = []
if 'chat_messages' not in st.session_state:
    st.session_state.chat_messages = []
if 'db_manager' not in st.session_state:
    st.session_state.db_manager = ChromaDBManager()
if 'sync_manager' not in st.session_state:
    st.session_state.sync_manager = RawDataSyncManager()
if 'rag_manager' not in st.session_state:
    st.session_state.rag_manager = RAGSystemManager()
if 'question_manager' not in st.session_state:
    st.session_state.question_manager = QuestionGenerationManager()
if 'evaluation_manager' not in st.session_state:
    st.session_state.evaluation_manager = EvaluationManager()
if 'chat_interface' not in st.session_state:
    st.session_state.chat_interface = ChatInterfaceManager()
if 'workflow_manager' not in st.session_state:
    st.session_state.workflow_manager = WorkflowStatusManager()
if 'elasticsearch_manager' not in st.session_state:
    st.session_state.elasticsearch_manager = ElasticsearchManager()
if 'hybrid_search_manager' not in st.session_state:
    st.session_state.hybrid_search_manager = None  # Initialized later when both managers are ready

st.title("ğŸ¤– RAG ì‹œìŠ¤í…œ ë° RAGAS í‰ê°€")
st.markdown("---")

# íƒ­ ì´ë¦„
tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs(["ğŸ“ Raw Data ê´€ë¦¬", "ğŸ”„ Raw Data ë™ê¸°í™”", "ğŸ” í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰", "ğŸ’¬ RAG í…ŒìŠ¤íŠ¸", "ğŸ“ ì§ˆë¬¸ ìƒì„±í•˜ê¸°", "ğŸ” RAG í‰ê°€í•˜ê¸°"])

with tab1:
    st.header("ğŸ“ Raw Data ê´€ë¦¬")
    
    # Raw Data í´ë” ê´€ë¦¬ ê¸°ëŠ¥
    sync_manager = st.session_state.sync_manager
    raw_data_path = sync_manager.raw_data_path
    
    st.subheader("ğŸ“‚ í´ë” ì •ë³´")
    st.info(f"**Raw Data í´ë” ê²½ë¡œ:** {raw_data_path}")
    
    # í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
    if not os.path.exists(raw_data_path):
        os.makedirs(raw_data_path)
        st.success("âœ… Raw Data í´ë”ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    def get_file_list():
        """raw_data í´ë”ì˜ íŒŒì¼ ëª©ë¡ì„ ê°€ì ¸ì˜´"""
        if not os.path.exists(raw_data_path):
            return []
        
        files = []
        for filename in os.listdir(raw_data_path):
            file_path = os.path.join(raw_data_path, filename)
            if os.path.isfile(file_path):
                file_stat = os.stat(file_path)
                file_size_mb = file_stat.st_size / (1024 * 1024)
                files.append({
                    'filename': filename,
                    'size_mb': file_size_mb,
                    'modified_time': file_stat.st_mtime,
                    'file_path': file_path
                })
        return sorted(files, key=lambda x: x['modified_time'], reverse=True)
    
    # íŒŒì¼ ëª©ë¡ í‘œì‹œ
    st.subheader("ğŸ“‹ íŒŒì¼ ëª©ë¡")
    
    files = get_file_list()
    
    if files:
        # íŒŒì¼ ì •ë³´ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
        import datetime
        file_data = []
        for file_info in files:
            modified_time = datetime.datetime.fromtimestamp(file_info['modified_time'])
            file_data.append({
                'íŒŒì¼ëª…': file_info['filename'],
                'í¬ê¸° (MB)': f"{file_info['size_mb']:.2f}",
                'ìˆ˜ì •ì¼': modified_time.strftime('%Y-%m-%d %H:%M:%S'),
                'í˜•ì‹': os.path.splitext(file_info['filename'])[1].upper()
            })
        
        df = pd.DataFrame(file_data)
        st.dataframe(df, use_container_width=True)
        
        # ì „ì²´ í†µê³„
        total_files = len(files)
        total_size = sum(f['size_mb'] for f in files)
        st.info(f"ğŸ“Š **ì´ {total_files}ê°œ íŒŒì¼, ì „ì²´ í¬ê¸°: {total_size:.2f} MB**")
        
    else:
        st.warning("ğŸ“ í´ë”ì— íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    st.markdown("---")
    
    # íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜
    st.subheader("ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**ë‹¨ì¼ íŒŒì¼ ì—…ë¡œë“œ**")
        uploaded_file = st.file_uploader(
            "íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”",
            type=['txt', 'pdf'],
            key="single_upload"
        )
        
        if uploaded_file is not None:
            if st.button("ğŸ’¾ ë‹¨ì¼ íŒŒì¼ ì €ì¥", key="save_single"):
                try:
                    file_path = os.path.join(raw_data_path, uploaded_file.name)
                    with open(file_path, "wb") as f:
                        f.write(uploaded_file.getbuffer())
                    st.success(f"âœ… '{uploaded_file.name}' íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    st.rerun()
                except Exception as e:
                    st.error(f"âŒ íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    with col2:
        st.write("**ë‹¤ì¤‘ íŒŒì¼ ì—…ë¡œë“œ**")
        uploaded_files = st.file_uploader(
            "ì—¬ëŸ¬ íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”",
            type=['txt', 'pdf'],
            accept_multiple_files=True,
            key="multiple_upload"
        )
        
        if uploaded_files:
            if st.button("ğŸ’¾ ë‹¤ì¤‘ íŒŒì¼ ì €ì¥", key="save_multiple"):
                try:
                    saved_count = 0
                    for uploaded_file in uploaded_files:
                        file_path = os.path.join(raw_data_path, uploaded_file.name)
                        with open(file_path, "wb") as f:
                            f.write(uploaded_file.getbuffer())
                        saved_count += 1
                    
                    st.success(f"âœ… {saved_count}ê°œ íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    st.rerun()
                except Exception as e:
                    st.error(f"âŒ íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    st.markdown("---")
    
    # íŒŒì¼ ì‚­ì œ ì„¹ì…˜
    st.subheader("ğŸ—‘ï¸ íŒŒì¼ ì‚­ì œ")
    
    if files:
        st.write("ì‚­ì œí•  íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”:")
        
        # íŒŒì¼ ì„ íƒ ì²´í¬ë°•ìŠ¤
        selected_files = []
        for file_info in files:
            if st.checkbox(
                f"{file_info['filename']} ({file_info['size_mb']:.2f} MB)",
                key=f"delete_{file_info['filename']}"
            ):
                selected_files.append(file_info)
        
        if selected_files:
            st.warning(f"âš ï¸ **{len(selected_files)}ê°œ íŒŒì¼ì´ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤.**")
            
            # ì„ íƒëœ íŒŒì¼ ëª©ë¡ í‘œì‹œ
            st.write("**ì„ íƒëœ íŒŒì¼:**")
            for file_info in selected_files:
                st.write(f"- {file_info['filename']} ({file_info['size_mb']:.2f} MB)")
            
            # ì‚­ì œ í™•ì¸ ë° ì‹¤í–‰
            if st.button("ğŸ—‘ï¸ ì„ íƒëœ íŒŒì¼ ì‚­ì œ", type="secondary"):
                try:
                    deleted_count = 0
                    for file_info in selected_files:
                        os.remove(file_info['file_path'])
                        deleted_count += 1
                    
                    st.success(f"âœ… {deleted_count}ê°œ íŒŒì¼ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤!")
                    st.rerun()
                except Exception as e:
                    st.error(f"âŒ íŒŒì¼ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        else:
            st.info("ğŸ“ ì‚­ì œí•  íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
    else:
        st.info("ğŸ“ ì‚­ì œí•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    st.markdown("---")
    
    # ì‚¬ìš©ë²• ì•ˆë‚´
    st.subheader("ğŸ’¡ ì‚¬ìš©ë²•")
    st.info("""
    **ì§€ì› íŒŒì¼ í˜•ì‹:**
    - ğŸ“„ í…ìŠ¤íŠ¸ íŒŒì¼ (.txt)
    - ğŸ“• PDF íŒŒì¼ (.pdf)
    
    **íŒŒì¼ í¬ê¸° ì œí•œ:**
    - ë‹¨ì¼ íŒŒì¼: ìµœëŒ€ 200MB
    - ì „ì²´ í´ë”: ìµœëŒ€ 1GB
    
    **ì£¼ì˜ì‚¬í•­:**
    - íŒŒì¼ ì‚­ì œëŠ” ë˜ëŒë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤
    - íŒŒì¼ëª…ì— íŠ¹ìˆ˜ë¬¸ì ì‚¬ìš©ì„ í”¼í•´ì£¼ì„¸ìš”
    """)

with tab2:
    st.header("Raw Data ë™ê¸°í™”")
    
    # ë™ê¸°í™” ê´€ë¦¬ì ê°€ì ¸ì˜¤ê¸°
    sync_manager = st.session_state.sync_manager
    db_manager = st.session_state.db_manager
    
    # VectorDB ìƒíƒœ í‘œì‹œ
    db_status = db_manager.get_status()
    
    st.subheader("ğŸ“ VectorDB ìƒíƒœ")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if db_status["db_exists"]:
            st.success("âœ… VectorDB ì¡´ì¬")
            st.metric("ì €ì¥ëœ ë¬¸ì„œ ìˆ˜", db_status["document_count"])
        else:
            st.warning("âŒ VectorDB ì—†ìŒ")
            st.metric("ì €ì¥ëœ ë¬¸ì„œ ìˆ˜", 0)
    
    with col2:
        st.info(f"ğŸ“‚ ì €ì¥ ê²½ë¡œ: {db_status['db_path']}")
        st.info(f"ğŸ”¤ ì„ë² ë”© ëª¨ë¸: {db_status['embedding_model']}")
    
    with col3:
        if db_status["db_exists"]:
            if st.button("ğŸ—‘ï¸ VectorDB ì‚­ì œ", type="secondary"):
                try:
                    with st.spinner("VectorDBë¥¼ ì‚­ì œí•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                        # ì„¸ì…˜ ë°ì´í„° ì´ˆê¸°í™”
                        st.session_state.documents = None
                        st.session_state.generated_questions = []
                        st.session_state.edited_questions = []
                        st.session_state.evaluation_results = None
                        st.session_state.db = None
                        
                        # DB ì‚­ì œ
                        success = db_manager.delete_db()
                        
                        if success:
                            st.success("âœ… VectorDBê°€ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤!")
                        else:
                            st.error("âŒ VectorDB ì‚­ì œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                            
                        st.rerun()
                        
                except Exception as e:
                    st.error(f"VectorDB ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    st.markdown("---")
    
    st.subheader("ğŸ“Š ë™ê¸°í™” ìƒíƒœ")
    
    # ë™ê¸°í™” ìƒíƒœ í™•ì¸
    if st.button("ğŸ”„ ë™ê¸°í™” ìƒíƒœ í™•ì¸"):
        sync_status = sync_manager.compare_with_db(db_manager)
        raw_files_info = sync_manager.scan_raw_data_folder()
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("ğŸ“ **Raw Data í´ë” ìƒíƒœ**")
            st.write(f"- ê²½ë¡œ: {sync_manager.raw_data_path}")
            st.write(f"- ì´ íŒŒì¼ ìˆ˜: {len(raw_files_info)}ê°œ")
            
            if raw_files_info:
                total_size_mb = sum(info['size_mb'] for info in raw_files_info)
                st.write(f"- ì´ íŒŒì¼ í¬ê¸°: {total_size_mb:.2f} MB")
                
                # íŒŒì¼ ëª©ë¡ í‘œì‹œ
                st.write("**íŒŒì¼ ëª©ë¡:**")
                for file_info in raw_files_info:
                    st.write(f"  - {file_info['filename']} ({file_info['size_mb']:.2f} MB)")
        
        with col2:
            st.write("ğŸ—„ï¸ **ChromaDB ìƒíƒœ**")
            db_status = db_manager.get_status()
            st.write(f"- DB ì¡´ì¬: {'âœ…' if db_status['db_exists'] else 'âŒ'}")
            st.write(f"- ì´ ë¬¸ì„œ ìˆ˜: {db_status['document_count']}ê°œ")
            st.write(f"- ì €ì¥ëœ íŒŒì¼ ìˆ˜: {len(sync_status['all_db_files'])}ê°œ")
            
            # ë™ê¸°í™” ìƒíƒœ
            st.write("**ë™ê¸°í™” ìƒíƒœ:**")
            st.write(f"- ìƒˆ íŒŒì¼: {len(sync_status['new_files'])}ê°œ")
            st.write(f"- ë™ê¸°í™”ë¨: {len(sync_status['existing_files'])}ê°œ")
            st.write(f"- ê³ ì•„ íŒŒì¼: {len(sync_status['orphaned_files'])}ê°œ")
            
            # ìƒì„¸ ì •ë³´
            if sync_status['new_files']:
                st.write("**ì¶”ê°€í•  ìƒˆ íŒŒì¼:**")
                for filename in sync_status['new_files']:
                    st.write(f"  - {filename}")
            
            if sync_status['orphaned_files']:
                st.write("**ê³ ì•„ íŒŒì¼ (raw_dataì— ì—†ìŒ):**")
                for filename in sync_status['orphaned_files']:
                    st.write(f"  - {filename}")
    
    st.markdown("---")
    
    # ë™ê¸°í™” ì„¤ì •
    st.subheader("âš™ï¸ ë™ê¸°í™” ì„¤ì •")
    
    col1, col2 = st.columns(2)
    
    with col1:
        sync_chunk_size = st.slider("ì²­í¬ í¬ê¸°", min_value=100, max_value=2000, value=500, step=50, key="sync_chunk_size")
    
    with col2:
        sync_chunk_overlap = st.slider("ì²­í¬ ì¤‘ì²©", min_value=0, max_value=500, value=100, step=25, key="sync_chunk_overlap")
    
    # Elasticsearch ì—°ë™ ì˜µì…˜
    st.subheader("ğŸ” Elasticsearch ì—°ë™")
    
    col1, col2 = st.columns(2)
    
    with col1:
        enable_elasticsearch = st.checkbox(
            "Elasticsearch ë³‘ë ¬ ì¸ë±ì‹± í™œì„±í™”", 
            value=False,
            help="ChromaDBì™€ í•¨ê»˜ Elasticsearchì—ë„ ë™ì‹œì— ì¸ë±ì‹±í•©ë‹ˆë‹¤. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì„ ìœ„í•´ í•„ìš”í•©ë‹ˆë‹¤."
        )
    
    with col2:
        if enable_elasticsearch:
            elasticsearch_manager = st.session_state.elasticsearch_manager
            es_connection_ok = elasticsearch_manager.check_connection()
            
            if es_connection_ok:
                st.success("âœ… Elasticsearch ì—°ê²° í™•ì¸")
                doc_count = elasticsearch_manager.get_document_count()
                st.info(f"í˜„ì¬ ë¬¸ì„œ ìˆ˜: {doc_count}")
            else:
                st.warning("âš ï¸ Elasticsearch ì—°ê²° ì‹¤íŒ¨")
                st.info("Dockerë¡œ Elasticsearchë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”")
    
    # ë™ê¸°í™” ì‹¤í–‰
    if st.button("ğŸš€ ë™ê¸°í™” ì‹¤í–‰", type="primary"):
        # Update workflow status to in_progress
        workflow_manager = st.session_state.workflow_manager
        workflow_manager.update_step_status("embedding", "in_progress", 0)
        
        with st.spinner("ë™ê¸°í™”ë¥¼ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤..."):
            # Check sync status first
            sync_status = sync_manager.compare_with_db(db_manager)
            new_files_count = len(sync_status['new_files'])
            
            workflow_manager.update_step_status("embedding", "in_progress", 25, {
                "new_files": new_files_count,
                "document_count": db_manager.get_document_count()
            })
            
            # Elasticsearch ë§¤ë‹ˆì € ì¤€ë¹„
            elasticsearch_mgr = None
            if enable_elasticsearch:
                elasticsearch_mgr = st.session_state.elasticsearch_manager
                if not elasticsearch_mgr.check_connection():
                    st.warning("Elasticsearch ì—°ê²°ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ChromaDBë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                    elasticsearch_mgr = None
            
            success = sync_manager.sync_with_db(
                db_manager=db_manager,
                chunk_size=sync_chunk_size,
                chunk_overlap=sync_chunk_overlap,
                elasticsearch_manager=elasticsearch_mgr
            )
            
            if success:
                # ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
                st.session_state.db = db_manager.db
                final_doc_count = db_manager.get_document_count()
                
                # Update workflow status to completed
                workflow_manager.update_step_status("embedding", "completed", 100, {
                    "document_count": final_doc_count,
                    "new_files": new_files_count
                })
                
                st.rerun()
            else:
                # Update workflow status to error
                workflow_manager.update_step_status("embedding", "error", 0, error="ë™ê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                st.error("ë™ê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    
    # ì¶”ê°€ ì •ë³´
    st.info("ğŸ’¡ **ì‚¬ìš©ë²•:** raw_data í´ë”ì— .txt ë˜ëŠ” .pdf íŒŒì¼ì„ ì¶”ê°€í•œ í›„ ë™ê¸°í™”ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
    st.info(f"ğŸ“‚ **Raw Data í´ë” ê²½ë¡œ:** {sync_manager.raw_data_path}")
    
    # ê¸°ì¡´ DB ê´€ë¦¬ ê¸°ëŠ¥
    if db_status["db_exists"]:
        st.markdown("---")
        st.subheader("ğŸ“‹ VectorDB ê´€ë¦¬")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if not db_status["db_loaded"]:
                if st.button("ğŸ“¥ ê¸°ì¡´ VectorDB ë¡œë“œ", type="primary"):
                    try:
                        with st.spinner("ê¸°ì¡´ VectorDBë¥¼ ë¡œë“œ ì¤‘ì…ë‹ˆë‹¤..."):
                            success = db_manager.load_existing_db()
                            
                            if success:
                                st.session_state.db = db_manager.db
                                st.success(f"ê¸°ì¡´ VectorDBë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤! (ë¬¸ì„œ ìˆ˜: {db_status['document_count']})")
                                st.rerun()
                            
                    except Exception as e:
                        st.error(f"VectorDB ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        
        with col2:
            if st.button("ğŸ“‹ ì €ì¥ëœ ë¬¸ì„œ ëª©ë¡ ë³´ê¸°"):
                with st.spinner("ë¬¸ì„œ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                    files_in_db = db_manager.get_files_in_db()
                    
                    if files_in_db:
                        st.subheader("ğŸ“š ì €ì¥ëœ íŒŒì¼ ëª©ë¡")
                        st.write(f"ì´ {len(files_in_db)}ê°œì˜ íŒŒì¼ì´ ì €ì¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
                        st.write(f"ì´ ë¬¸ì„œ ì²­í¬ ìˆ˜: {db_status['document_count']}ê°œ")
                        
                        # íŒŒì¼ ëª©ë¡ í‘œì‹œ
                        for i, filename in enumerate(files_in_db, 1):
                            st.write(f"{i}. {filename}")
                    else:
                        st.warning("ì €ì¥ëœ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

with tab3:
    st.header("ğŸ” í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰")
    
    # Initialize hybrid search manager
    db_manager = st.session_state.db_manager
    elasticsearch_manager = st.session_state.elasticsearch_manager
    
    if st.session_state.hybrid_search_manager is None and st.session_state.db is not None:
        st.session_state.hybrid_search_manager = HybridSearchManager(
            chroma_manager=db_manager,
            elasticsearch_manager=elasticsearch_manager
        )
    
    hybrid_search_manager = st.session_state.hybrid_search_manager
    
    if st.session_state.db is None:
        st.warning("ë¨¼ì € 'Raw Data ë™ê¸°í™”' íƒ­ì—ì„œ ë¬¸ì„œë¥¼ ë™ê¸°í™”í•´ ì£¼ì„¸ìš”.")
    else:
        # Search system status
        st.subheader("ğŸ” ê²€ìƒ‰ ì‹œìŠ¤í…œ ìƒíƒœ")
        
        if hybrid_search_manager:
            search_status = hybrid_search_manager.get_search_status()
            availability = search_status['availability']
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("Vector ê²€ìƒ‰", "âœ… ì‚¬ìš© ê°€ëŠ¥" if availability['vector_search'] else "âŒ ì‚¬ìš© ë¶ˆê°€")
                if availability['vector_search']:
                    chroma_status = search_status['chromadb_status']
                    st.info(f"ë¬¸ì„œ ìˆ˜: {chroma_status['document_count']}")
            
            with col2:
                st.metric("BM25 ê²€ìƒ‰", "âœ… ì‚¬ìš© ê°€ëŠ¥" if availability['bm25_search'] else "âŒ ì‚¬ìš© ë¶ˆê°€")
                if availability['bm25_search']:
                    es_status = search_status['elasticsearch_status']
                    st.info(f"ë¬¸ì„œ ìˆ˜: {es_status['document_count']}")
                else:
                    st.warning("Elasticsearch ì—°ê²° í•„ìš”")
            
            with col3:
                st.metric("í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰", "âœ… ì‚¬ìš© ê°€ëŠ¥" if availability['hybrid_search'] else "âŒ ì‚¬ìš© ë¶ˆê°€")
                if availability['hybrid_search']:
                    st.success("BM25 + Vector ìœµí•© ê²€ìƒ‰")
                else:
                    st.warning("ChromaDBì™€ Elasticsearch ëª¨ë‘ í•„ìš”")
        
        st.markdown("---")
        
        # Search configuration
        st.subheader("âš™ï¸ ê²€ìƒ‰ ì„¤ì •")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            search_type = st.selectbox(
                "ê²€ìƒ‰ ë°©ë²•",
                ["hybrid", "vector", "bm25"],
                index=0,
                help="hybrid: BM25+Vector ìœµí•©, vector: ì˜ë¯¸ ê²€ìƒ‰, bm25: í‚¤ì›Œë“œ ê²€ìƒ‰"
            )
        
        with col2:
            search_k = st.slider("ê²€ìƒ‰ ê²°ê³¼ ìˆ˜", min_value=1, max_value=20, value=5)
        
        with col3:
            if search_type == "hybrid":
                rrf_k = st.slider("RRF ìƒìˆ˜", min_value=10, max_value=100, value=60, 
                                help="Reciprocal Rank Fusion ìƒìˆ˜ (ë‚®ì„ìˆ˜ë¡ ìƒìœ„ ê²°ê³¼ ê°•ì¡°)")
        
        # Search interface
        st.subheader("ğŸ” ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
        
        search_query = st.text_input("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”:", placeholder="ì˜ˆ: ë²•ì¸ì„¸ìœ¨ì´ ì–¼ë§ˆì¸ê°€ìš”?")
        
        if st.button("ğŸ” ê²€ìƒ‰ ì‹¤í–‰", type="primary") and search_query:
            if hybrid_search_manager:
                try:
                    with st.spinner("ê²€ìƒ‰ ì¤‘..."):
                        # Execute search
                        if search_type == "hybrid":
                            results, search_info = hybrid_search_manager.search(
                                search_query, search_type, search_k, rrf_k
                            )
                        else:
                            results, search_info = hybrid_search_manager.search(
                                search_query, search_type, search_k
                            )
                        
                        # Display search info
                        st.subheader("ğŸ“Š ê²€ìƒ‰ ê²°ê³¼ ì •ë³´")
                        info_col1, info_col2 = st.columns(2)
                        
                        with info_col1:
                            st.metric("ê²€ìƒ‰ ë°©ë²•", search_info.get('search_type', search_type))
                            st.metric("ì´ ê²°ê³¼ ìˆ˜", len(results))
                        
                        with info_col2:
                            if 'search_methods_used' in search_info:
                                methods = ", ".join(search_info['search_methods_used'])
                                st.metric("ì‚¬ìš©ëœ ë°©ë²•", methods)
                            if search_type == "hybrid" and 'rrf_k' in search_info:
                                st.metric("RRF ìƒìˆ˜", search_info['rrf_k'])
                        
                        # Display results
                        if results:
                            st.subheader("ğŸ¯ ê²€ìƒ‰ ê²°ê³¼")
                            
                            for i, result in enumerate(results):
                                with st.expander(f"ê²°ê³¼ {i+1}: {result['filename']} (ì ìˆ˜: {result['score']:.3f})"):
                                    # Result metadata
                                    col1, col2 = st.columns(2)
                                    with col1:
                                        st.write(f"**íŒŒì¼ëª…:** {result['filename']}")
                                        st.write(f"**ê²€ìƒ‰ ìœ í˜•:** {result['search_type']}")
                                    with col2:
                                        st.write(f"**ì ìˆ˜:** {result['score']:.3f}")
                                        if 'hybrid_rank' in result:
                                            st.write(f"**í•˜ì´ë¸Œë¦¬ë“œ ìˆœìœ„:** {result['hybrid_rank']}")
                                    
                                    # Show ranking details for hybrid search
                                    if search_type == "hybrid" and 'rrf_score' in result:
                                        st.write("**ìƒì„¸ ì ìˆ˜:**")
                                        score_col1, score_col2, score_col3 = st.columns(3)
                                        with score_col1:
                                            if result.get('vector_rank'):
                                                st.write(f"Vector ìˆœìœ„: {result['vector_rank']}")
                                        with score_col2:
                                            if result.get('bm25_rank'):
                                                st.write(f"BM25 ìˆœìœ„: {result['bm25_rank']}")
                                        with score_col3:
                                            st.write(f"RRF ì ìˆ˜: {result['rrf_score']:.4f}")
                                    
                                    # Content
                                    st.write("**ë‚´ìš©:**")
                                    st.write(result['content'])
                        else:
                            st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                            
                except Exception as e:
                    st.error(f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            else:
                st.error("í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ë§¤ë‹ˆì €ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # Search comparison tool
        if hybrid_search_manager and search_query:
            st.markdown("---")
            st.subheader("ğŸ“Š ê²€ìƒ‰ ë°©ë²• ë¹„êµ")
            
            if st.button("ğŸ” ëª¨ë“  ê²€ìƒ‰ ë°©ë²• ë¹„êµ", type="secondary"):
                try:
                    with st.spinner("ëª¨ë“  ê²€ìƒ‰ ë°©ë²•ìœ¼ë¡œ ê²€ìƒ‰ ì¤‘..."):
                        # Execute all search types
                        vector_results, vector_info = hybrid_search_manager.search(search_query, "vector", search_k)
                        bm25_results, bm25_info = hybrid_search_manager.search(search_query, "bm25", search_k)
                        hybrid_results, hybrid_info = hybrid_search_manager.search(search_query, "hybrid", search_k, 60)
                        
                        # Display comparison
                        st.write("**ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ ë¹„êµ:**")
                        comp_col1, comp_col2, comp_col3 = st.columns(3)
                        
                        with comp_col1:
                            st.metric("Vector ê²€ìƒ‰", len(vector_results))
                        with comp_col2:
                            st.metric("BM25 ê²€ìƒ‰", len(bm25_results))
                        with comp_col3:
                            st.metric("í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰", len(hybrid_results))
                        
                        # Show top results from each method
                        st.write("**ê° ê²€ìƒ‰ ë°©ë²•ì˜ ìƒìœ„ 3ê°œ ê²°ê³¼:**")
                        
                        for search_name, results in [("Vector", vector_results[:3]), ("BM25", bm25_results[:3]), ("Hybrid", hybrid_results[:3])]:
                            st.write(f"**{search_name} ê²€ìƒ‰:**")
                            for i, result in enumerate(results, 1):
                                st.write(f"{i}. {result['filename']} (ì ìˆ˜: {result['score']:.3f})")
                                st.write(f"   {result['content'][:100]}...")
                            st.write("")
                        
                except Exception as e:
                    st.error(f"ê²€ìƒ‰ ë¹„êµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

with tab4:
    st.header("RAG í…ŒìŠ¤íŠ¸")
    
    if st.session_state.db is None:
        st.warning("ë¨¼ì € 'Raw Data ë™ê¸°í™”' íƒ­ì—ì„œ ë¬¸ì„œë¥¼ ë™ê¸°í™”í•´ ì£¼ì„¸ìš”.")
    else:
        # RAG Configuration
        st.subheader("RAG ì„¤ì •")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            chat_model = st.selectbox(
                "Answer Model",
                ["gpt-3.5-turbo", "gpt-4o-mini", "gpt-4o", "gpt-4-turbo"],
                index=0,
                key="chat_model"
            )
        
        with col2:
            chat_temperature = st.slider("ë‹µë³€ ìƒì„± ì˜¨ë„", min_value=0.0, max_value=1.0, value=0.0, step=0.1, key="chat_temp")
        
        with col3:
            search_k = st.slider("ê²€ìƒ‰í•  ë¬¸ì„œ ê°œìˆ˜", min_value=1, max_value=10, value=3, key="chat_k")
        
        # RAG ë§¤ë‹ˆì € ì„¤ì •
        rag_manager = st.session_state.rag_manager
        rag_manager.set_llm(chat_model, chat_temperature)
        rag_manager.set_retriever(st.session_state.db, "similarity", {"k": search_k})
        
        # ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ ë§¤ë‹ˆì €
        chat_interface = st.session_state.chat_interface
        
        # Clear chat button and LangSmith dashboard
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™”"):
                chat_interface.clear_messages()
                st.rerun()
        
        with col2:
            # LangSmith dashboard link
            langsmith_project = os.getenv("LANGSMITH_PROJECT", "rag_lab_project")
            langsmith_url = f"https://smith.langchain.com/projects/{langsmith_project}"
            st.markdown(f"[ğŸ” LangSmith ëŒ€ì‹œë³´ë“œ ì—´ê¸°]({langsmith_url})", unsafe_allow_html=True)
        
        # Display chat messages
        st.subheader("ì±„íŒ…")
        
        # Chat container
        chat_container = st.container()
        
        with chat_container:
            chat_interface.display_messages()
        
        # Chat input
        user_question = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...")
        
        if user_question:
            # Add user message to chat
            chat_interface.add_message("user", user_question)
            
            try:
                with st.spinner("ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                    # Get answer using RAG manager (LangChain ìë™ ì¶”ì )
                    answer, contexts = rag_manager.get_answer(user_question)
                    
                    # Add assistant message to chat
                    chat_interface.add_message("assistant", answer, contexts)
                    
                    st.rerun()
                    
            except Exception as e:
                st.error(f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                # Add error message to chat
                chat_interface.add_message("assistant", f"ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

with tab4:
    st.header("ì§ˆë¬¸ ìƒì„±í•˜ê¸°")
    
    if st.session_state.db is None:
        st.warning("ë¨¼ì € 'Raw Data ë™ê¸°í™”' íƒ­ì—ì„œ ë¬¸ì„œë¥¼ ë™ê¸°í™”í•´ ì£¼ì„¸ìš”.")
    else:
        # LLM configuration for question generation
        st.subheader("LLM ì„¤ì •")
        
        col1, col2 = st.columns(2)
        
        with col1:
            question_model = st.selectbox(
                "Question Generation Model",
                ["gpt-4o-mini", "gpt-3.5-turbo", "gpt-4o", "gpt-4-turbo"],
                index=0
            )
        
        with col2:
            question_temperature = st.slider("ì§ˆë¬¸ ìƒì„± ì˜¨ë„", min_value=0.0, max_value=1.0, value=0.9, step=0.1)
        
        # Number of questions
        num_questions = st.slider("ìƒì„±í•  ì§ˆë¬¸ ê°œìˆ˜", min_value=1, max_value=10, value=5)
        
        # ì§ˆë¬¸ ìƒì„± ë§¤ë‹ˆì € ì„¤ì •
        question_manager = st.session_state.question_manager
        question_manager.set_llm(question_model, question_temperature)
        
        # Generate questions
        if st.button("ì§ˆë¬¸ ìƒì„±", type="primary"):
            try:
                # Update workflow status to in_progress
                workflow_manager = st.session_state.workflow_manager
                workflow_manager.update_step_status("question_generation", "in_progress", 0)
                
                with st.spinner("ì§ˆë¬¸ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                    if st.session_state.db is None:
                        workflow_manager.update_step_status("question_generation", "error", 0, 
                                                          error="DBê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € ë™ê¸°í™”ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
                        st.error("DBê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € ë™ê¸°í™”ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
                    else:
                        # Update progress
                        workflow_manager.update_step_status("question_generation", "in_progress", 25, {
                            "model_used": question_model,
                            "target_count": num_questions
                        })
                        
                        # Generate questions using manager
                        questions = question_manager.generate_questions(st.session_state.db, num_questions)
                        
                        # Store generated questions
                        st.session_state.generated_questions = questions
                        st.session_state.edited_questions = questions.copy()
                        
                        # Update workflow status to completed
                        workflow_manager.update_step_status("question_generation", "completed", 100, {
                            "question_count": len(questions),
                            "model_used": question_model
                        })
                        
                        st.success(f"{len(questions)}ê°œì˜ ì§ˆë¬¸ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    
            except Exception as e:
                workflow_manager.update_step_status("question_generation", "error", 0, 
                                                  error=str(e))
                st.error(f"ì§ˆë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        
        # Display and edit questions
        if st.session_state.generated_questions:
            st.subheader("ìƒì„±ëœ ì§ˆë¬¸ ìˆ˜ì •")
            st.write("ì•„ë˜ì—ì„œ ì§ˆë¬¸ì„ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:")
            
            # Edit questions
            for i, question in enumerate(st.session_state.generated_questions):
                edited_question = st.text_area(
                    f"ì§ˆë¬¸ {i+1}",
                    value=st.session_state.edited_questions[i] if i < len(st.session_state.edited_questions) else question,
                    key=f"question_{i}"
                )
                
                # Update edited questions in session state
                if len(st.session_state.edited_questions) <= i:
                    st.session_state.edited_questions.append(edited_question)
                else:
                    st.session_state.edited_questions[i] = edited_question
            
            # Add/Remove questions
            col1, col2 = st.columns(2)
            
            with col1:
                if st.button("ì§ˆë¬¸ ì¶”ê°€"):
                    question_manager.add_question("ìƒˆë¡œìš´ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")
                    st.session_state.generated_questions = question_manager.get_questions()
                    st.session_state.edited_questions = question_manager.get_questions()
                    st.rerun()
            
            with col2:
                if st.button("ë§ˆì§€ë§‰ ì§ˆë¬¸ ì‚­ì œ") and len(st.session_state.generated_questions) > 1:
                    question_manager.remove_question(len(question_manager.get_questions()) - 1)
                    st.session_state.generated_questions = question_manager.get_questions()
                    st.session_state.edited_questions = question_manager.get_questions()
                    st.rerun()
            
            # Display final questions
            st.subheader("ìµœì¢… ì§ˆë¬¸ ëª©ë¡")
            for i, question in enumerate(st.session_state.edited_questions):
                st.write(f"{i+1}. {question}")

with tab5:
    st.header("RAG í‰ê°€í•˜ê¸°")
    
    if st.session_state.db is None:
        st.warning("ë¨¼ì € 'Raw Data ë™ê¸°í™”' íƒ­ì—ì„œ ë¬¸ì„œë¥¼ ë™ê¸°í™”í•´ ì£¼ì„¸ìš”.")
    elif not st.session_state.edited_questions:
        st.warning("ë¨¼ì € 'ì§ˆë¬¸ ìƒì„±í•˜ê¸°' íƒ­ì—ì„œ ì§ˆë¬¸ì„ ìƒì„±í•´ ì£¼ì„¸ìš”.")
    else:
        # Retriever configuration
        st.subheader("ê²€ìƒ‰ê¸° ì„¤ì •")
        
        col1, col2 = st.columns(2)
        
        with col1:
            search_type = st.selectbox(
                "Search Type",
                ["mmr", "similarity", "similarity_score_threshold"],
                index=0
            )
        
        with col2:
            k = st.slider("ê²€ìƒ‰í•  ë¬¸ì„œ ê°œìˆ˜ (k)", min_value=1, max_value=20, value=5)
        
        # Additional parameters based on search type
        if search_type == "mmr":
            col1, col2 = st.columns(2)
            with col1:
                lambda_mult = st.slider("ëŒë‹¤ ê°€ì¤‘ì¹˜", min_value=0.0, max_value=1.0, value=0.25, step=0.05)
            with col2:
                fetch_k = st.slider("Fetch K (ê²€ìƒ‰ í›„ë³´ ìˆ˜)", min_value=k, max_value=50, value=10)
            
            search_kwargs = {"k": k, "lambda_mult": lambda_mult, "fetch_k": fetch_k}
        
        elif search_type == "similarity_score_threshold":
            score_threshold = st.slider("ì ìˆ˜ ì„ê³„ê°’", min_value=-1.0, max_value=1.0, value=0.5, step=0.1)
            search_kwargs = {"k": k, "score_threshold": score_threshold}
        
        else:
            search_kwargs = {"k": k}
        
        # LLM configuration
        st.subheader("LLM ì„¤ì •")
        
        answer_model = st.selectbox(
            "Answer Generation Model",
            ["gpt-3.5-turbo", "gpt-4o-mini", "gpt-4o", "gpt-4-turbo"],
            index=0
        )
        answer_temperature = st.slider("ë‹µë³€ ìƒì„± ì˜¨ë„", min_value=0.0, max_value=1.0, value=0.0, step=0.1)
        
        # RAGAS metrics selection
        st.subheader("RAGAS í‰ê°€ ì§€í‘œ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            use_faithfulness = st.checkbox("ì •í™•ì„±(Faithfulness)", value=True)
            use_answer_relevancy = st.checkbox("ë‹µë³€ ê´€ë ¨ì„±(Answer Relevancy)", value=True)
        
        with col2:
            use_context_precision = st.checkbox("ë¬¸ë§¥ ì •ë°€ë„(Context Precision)", value=True)
            use_context_recall = st.checkbox("ë¬¸ë§¥ ì¬í˜„ìœ¨(Context Recall)", value=True)
        
        # Display questions to be evaluated
        st.subheader("í‰ê°€í•  ì§ˆë¬¸ ëª©ë¡")
        for i, question in enumerate(st.session_state.edited_questions):
            st.write(f"{i+1}. {question}")
        
        # í‰ê°€ ë§¤ë‹ˆì € ì„¤ì •
        evaluation_manager = st.session_state.evaluation_manager
        rag_manager = st.session_state.rag_manager
        
        # RAG ë§¤ë‹ˆì € ì„¤ì •
        rag_manager.set_llm(answer_model, answer_temperature)
        rag_manager.set_retriever(st.session_state.db, search_type, search_kwargs)
        
        # Evaluate questions
        if st.button("RAG í‰ê°€ ì‹¤í–‰", type="primary"):
            try:
                # Update workflow status to in_progress
                workflow_manager = st.session_state.workflow_manager
                workflow_manager.update_step_status("evaluation", "in_progress", 0)
                
                with st.spinner("ì§ˆë¬¸ì„ í‰ê°€ ì¤‘ì…ë‹ˆë‹¤..."):
                    st.write("RAGASë¡œ í‰ê°€ ì¤‘...")
                    
                    # Update progress
                    workflow_manager.update_step_status("evaluation", "in_progress", 10, {
                        "total_questions": len(st.session_state.edited_questions),
                        "model_used": answer_model
                    })
                    
                    # í‰ê°€ ë©”íŠ¸ë¦­ ì„¤ì •
                    metrics_config = {
                        'use_faithfulness': use_faithfulness,
                        'use_answer_relevancy': use_answer_relevancy,
                        'use_context_precision': use_context_precision,
                        'use_context_recall': use_context_recall
                    }
                    
                    # Progress update
                    workflow_manager.update_step_status("evaluation", "in_progress", 30)
                    
                    # í‰ê°€ ì‹¤í–‰
                    results_df = evaluation_manager.evaluate_rag_system(
                        st.session_state.edited_questions,
                        st.session_state.db,
                        rag_manager,
                        metrics_config
                    )
                    
                    # Store results
                    st.session_state.evaluation_results = results_df
                    
                    # Get average scores for workflow status
                    avg_scores = evaluation_manager.get_average_scores()
                    
                    # Update workflow status to completed
                    workflow_manager.update_step_status("evaluation", "completed", 100, {
                        "total_questions": len(st.session_state.edited_questions),
                        "model_used": answer_model,
                        "average_scores": avg_scores
                    })
                    
                    st.success("í‰ê°€ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                    
            except Exception as e:
                workflow_manager.update_step_status("evaluation", "error", 0, 
                                                  error=str(e))
                st.error(f"í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        
        # Display results
        if st.session_state.evaluation_results is not None:
            st.subheader("í‰ê°€ ê²°ê³¼")
            
            results_df = st.session_state.evaluation_results
            
            # Display dataframe
            st.dataframe(results_df)
            
            # Calculate and display average scores
            avg_scores = evaluation_manager.get_average_scores()
            
            if avg_scores:
                st.subheader("í‰ê·  ì ìˆ˜")
                col1, col2 = st.columns(2)
                
                avg_scores_items = list(avg_scores.items())
                with col1:
                    for i, (metric, score) in enumerate(avg_scores_items):
                        if i < len(avg_scores_items) // 2 + len(avg_scores_items) % 2:
                            st.metric(metric.replace("_", " ").title(), f"{score:.3f}")
                
                with col2:
                    for i, (metric, score) in enumerate(avg_scores_items):
                        if i >= len(avg_scores_items) // 2 + len(avg_scores_items) % 2:
                            st.metric(metric.replace("_", " ").title(), f"{score:.3f}")
                
                # Visualizations
                st.subheader("Visualizations")
                
                # Bar chart for each metric
                metric_columns = [col for col in results_df.columns if col not in ["question", "answer"]]
                for metric in metric_columns:
                    fig = VisualizationUtils.create_metric_bar_chart(results_df, metric)
                    st.pyplot(fig)
                
                # Radar chart for average scores
                radar_fig = VisualizationUtils.create_radar_chart(avg_scores)
                if radar_fig:
                    st.pyplot(radar_fig)
            
            # Q&A Display
            st.subheader("ì§ˆë¬¸ê³¼ ë‹µë³€")
            for i, row in results_df.iterrows():
                with st.expander(f"Q{i+1}: {row['question']}"):
                    st.write("**ë‹µë³€:**")
                    st.write(row['answer'])
                    
                    if avg_scores:
                        st.write("**ì ìˆ˜:**")
                        for metric in avg_scores.keys():
                            if metric in row:
                                st.write(f"- {metric.replace('_', ' ').title()}: {row[metric]:.3f}")

# Workflow Status Sidebar
def display_workflow_sidebar():
    """Display workflow status in sidebar"""
    workflow_manager = st.session_state.workflow_manager
    
    st.sidebar.title("ğŸ”„ RAG Workflow Status")
    st.sidebar.markdown("---")
    
    # Overall progress
    overall_progress = workflow_manager.get_overall_progress()
    st.sidebar.progress(overall_progress / 100)
    st.sidebar.text(f"Overall Progress: {overall_progress:.1f}%")
    
    # Current status
    workflow_status = workflow_manager.get_workflow_status()
    status_emoji = {"pending": "â³", "in_progress": "ğŸ”„", "completed": "âœ…"}.get(workflow_status, "â“")
    st.sidebar.text(f"Status: {status_emoji} {workflow_status.title()}")
    
    st.sidebar.markdown("---")
    
    # Individual steps
    st.sidebar.subheader("ğŸ“‹ Workflow Steps")
    
    # Step 1: Document Embedding
    embedding_info = workflow_manager.get_step_display_info("embedding")
    with st.sidebar.expander(f"{embedding_info['emoji']} Document Embedding", expanded=True):
        st.text(f"Status: {embedding_info['status'].title()}")
        if embedding_info['progress'] > 0:
            st.progress(embedding_info['progress'] / 100)
        st.text(f"Updated: {embedding_info['last_updated']}")
        
        if embedding_info['details']:
            if 'document_count' in embedding_info['details']:
                st.text(f"Documents: {embedding_info['details']['document_count']}")
            if 'new_files' in embedding_info['details']:
                st.text(f"New files: {embedding_info['details']['new_files']}")
        
        if embedding_info['error']:
            st.error(f"Error: {embedding_info['error']}")
    
    # Step 2: Question Generation
    question_info = workflow_manager.get_step_display_info("question_generation")
    with st.sidebar.expander(f"{question_info['emoji']} Question Generation"):
        st.text(f"Status: {question_info['status'].title()}")
        if question_info['progress'] > 0:
            st.progress(question_info['progress'] / 100)
        st.text(f"Updated: {question_info['last_updated']}")
        
        if question_info['details']:
            if 'question_count' in question_info['details']:
                st.text(f"Questions: {question_info['details']['question_count']}")
            if 'model_used' in question_info['details']:
                st.text(f"Model: {question_info['details']['model_used']}")
        
        if question_info['error']:
            st.error(f"Error: {question_info['error']}")
    
    # Step 3: Question Evaluation
    evaluation_info = workflow_manager.get_step_display_info("evaluation")
    with st.sidebar.expander(f"{evaluation_info['emoji']} Question Evaluation"):
        st.text(f"Status: {evaluation_info['status'].title()}")
        if evaluation_info['progress'] > 0:
            st.progress(evaluation_info['progress'] / 100)
        st.text(f"Updated: {evaluation_info['last_updated']}")
        
        if evaluation_info['details']:
            if 'average_scores' in evaluation_info['details']:
                st.text("Average Scores:")
                for metric, score in evaluation_info['details']['average_scores'].items():
                    st.text(f"  {metric}: {score:.3f}")
        
        if evaluation_info['error']:
            st.error(f"Error: {evaluation_info['error']}")
    
    st.sidebar.markdown("---")
    
    # Quick Actions
    st.sidebar.subheader("ğŸš€ Quick Actions")
    
    # Next step suggestion
    next_step = workflow_manager.get_next_step()
    if next_step:
        step_names = {
            "embedding": "Document Sync",
            "question_generation": "Question Generation", 
            "evaluation": "Evaluation"
        }
        st.sidebar.info(f"Next: {step_names.get(next_step, next_step)}")
    
    # Reset workflow button
    if st.sidebar.button("ğŸ”„ Reset Workflow"):
        workflow_manager.reset_workflow()
        st.rerun()
    
    # Workflow completion celebration
    if workflow_manager.workflow_completed:
        st.sidebar.success("ğŸ‰ Workflow Completed!")
        completion_time = workflow_manager.completion_time
        start_time = workflow_manager.start_time
        if completion_time and start_time:
            duration = completion_time - start_time
            st.sidebar.text(f"Duration: {duration:.1f} seconds")

# Display sidebar
display_workflow_sidebar()