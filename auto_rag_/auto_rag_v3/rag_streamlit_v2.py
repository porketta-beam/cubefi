import streamlit as st
import os
import shutil
import time
from pathlib import Path
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import koreanize_matplotlib
import plotly.graph_objects as go
import plotly.express as px
from datasets import Dataset

# Langchain imports
from langchain_community.document_loaders import TextLoader, PyPDFLoader
from langchain_openai.embeddings import OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import ChatOpenAI
from langchain.chains import create_retrieval_chain
from langchain_core.prompts import ChatPromptTemplate

# RAGAS imports
from ragas.metrics import (
    faithfulness,
    answer_relevancy,
    context_precision,
    context_recall
)
from ragas.evaluation import evaluate

# Load environment variables
from dotenv import load_dotenv
import os

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ì˜ .env íŒŒì¼ ê²½ë¡œ ì„¤ì •
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
env_path = os.path.join(project_root, '.env')

load_dotenv(dotenv_path=env_path, override=True)

# LangSmith ì„¤ì • í™•ì¸
print(f"LangSmith API Key loaded: {'Yes' if os.getenv('LANGSMITH_API_KEY') else 'No'}")
print(f"LangSmith Project: {os.getenv('LANGSMITH_PROJECT', 'Not set')}")

# LangSmith ê°•ì œ ì´ˆê¸°í™” (Streamlit í™˜ê²½ì—ì„œ í•„ìš”)
if os.getenv('LANGSMITH_API_KEY'):
    from langsmith import Client
    try:
        langsmith_client = Client()
        print(f"LangSmith client initialized successfully")
    except Exception as e:
        print(f"LangSmith client initialization failed: {e}")

from typing import List, Dict, Any
from mod import (
    ChromaDBManager,
    RawDataSyncManager,
    RAGSystemManager,
    QuestionGenerationManager,
    EvaluationManager,
    ChatInterfaceManager,
    VisualizationUtils,
    WorkflowStatusManager,
    ElasticsearchManager,
    HybridSearchManager
)
from mod.search_parameter_optimizer import SearchParameterOptimizer
from mod.weight_optimization_experiment import get_weight_experiment
from mod.weight_visualization import get_visualization_manager
# UI modules import
from ui.evaluation_charts import create_quality_analysis_dashboard, QualityMetrics, SearchResultAnalyzer
# LangChain ë„¤ì´í‹°ë¸Œ ìë™ ì¶”ì  ì‚¬ìš©

# Matplotlib í•œê¸€ ë° ìŒìˆ˜ ê¹¨ì§ ë°©ì§€ ì„¤ì •
plt.rcParams['axes.unicode_minus'] = False

# Set page config
st.set_page_config(
    page_title="RAG System with RAGAS Evaluation",
    page_icon="ğŸ¤–",
    layout="wide"
)

# Database connection management functions
def get_db_connection_status():
    """Get comprehensive database connection status"""
    status = {
        'chroma_connected': False,
        'chroma_doc_count': 0,
        'elasticsearch_connected': False,
        'elasticsearch_doc_count': 0,
        'hybrid_search_available': False,
        'db_manager_available': False
    }
    
    # ChromaDB ìƒíƒœ í™•ì¸
    if hasattr(st.session_state, 'db_manager') and st.session_state.db_manager:
        status['db_manager_available'] = True
        db_manager = st.session_state.db_manager
        
        # DB ë¡œë“œ ìƒíƒœ í™•ì¸ (load_existing_db í˜¸ì¶œ ì—¬ë¶€ì™€ ê´€ê³„ì—†ì´)
        if db_manager.db is not None:
            status['chroma_connected'] = True
            status['chroma_doc_count'] = db_manager.get_document_count()
            # ì„¸ì…˜ ìƒíƒœ ë™ê¸°í™”
            st.session_state.db = db_manager.db
        elif db_manager.check_db_exists():
            # DB íŒŒì¼ì€ ì¡´ì¬í•˜ì§€ë§Œ ë¡œë“œë˜ì§€ ì•Šì€ ê²½ìš° ìë™ ë¡œë“œ ì‹œë„
            try:
                if db_manager.load_existing_db():
                    status['chroma_connected'] = True
                    status['chroma_doc_count'] = db_manager.get_document_count()
                    st.session_state.db = db_manager.db
            except:
                pass
    
    # Elasticsearch ìƒíƒœ í™•ì¸
    if hasattr(st.session_state, 'elasticsearch_manager') and st.session_state.elasticsearch_manager:
        es_manager = st.session_state.elasticsearch_manager
        try:
            if es_manager.check_connection():
                status['elasticsearch_connected'] = True
                if es_manager.check_index_exists():
                    # ë¬¸ì„œ ìˆ˜ ì§ì ‘ ì¡°íšŒ
                    doc_count = es_manager.get_document_count()
                    status['elasticsearch_doc_count'] = doc_count
                    
                    # ì¶”ê°€ í†µê³„ ì •ë³´
                    es_stats = es_manager.get_index_stats()
                    if es_stats and es_stats.get('document_count', 0) != doc_count:
                        # ë‘ ë°©ë²•ìœ¼ë¡œ ì¡°íšŒí•œ ê²°ê³¼ê°€ ë‹¤ë¥¸ ê²½ìš° ë” ì •í™•í•œ ê°’ ì‚¬ìš©
                        status['elasticsearch_doc_count'] = max(doc_count, es_stats.get('document_count', 0))
                else:
                    status['elasticsearch_doc_count'] = 0
        except Exception as e:
            # ì—°ê²° ì˜¤ë¥˜ê°€ ì•„ë‹Œ ë‹¤ë¥¸ ì˜¤ë¥˜ëŠ” ê²½ê³ ë§Œ í‘œì‹œ
            if "connection" not in str(e).lower():
                st.warning(f"Elasticsearch ìƒíƒœ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            status['elasticsearch_connected'] = False
    
    # Hybrid search ê°€ìš©ì„± í™•ì¸
    if hasattr(st.session_state, 'hybrid_search_manager') and st.session_state.hybrid_search_manager:
        hybrid_manager = st.session_state.hybrid_search_manager
        availability = hybrid_manager.check_search_availability()
        status['hybrid_search_available'] = availability.get('hybrid_search', False)
    
    return status

def ensure_db_connection():
    """Ensure database connections are properly initialized and synchronized"""
    status = get_db_connection_status()
    
    # ChromaDB ì—°ê²° ë³´ì¥
    if not status['chroma_connected'] and status['db_manager_available']:
        db_manager = st.session_state.db_manager
        if db_manager.check_db_exists() and db_manager.db is None:
            try:
                db_manager.load_existing_db()
                st.session_state.db = db_manager.db
            except:
                pass
    
    return get_db_connection_status()

# Document loading and splitting function
def load_and_split_document(file_path: str, chunk_size: int = 500, chunk_overlap: int = 100) -> list:
    """íŒŒì¼ì„ ë¡œë“œí•˜ê³  ì²­í¬ë¡œ ë¶„í• """
    try:
        file_extension = Path(file_path).suffix.lower()
        
        # íŒŒì¼ íƒ€ì…ì— ë”°ë¥¸ ë¡œë” ì„ íƒ
        if file_extension == '.txt':
            loader = TextLoader(file_path, encoding='utf-8')
        elif file_extension == '.pdf':
            loader = PyPDFLoader(file_path)
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_extension}")
        
        # í…ìŠ¤íŠ¸ ë¶„í• ê¸° ì„¤ì •
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap
        )
        
        # ë¬¸ì„œ ë¡œë“œ ë° ë¶„í• 
        documents = loader.load_and_split(text_splitter)
        
        return documents
        
    except Exception as e:
        st.error(f"íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ ({os.path.basename(file_path)}): {str(e)}")
        return []


# Initialize session state
if 'db' not in st.session_state:
    st.session_state.db = None
if 'documents' not in st.session_state:
    st.session_state.documents = None
if 'evaluation_results' not in st.session_state:
    st.session_state.evaluation_results = None
if 'generated_questions' not in st.session_state:
    st.session_state.generated_questions = []
if 'edited_questions' not in st.session_state:
    st.session_state.edited_questions = []
if 'chat_messages' not in st.session_state:
    st.session_state.chat_messages = []
if 'db_manager' not in st.session_state:
    st.session_state.db_manager = ChromaDBManager()
if 'sync_manager' not in st.session_state:
    st.session_state.sync_manager = RawDataSyncManager()
if 'rag_manager' not in st.session_state:
    st.session_state.rag_manager = RAGSystemManager()
if 'question_manager' not in st.session_state:
    st.session_state.question_manager = QuestionGenerationManager()
if 'evaluation_manager' not in st.session_state:
    st.session_state.evaluation_manager = EvaluationManager()
if 'chat_interface' not in st.session_state:
    st.session_state.chat_interface = ChatInterfaceManager()
if 'workflow_manager' not in st.session_state:
    st.session_state.workflow_manager = WorkflowStatusManager()
if 'elasticsearch_manager' not in st.session_state:
    st.session_state.elasticsearch_manager = ElasticsearchManager()
if 'hybrid_search_manager' not in st.session_state:
    st.session_state.hybrid_search_manager = None  # Initialized later when both managers are ready

# Sidebar - DB ìƒíƒœ ëª¨ë‹ˆí„°ë§
with st.sidebar:
    st.header("ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ")
    
    # DB ì—°ê²° ìƒíƒœ í™•ì¸
    db_status = ensure_db_connection()
    
    # ChromaDB ìƒíƒœ
    st.subheader("ğŸ—„ï¸ ChromaDB")
    if db_status['chroma_connected']:
        st.success(f"âœ… ì—°ê²°ë¨ ({db_status['chroma_doc_count']}ê°œ ì²­í¬)")
    else:
        st.error("âŒ ì—°ê²° ì•ˆë¨")
        if db_status['db_manager_available']:
            db_manager = st.session_state.db_manager
            if db_manager.check_db_exists():
                st.info("ğŸ’¡ DB íŒŒì¼ ì¡´ì¬, 'ë™ê¸°í™”' íƒ­ì—ì„œ ë¡œë“œ ê°€ëŠ¥")
            else:
                st.info("ğŸ’¡ 'ë™ê¸°í™”' íƒ­ì—ì„œ DB ìƒì„± í•„ìš”")
    
    # Elasticsearch ìƒíƒœ
    st.subheader("ğŸ” Elasticsearch")
    if db_status['elasticsearch_connected']:
        st.success(f"âœ… ì—°ê²°ë¨ ({db_status['elasticsearch_doc_count']}ê°œ ì²­í¬)")
    else:
        st.error("âŒ ì—°ê²° ì•ˆë¨")
        st.info("ğŸ’¡ Elasticsearch ì„œë²„ í™•ì¸ í•„ìš”")
    
    # Hybrid Search ìƒíƒœ
    st.subheader("ğŸ”„ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰")
    if db_status['hybrid_search_available']:
        st.success("âœ… ì‚¬ìš© ê°€ëŠ¥")
    else:
        st.error("âŒ ì‚¬ìš© ë¶ˆê°€")
        missing = []
        if not db_status['chroma_connected']:
            missing.append("ChromaDB")
        if not db_status['elasticsearch_connected']:
            missing.append("Elasticsearch")
        if missing:
            st.info(f"ğŸ’¡ {', '.join(missing)} ì—°ê²° í•„ìš”")
    
    # ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼
    if st.button("ğŸ”„ ìƒíƒœ ìƒˆë¡œê³ ì¹¨", help="ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ìƒíƒœë¥¼ ë‹¤ì‹œ í™•ì¸í•©ë‹ˆë‹¤"):
        st.rerun()
    
    st.markdown("---")
    
    # ë¹ ë¥¸ ì•¡ì…˜
    st.subheader("âš¡ ë¹ ë¥¸ ì•¡ì…˜")
    if not db_status['chroma_connected']:
        if st.button("ğŸ“¥ ChromaDB ë¡œë“œ", help="ê¸°ì¡´ ChromaDBë¥¼ ë¡œë“œí•©ë‹ˆë‹¤"):
            try:
                if st.session_state.db_manager.load_existing_db():
                    st.success("ChromaDB ë¡œë“œ ì™„ë£Œ!")
                    st.rerun()
                else:
                    st.error("ChromaDB ë¡œë“œ ì‹¤íŒ¨")
            except Exception as e:
                st.error(f"ì˜¤ë¥˜: {str(e)}")

st.title("ğŸ¤– RAG ì‹œìŠ¤í…œ ë° RAGAS í‰ê°€")
st.markdown("---")

# íƒ­ ì´ë¦„
tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8 = st.tabs([
    "ğŸ“ ë¬¸ì„œ ê´€ë¦¬", 
    "ğŸ”„ ë¬¸ì„œ ì²­í‚¹ ë° ì¸ë±ì‹±", 
    "ğŸ” í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰", 
    "ğŸ“Š í’ˆì§ˆ ë¶„ì„", 
    "âš–ï¸ ê°€ì¤‘ì¹˜ ìµœì í™”",
    "ğŸ’¬ RAG í…ŒìŠ¤íŠ¸", 
    "ğŸ“ ì§ˆë¬¸ ìƒì„±í•˜ê¸°", 
    "ğŸ” RAG í‰ê°€í•˜ê¸°"
])

with tab1:
    st.header("ğŸ“ ë¬¸ì„œ ê´€ë¦¬")
    
    # ì›ë³¸ ë¬¸ì„œ í´ë” ê´€ë¦¬ ê¸°ëŠ¥
    sync_manager = st.session_state.sync_manager
    raw_data_path = sync_manager.raw_data_path
    
    st.subheader("ğŸ“‚ í´ë” ì •ë³´")
    st.info(f"**ì›ë³¸ ë¬¸ì„œ í´ë” ê²½ë¡œ:** {raw_data_path}")
    
    # í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
    if not os.path.exists(raw_data_path):
        os.makedirs(raw_data_path)
        st.success("âœ… ì›ë³¸ ë¬¸ì„œ í´ë”ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # ì›ë³¸ ë¬¸ì„œ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    def get_file_list():
        """raw_data í´ë”ì˜ ì›ë³¸ ë¬¸ì„œ ëª©ë¡ì„ ê°€ì ¸ì˜´"""
        if not os.path.exists(raw_data_path):
            return []
        
        files = []
        for filename in os.listdir(raw_data_path):
            file_path = os.path.join(raw_data_path, filename)
            if os.path.isfile(file_path):
                file_stat = os.stat(file_path)
                file_size_mb = file_stat.st_size / (1024 * 1024)
                files.append({
                    'filename': filename,
                    'size_mb': file_size_mb,
                    'modified_time': file_stat.st_mtime,
                    'file_path': file_path
                })
        return sorted(files, key=lambda x: x['modified_time'], reverse=True)
    
    # ì›ë³¸ ë¬¸ì„œ ëª©ë¡ í‘œì‹œ
    st.subheader("ğŸ“‹ ì›ë³¸ ë¬¸ì„œ ëª©ë¡")
    
    files = get_file_list()
    
    if files:
        # ë¬¸ì„œ ì •ë³´ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
        import datetime
        file_data = []
        for file_info in files:
            modified_time = datetime.datetime.fromtimestamp(file_info['modified_time'])
            file_data.append({
                'ë¬¸ì„œëª…': file_info['filename'],
                'í¬ê¸° (MB)': f"{file_info['size_mb']:.2f}",
                'ìˆ˜ì •ì¼': modified_time.strftime('%Y-%m-%d %H:%M:%S'),
                'í˜•ì‹': os.path.splitext(file_info['filename'])[1].upper()
            })
        
        df = pd.DataFrame(file_data)
        st.dataframe(df, use_container_width=True)
        
        # ì „ì²´ í†µê³„
        total_files = len(files)
        total_size = sum(f['size_mb'] for f in files)
        st.info(f"ğŸ“Š **ì´ {total_files}ê°œ íŒŒì¼, ì „ì²´ í¬ê¸°: {total_size:.2f} MB**")
        
    else:
        st.warning("ğŸ“ í´ë”ì— íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    st.markdown("---")
    
    # íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜
    st.subheader("ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**ë‹¨ì¼ íŒŒì¼ ì—…ë¡œë“œ**")
        uploaded_file = st.file_uploader(
            "íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”",
            type=['txt', 'pdf'],
            key="single_upload"
        )
        
        if uploaded_file is not None:
            if st.button("ğŸ’¾ ë‹¨ì¼ íŒŒì¼ ì €ì¥", key="save_single"):
                try:
                    file_path = os.path.join(raw_data_path, uploaded_file.name)
                    with open(file_path, "wb") as f:
                        f.write(uploaded_file.getbuffer())
                    st.success(f"âœ… '{uploaded_file.name}' íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    st.rerun()
                except Exception as e:
                    st.error(f"âŒ íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    with col2:
        st.write("**ë‹¤ì¤‘ íŒŒì¼ ì—…ë¡œë“œ**")
        uploaded_files = st.file_uploader(
            "ì—¬ëŸ¬ íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”",
            type=['txt', 'pdf'],
            accept_multiple_files=True,
            key="multiple_upload"
        )
        
        if uploaded_files:
            if st.button("ğŸ’¾ ë‹¤ì¤‘ íŒŒì¼ ì €ì¥", key="save_multiple"):
                try:
                    saved_count = 0
                    for uploaded_file in uploaded_files:
                        file_path = os.path.join(raw_data_path, uploaded_file.name)
                        with open(file_path, "wb") as f:
                            f.write(uploaded_file.getbuffer())
                        saved_count += 1
                    
                    st.success(f"âœ… {saved_count}ê°œ íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    st.rerun()
                except Exception as e:
                    st.error(f"âŒ íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    st.markdown("---")
    
    # íŒŒì¼ ì‚­ì œ ì„¹ì…˜
    st.subheader("ğŸ—‘ï¸ íŒŒì¼ ì‚­ì œ")
    
    if files:
        st.write("ì‚­ì œí•  íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”:")
        
        # íŒŒì¼ ì„ íƒ ì²´í¬ë°•ìŠ¤
        selected_files = []
        for file_info in files:
            if st.checkbox(
                f"{file_info['filename']} ({file_info['size_mb']:.2f} MB)",
                key=f"delete_{file_info['filename']}"
            ):
                selected_files.append(file_info)
        
        if selected_files:
            st.warning(f"âš ï¸ **{len(selected_files)}ê°œ íŒŒì¼ì´ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤.**")
            
            # ì„ íƒëœ íŒŒì¼ ëª©ë¡ í‘œì‹œ
            st.write("**ì„ íƒëœ íŒŒì¼:**")
            for file_info in selected_files:
                st.write(f"- {file_info['filename']} ({file_info['size_mb']:.2f} MB)")
            
            # ì‚­ì œ í™•ì¸ ë° ì‹¤í–‰
            if st.button("ğŸ—‘ï¸ ì„ íƒëœ íŒŒì¼ ì‚­ì œ", type="secondary"):
                try:
                    deleted_count = 0
                    for file_info in selected_files:
                        os.remove(file_info['file_path'])
                        deleted_count += 1
                    
                    st.success(f"âœ… {deleted_count}ê°œ íŒŒì¼ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤!")
                    st.rerun()
                except Exception as e:
                    st.error(f"âŒ íŒŒì¼ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        else:
            st.info("ğŸ“ ì‚­ì œí•  íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
    else:
        st.info("ğŸ“ ì‚­ì œí•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    st.markdown("---")
    
    # ì‚¬ìš©ë²• ì•ˆë‚´
    st.subheader("ğŸ’¡ ì‚¬ìš©ë²•")
    st.info("""
    **ì§€ì› íŒŒì¼ í˜•ì‹:**
    - ğŸ“„ í…ìŠ¤íŠ¸ íŒŒì¼ (.txt)
    - ğŸ“• PDF íŒŒì¼ (.pdf)
    
    **íŒŒì¼ í¬ê¸° ì œí•œ:**
    - ë‹¨ì¼ íŒŒì¼: ìµœëŒ€ 200MB
    - ì „ì²´ í´ë”: ìµœëŒ€ 1GB
    
    **ì£¼ì˜ì‚¬í•­:**
    - íŒŒì¼ ì‚­ì œëŠ” ë˜ëŒë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤
    - íŒŒì¼ëª…ì— íŠ¹ìˆ˜ë¬¸ì ì‚¬ìš©ì„ í”¼í•´ì£¼ì„¸ìš”
    """)

with tab2:
    st.header("ğŸ”„ ë¬¸ì„œ ì²­í‚¹ ë° ì¸ë±ì‹±")
    
    # ë™ê¸°í™” ê´€ë¦¬ì ê°€ì ¸ì˜¤ê¸°
    sync_manager = st.session_state.sync_manager
    db_manager = st.session_state.db_manager
    
    # VectorDB ìƒíƒœ í‘œì‹œ
    db_status = db_manager.get_status()
    
    st.subheader("ğŸ“ ì²­í¬ ì¸ë±ì‹± ìƒíƒœ")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if db_status["db_exists"]:
            st.success("âœ… VectorDB ì¡´ì¬")
            st.metric("ì¸ë±ì‹±ëœ ì²­í¬ ìˆ˜", db_status["document_count"])
        else:
            st.warning("âŒ VectorDB ì—†ìŒ")
            st.metric("ì¸ë±ì‹±ëœ ì²­í¬ ìˆ˜", 0)
    
    with col2:
        st.info(f"ğŸ“‚ ì €ì¥ ê²½ë¡œ: {db_status['db_path']}")
        st.info(f"ğŸ”¤ ì„ë² ë”© ëª¨ë¸: {db_status['embedding_model']}")
    
    with col3:
        if db_status["db_exists"]:
            if st.button("ğŸ—‘ï¸ VectorDB ì‚­ì œ", type="secondary"):
                try:
                    with st.spinner("VectorDBë¥¼ ì‚­ì œí•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                        # ì„¸ì…˜ ë°ì´í„° ì´ˆê¸°í™”
                        st.session_state.documents = None
                        st.session_state.generated_questions = []
                        st.session_state.edited_questions = []
                        st.session_state.evaluation_results = None
                        st.session_state.db = None
                        
                        # DB ì‚­ì œ
                        success = db_manager.delete_db()
                        
                        if success:
                            st.success("âœ… VectorDBê°€ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤!")
                        else:
                            st.error("âŒ VectorDB ì‚­ì œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                            
                        st.rerun()
                        
                except Exception as e:
                    st.error(f"VectorDB ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    st.markdown("---")
    
    st.subheader("ğŸ“Š ë¬¸ì„œ-ì²­í¬ ë™ê¸°í™” ìƒíƒœ")
    
    # ë™ê¸°í™” ìƒíƒœ í™•ì¸
    if st.button("ğŸ”„ ë™ê¸°í™” ìƒíƒœ í™•ì¸"):
        sync_status = sync_manager.compare_with_db(db_manager)
        raw_files_info = sync_manager.scan_raw_data_folder()
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("ğŸ“ **ì›ë³¸ ë¬¸ì„œ í´ë” ìƒíƒœ**")
            st.write(f"- ê²½ë¡œ: {sync_manager.raw_data_path}")
            st.write(f"- ì´ ë¬¸ì„œ ìˆ˜: {len(raw_files_info)}ê°œ")
            
            if raw_files_info:
                total_size_mb = sum(info['size_mb'] for info in raw_files_info)
                st.write(f"- ì´ ë¬¸ì„œ í¬ê¸°: {total_size_mb:.2f} MB")
                
                # ë¬¸ì„œ ëª©ë¡ í‘œì‹œ
                st.write("**ë¬¸ì„œ ëª©ë¡:**")
                for file_info in raw_files_info:
                    st.write(f"  - {file_info['filename']} ({file_info['size_mb']:.2f} MB)")
        
        with col2:
            st.write("ğŸ—„ï¸ **ChromaDB ìƒíƒœ**")
            db_status = db_manager.get_status()
            st.write(f"- DB ì¡´ì¬: {'âœ…' if db_status['db_exists'] else 'âŒ'}")
            st.write(f"- ì¸ë±ì‹±ëœ ì²­í¬ ìˆ˜: {db_status['document_count']}ê°œ")
            st.write(f"- ì €ì¥ëœ ë¬¸ì„œ ìˆ˜: {len(sync_status['all_db_files'])}ê°œ")
            
            # ë™ê¸°í™” ìƒíƒœ
            st.write("**ë™ê¸°í™” ìƒíƒœ:**")
            st.write(f"- ìƒˆ ë¬¸ì„œ: {len(sync_status['new_files'])}ê°œ")
            st.write(f"- ë™ê¸°í™”ë¨: {len(sync_status['existing_files'])}ê°œ")
            st.write(f"- ê³ ì•„ ì²­í¬: {len(sync_status['orphaned_files'])}ê°œ")
            
            # ìƒì„¸ ì •ë³´
            if sync_status['new_files']:
                st.write("**ì¶”ê°€í•  ìƒˆ íŒŒì¼:**")
                for filename in sync_status['new_files']:
                    st.write(f"  - {filename}")
            
            if sync_status['orphaned_files']:
                st.write("**ê³ ì•„ íŒŒì¼ (raw_dataì— ì—†ìŒ):**")
                for filename in sync_status['orphaned_files']:
                    st.write(f"  - {filename}")
    
    st.markdown("---")
    
    # ë™ê¸°í™” ì„¤ì •
    st.subheader("âš™ï¸ ë™ê¸°í™” ì„¤ì •")
    
    col1, col2 = st.columns(2)
    
    with col1:
        sync_chunk_size = st.slider("ì²­í¬ í¬ê¸°", min_value=100, max_value=2000, value=500, step=50, key="sync_chunk_size")
    
    with col2:
        sync_chunk_overlap = st.slider("ì²­í¬ ì¤‘ì²©", min_value=0, max_value=500, value=100, step=25, key="sync_chunk_overlap")
    
    # Elasticsearch ì—°ë™ ì˜µì…˜
    st.subheader("ğŸ” Elasticsearch ì—°ë™")
    
    col1, col2 = st.columns(2)
    
    with col1:
        enable_elasticsearch = st.checkbox(
            "Elasticsearch ë³‘ë ¬ ì¸ë±ì‹± í™œì„±í™”", 
            value=False,
            help="ChromaDBì™€ í•¨ê»˜ Elasticsearchì—ë„ ë™ì‹œì— ì¸ë±ì‹±í•©ë‹ˆë‹¤. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì„ ìœ„í•´ í•„ìš”í•©ë‹ˆë‹¤."
        )
    
    with col2:
        if enable_elasticsearch:
            elasticsearch_manager = st.session_state.elasticsearch_manager
            es_connection_ok = elasticsearch_manager.check_connection()
            
            if es_connection_ok:
                st.success("âœ… Elasticsearch ì—°ê²° í™•ì¸")
                doc_count = elasticsearch_manager.get_document_count()
                st.info(f"í˜„ì¬ ë¬¸ì„œ ìˆ˜: {doc_count}")
            else:
                st.warning("âš ï¸ Elasticsearch ì—°ê²° ì‹¤íŒ¨")
                st.info("Dockerë¡œ Elasticsearchë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”")
    
    # ë™ê¸°í™” ì‹¤í–‰
    if st.button("ğŸš€ ë™ê¸°í™” ì‹¤í–‰", type="primary"):
        # Update workflow status to in_progress
        workflow_manager = st.session_state.workflow_manager
        workflow_manager.update_step_status("embedding", "in_progress", 0)
        
        with st.spinner("ë™ê¸°í™”ë¥¼ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤..."):
            # Check sync status first
            sync_status = sync_manager.compare_with_db(db_manager)
            new_files_count = len(sync_status['new_files'])
            
            workflow_manager.update_step_status("embedding", "in_progress", 25, {
                "new_files": new_files_count,
                "document_count": db_manager.get_document_count()
            })
            
            # Elasticsearch ë§¤ë‹ˆì € ì¤€ë¹„
            elasticsearch_mgr = None
            if enable_elasticsearch:
                elasticsearch_mgr = st.session_state.elasticsearch_manager
                if not elasticsearch_mgr.check_connection():
                    st.warning("Elasticsearch ì—°ê²°ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ChromaDBë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                    elasticsearch_mgr = None
            
            success = sync_manager.sync_with_db(
                db_manager=db_manager,
                chunk_size=sync_chunk_size,
                chunk_overlap=sync_chunk_overlap,
                elasticsearch_manager=elasticsearch_mgr
            )
            
            if success:
                # ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
                st.session_state.db = db_manager.db
                final_doc_count = db_manager.get_document_count()
                
                # Update workflow status to completed
                workflow_manager.update_step_status("embedding", "completed", 100, {
                    "document_count": final_doc_count,
                    "new_files": new_files_count
                })
                
                st.rerun()
            else:
                # Update workflow status to error
                workflow_manager.update_step_status("embedding", "error", 0, error="ë™ê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                st.error("ë™ê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    
    # ì¶”ê°€ ì •ë³´
    st.info("ğŸ’¡ **ì‚¬ìš©ë²•:** raw_data í´ë”ì— .txt ë˜ëŠ” .pdf íŒŒì¼ì„ ì¶”ê°€í•œ í›„ ë™ê¸°í™”ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
    st.info(f"ğŸ“‚ **ë¬¸ì„œ í´ë” ê²½ë¡œ:** {sync_manager.raw_data_path}")
    
    # ê¸°ì¡´ DB ê´€ë¦¬ ê¸°ëŠ¥
    if db_status["db_exists"]:
        st.markdown("---")
        st.subheader("ğŸ“‹ VectorDB ê´€ë¦¬")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if not db_status["db_loaded"]:
                if st.button("ğŸ“¥ ê¸°ì¡´ VectorDB ë¡œë“œ", type="primary"):
                    try:
                        with st.spinner("ê¸°ì¡´ VectorDBë¥¼ ë¡œë“œ ì¤‘ì…ë‹ˆë‹¤..."):
                            success = db_manager.load_existing_db()
                            
                            if success:
                                # ì„¸ì…˜ ìƒíƒœ ë™ê¸°í™”
                                st.session_state.db = db_manager.db
                                
                                # ë¬¸ì„œ ìˆ˜ ë‹¤ì‹œ ê³„ì‚°
                                doc_count = db_manager.get_document_count()
                                
                                st.success(f"âœ… ê¸°ì¡´ VectorDBë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤! (ë¬¸ì„œ ìˆ˜: {doc_count})")
                                
                                # ìƒíƒœ ìƒˆë¡œê³ ì¹¨ì„ ìœ„í•´ rerun
                                st.rerun()
                            else:
                                st.error("âŒ VectorDB ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. DB íŒŒì¼ì´ ì†ìƒë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                            
                    except Exception as e:
                        st.error(f"âŒ VectorDB ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        
        with col2:
            if st.button("ğŸ“‹ ì €ì¥ëœ ë¬¸ì„œ ëª©ë¡ ë³´ê¸°"):
                with st.spinner("ë¬¸ì„œ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                    files_in_db = db_manager.get_files_in_db()
                    
                    if files_in_db:
                        st.subheader("ğŸ“š ì €ì¥ëœ íŒŒì¼ ëª©ë¡")
                        st.write(f"ì´ {len(files_in_db)}ê°œì˜ íŒŒì¼ì´ ì €ì¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
                        st.write(f"ì´ ë¬¸ì„œ ì²­í¬ ìˆ˜: {db_status['document_count']}ê°œ")
                        
                        # íŒŒì¼ ëª©ë¡ í‘œì‹œ
                        for i, filename in enumerate(files_in_db, 1):
                            st.write(f"{i}. {filename}")
                    else:
                        st.warning("ì €ì¥ëœ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

with tab3:
    st.header("ğŸ” í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰")
    
    # Initialize hybrid search manager
    db_manager = st.session_state.db_manager
    elasticsearch_manager = st.session_state.elasticsearch_manager
    
    if st.session_state.hybrid_search_manager is None and st.session_state.db is not None:
        st.session_state.hybrid_search_manager = HybridSearchManager(
            chroma_manager=db_manager,
            elasticsearch_manager=elasticsearch_manager
        )
    
    # Initialize SearchParameterOptimizer
    if not hasattr(st.session_state, 'search_optimizer') or st.session_state.search_optimizer is None:
        if st.session_state.hybrid_search_manager is not None:
            st.session_state.search_optimizer = SearchParameterOptimizer()
    
    hybrid_search_manager = st.session_state.hybrid_search_manager
    
    if st.session_state.db is None:
        st.warning("ë¨¼ì € 'ë¬¸ì„œ ì²­í‚¹ ë° ì¸ë±ì‹±' íƒ­ì—ì„œ ë¬¸ì„œë¥¼ ë™ê¸°í™”í•´ ì£¼ì„¸ìš”.")
    else:
        # Search system status
        st.subheader("ğŸ” ê²€ìƒ‰ ì‹œìŠ¤í…œ ìƒíƒœ")
        
        if hybrid_search_manager:
            search_status = hybrid_search_manager.get_search_status()
            availability = search_status['availability']
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("Vector ê²€ìƒ‰", "âœ… ì‚¬ìš© ê°€ëŠ¥" if availability['vector_search'] else "âŒ ì‚¬ìš© ë¶ˆê°€")
                if availability['vector_search']:
                    chroma_status = search_status['chromadb_status']
                    st.info(f"ë¬¸ì„œ ìˆ˜: {chroma_status['document_count']}")
            
            with col2:
                st.metric("BM25 ê²€ìƒ‰", "âœ… ì‚¬ìš© ê°€ëŠ¥" if availability['bm25_search'] else "âŒ ì‚¬ìš© ë¶ˆê°€")
                if availability['bm25_search']:
                    es_status = search_status['elasticsearch_status']
                    st.info(f"ë¬¸ì„œ ìˆ˜: {es_status['document_count']}")
                else:
                    st.warning("Elasticsearch ì—°ê²° í•„ìš”")
            
            with col3:
                st.metric("í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰", "âœ… ì‚¬ìš© ê°€ëŠ¥" if availability['hybrid_search'] else "âŒ ì‚¬ìš© ë¶ˆê°€")
                if availability['hybrid_search']:
                    st.success("BM25 + Vector ìœµí•© ê²€ìƒ‰")
                else:
                    st.warning("ChromaDBì™€ Elasticsearch ëª¨ë‘ í•„ìš”")
        
        st.markdown("---")
        
        # Search configuration
        st.subheader("âš™ï¸ ê²€ìƒ‰ ì„¤ì •")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            search_type = st.selectbox(
                "ê²€ìƒ‰ ë°©ë²•",
                ["hybrid", "vector", "bm25"],
                index=0,
                help="hybrid: BM25+Vector ìœµí•©, vector: ì˜ë¯¸ ê²€ìƒ‰, bm25: í‚¤ì›Œë“œ ê²€ìƒ‰"
            )
        
        with col2:
            search_k = st.slider("ê²€ìƒ‰ ê²°ê³¼ ìˆ˜", min_value=1, max_value=20, value=5)
        
        with col3:
            if search_type == "hybrid":
                rrf_k = st.slider("RRF ìƒìˆ˜", min_value=10, max_value=100, value=60, 
                                help="Reciprocal Rank Fusion ìƒìˆ˜ (ë‚®ì„ìˆ˜ë¡ ìƒìœ„ ê²°ê³¼ ê°•ì¡°)")
        
        # Weight optimization controls for hybrid search
        if search_type == "hybrid" and hybrid_search_manager:
            st.markdown("---")
            st.subheader("âš–ï¸ ê²€ìƒ‰ ê°€ì¤‘ì¹˜ ìµœì í™”")
            
            # Get current optimizer settings
            optimizer = hybrid_search_manager.parameter_optimizer
            current_weights = optimizer.current_weights
            
            # Weight mode selection
            weight_mode = st.radio(
                "ê°€ì¤‘ì¹˜ ì¡°ì • ëª¨ë“œ",
                ["auto", "manual"],
                index=0 if current_weights['mode'] == 'auto' else 1,
                help="auto: ì¿¼ë¦¬ì— ë”°ë¼ ìë™ ìµœì í™”, manual: ìˆ˜ë™ ì¡°ì •",
                horizontal=True
            )
            
            if weight_mode == "manual":
                st.write("**ìˆ˜ë™ ê°€ì¤‘ì¹˜ ì¡°ì •:**")
                
                # Weight control sliders
                weight_col1, weight_col2 = st.columns(2)
                
                with weight_col1:
                    bm25_weight = st.slider(
                        "BM25 ê°€ì¤‘ì¹˜ (í‚¤ì›Œë“œ ê²€ìƒ‰)",
                        min_value=0.0, max_value=1.0, 
                        value=current_weights['bm25_weight'],
                        step=0.1,
                        help="í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ì˜ ì¤‘ìš”ë„"
                    )
                
                with weight_col2:
                    vector_weight = st.slider(
                        "Vector ê°€ì¤‘ì¹˜ (ì˜ë¯¸ ê²€ìƒ‰)",
                        min_value=0.0, max_value=1.0,
                        value=current_weights['vector_weight'],
                        step=0.1,
                        help="ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ì˜ ì¤‘ìš”ë„"
                    )
                
                # Weight normalization display
                total_weight = bm25_weight + vector_weight
                if total_weight > 0:
                    norm_bm25 = bm25_weight / total_weight
                    norm_vector = vector_weight / total_weight
                    st.info(f"ì •ê·œí™”ëœ ê°€ì¤‘ì¹˜: BM25 {norm_bm25:.3f}, Vector {norm_vector:.3f}")
                
                # Preset buttons
                st.write("**ë¹ ë¥¸ ì„¤ì •:**")
                preset_col1, preset_col2, preset_col3, preset_col4 = st.columns(4)
                
                with preset_col1:
                    if st.button("ê· í˜• (0.5/0.5)"):
                        optimizer.apply_preset("ê· í˜•")
                        st.rerun()
                
                with preset_col2:
                    if st.button("í‚¤ì›Œë“œ ì¤‘ì‹¬ (0.7/0.3)"):
                        optimizer.apply_preset("í‚¤ì›Œë“œ ì¤‘ì‹¬")
                        st.rerun()
                
                with preset_col3:
                    if st.button("ì˜ë¯¸ ì¤‘ì‹¬ (0.3/0.7)"):
                        optimizer.apply_preset("ì˜ë¯¸ ì¤‘ì‹¬")
                        st.rerun()
                
                with preset_col4:
                    if st.button("ê¸°ë³¸ê°’ ë³µì›"):
                        optimizer.reset_to_default()
                        st.rerun()
                
                # Apply weight changes
                if st.button("ê°€ì¤‘ì¹˜ ì ìš©", type="primary"):
                    if optimizer.set_weights(bm25_weight, vector_weight, mode="manual"):
                        st.success("ê°€ì¤‘ì¹˜ê°€ ì„±ê³µì ìœ¼ë¡œ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤!")
                        st.rerun()
                    else:
                        st.error("ê°€ì¤‘ì¹˜ ì ìš©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            
            else:  # auto mode
                st.write("**ìë™ ìµœì í™” ëª¨ë“œ:**")
                st.info("ğŸ¤– ì¿¼ë¦¬ ìœ í˜•ì— ë”°ë¼ ìë™ìœ¼ë¡œ ìµœì  ê°€ì¤‘ì¹˜ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.")
                
                # Show query type analysis if available
                if hasattr(st.session_state, 'last_query_type') and st.session_state.last_query_type:
                    st.write(f"**ë§ˆì§€ë§‰ ì¿¼ë¦¬ ìœ í˜•:** {st.session_state.last_query_type}")
                
                # Apply auto mode
                if current_weights['mode'] != 'auto':
                    if st.button("ìë™ ëª¨ë“œ í™œì„±í™”", type="primary"):
                        optimizer.set_weights(
                            current_weights['bm25_weight'], 
                            current_weights['vector_weight'], 
                            mode="auto"
                        )
                        st.success("ìë™ ëª¨ë“œê°€ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
                        st.rerun()
            
            # Current weight display
            st.write("**í˜„ì¬ ì„¤ì •:**")
            display_col1, display_col2, display_col3 = st.columns(3)
            
            with display_col1:
                st.metric("BM25 ê°€ì¤‘ì¹˜", f"{current_weights['bm25_weight']:.3f}")
            with display_col2:
                st.metric("Vector ê°€ì¤‘ì¹˜", f"{current_weights['vector_weight']:.3f}")
            with display_col3:
                st.metric("ëª¨ë“œ", current_weights['mode'])
        
        # Search interface
        st.subheader("ğŸ” ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
        
        search_query = st.text_input("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”:", placeholder="ì˜ˆ: ë²•ì¸ì„¸ìœ¨ì´ ì–¼ë§ˆì¸ê°€ìš”?")
        
        if st.button("ğŸ” ê²€ìƒ‰ ì‹¤í–‰", type="primary") and search_query:
            if hybrid_search_manager:
                try:
                    with st.spinner("ê²€ìƒ‰ ì¤‘..."):
                        # Execute search
                        if search_type == "hybrid":
                            results, search_info = hybrid_search_manager.search(
                                search_query, search_type, search_k, rrf_k
                            )
                        else:
                            results, search_info = hybrid_search_manager.search(
                                search_query, search_type, search_k
                            )
                        
                        # Display search info
                        st.subheader("ğŸ“Š ê²€ìƒ‰ ê²°ê³¼ ì •ë³´")
                        
                        if search_type == "hybrid":
                            # Enhanced info display for hybrid search
                            info_col1, info_col2, info_col3, info_col4 = st.columns(4)
                            
                            with info_col1:
                                st.metric("ê²€ìƒ‰ ë°©ë²•", search_info.get('search_type', search_type))
                                st.metric("ì´ ê²°ê³¼ ìˆ˜", len(results))
                            
                            with info_col2:
                                if 'search_methods_used' in search_info:
                                    methods = ", ".join(search_info['search_methods_used'])
                                    st.metric("ì‚¬ìš©ëœ ë°©ë²•", methods)
                                if 'rrf_k' in search_info:
                                    st.metric("RRF ìƒìˆ˜", search_info['rrf_k'])
                            
                            with info_col3:
                                if 'bm25_weight' in search_info:
                                    st.metric("BM25 ê°€ì¤‘ì¹˜", f"{search_info['bm25_weight']:.3f}")
                                if 'vector_results_count' in search_info:
                                    st.metric("Vector ê²°ê³¼", search_info['vector_results_count'])
                            
                            with info_col4:
                                if 'vector_weight' in search_info:
                                    st.metric("Vector ê°€ì¤‘ì¹˜", f"{search_info['vector_weight']:.3f}")
                                if 'bm25_results_count' in search_info:
                                    st.metric("BM25 ê²°ê³¼", search_info['bm25_results_count'])
                            
                            # Display weight mode information
                            if 'weight_mode' in search_info:
                                mode_text = "ğŸ¤– ìë™ ìµœì í™”" if search_info['weight_mode'] == 'auto' else "âš™ï¸ ìˆ˜ë™ ì„¤ì •"
                                st.info(f"**ê°€ì¤‘ì¹˜ ëª¨ë“œ:** {mode_text}")
                                
                                # Show query type if auto mode
                                if search_info['weight_mode'] == 'auto' and hasattr(st.session_state, 'last_query_type'):
                                    st.info(f"**ê°ì§€ëœ ì¿¼ë¦¬ ìœ í˜•:** {st.session_state.last_query_type}")
                        else:
                            # Standard info display for non-hybrid search
                            info_col1, info_col2 = st.columns(2)
                            
                            with info_col1:
                                st.metric("ê²€ìƒ‰ ë°©ë²•", search_info.get('search_type', search_type))
                                st.metric("ì´ ê²°ê³¼ ìˆ˜", len(results))
                            
                            with info_col2:
                                if 'search_methods_used' in search_info:
                                    methods = ", ".join(search_info['search_methods_used'])
                                    st.metric("ì‚¬ìš©ëœ ë°©ë²•", methods)
                        
                        # Display results
                        if results:
                            st.subheader("ğŸ¯ ê²€ìƒ‰ ê²°ê³¼")
                            
                            for i, result in enumerate(results):
                                with st.expander(f"ê²°ê³¼ {i+1}: {result['filename']} (ì ìˆ˜: {result['score']:.3f})"):
                                    # Result metadata
                                    col1, col2 = st.columns(2)
                                    with col1:
                                        st.write(f"**íŒŒì¼ëª…:** {result['filename']}")
                                        st.write(f"**ê²€ìƒ‰ ìœ í˜•:** {result['search_type']}")
                                    with col2:
                                        st.write(f"**ì ìˆ˜:** {result['score']:.3f}")
                                        if 'hybrid_rank' in result:
                                            st.write(f"**í•˜ì´ë¸Œë¦¬ë“œ ìˆœìœ„:** {result['hybrid_rank']}")
                                    
                                    # Show ranking details for hybrid search
                                    if search_type == "hybrid" and 'rrf_score' in result:
                                        st.write("**ìƒì„¸ ì ìˆ˜:**")
                                        score_col1, score_col2, score_col3 = st.columns(3)
                                        with score_col1:
                                            if result.get('vector_rank'):
                                                st.write(f"Vector ìˆœìœ„: {result['vector_rank']}")
                                        with score_col2:
                                            if result.get('bm25_rank'):
                                                st.write(f"BM25 ìˆœìœ„: {result['bm25_rank']}")
                                        with score_col3:
                                            st.write(f"RRF ì ìˆ˜: {result['rrf_score']:.4f}")
                                    
                                    # Content
                                    st.write("**ë‚´ìš©:**")
                                    st.write(result['content'])
                        else:
                            st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                            
                except Exception as e:
                    st.error(f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            else:
                st.error("í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ë§¤ë‹ˆì €ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # Search comparison tool
        if hybrid_search_manager and search_query:
            st.markdown("---")
            st.subheader("ğŸ“Š ê²€ìƒ‰ ë°©ë²• ë¹„êµ")
            
            if st.button("ğŸ” ëª¨ë“  ê²€ìƒ‰ ë°©ë²• ë¹„êµ", type="secondary"):
                try:
                    with st.spinner("ëª¨ë“  ê²€ìƒ‰ ë°©ë²•ìœ¼ë¡œ ê²€ìƒ‰ ì¤‘..."):
                        # Execute all search types
                        vector_results, vector_info = hybrid_search_manager.search(search_query, "vector", search_k)
                        bm25_results, bm25_info = hybrid_search_manager.search(search_query, "bm25", search_k)
                        hybrid_results, hybrid_info = hybrid_search_manager.search(search_query, "hybrid", search_k, 60)
                        
                        # Display comparison
                        st.write("**ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ ë¹„êµ:**")
                        comp_col1, comp_col2, comp_col3 = st.columns(3)
                        
                        with comp_col1:
                            st.metric("Vector ê²€ìƒ‰", len(vector_results))
                        with comp_col2:
                            st.metric("BM25 ê²€ìƒ‰", len(bm25_results))
                        with comp_col3:
                            st.metric("í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰", len(hybrid_results))
                        
                        # Show top results from each method
                        st.write("**ê° ê²€ìƒ‰ ë°©ë²•ì˜ ìƒìœ„ 3ê°œ ê²°ê³¼:**")
                        
                        for search_name, results in [("Vector", vector_results[:3]), ("BM25", bm25_results[:3]), ("Hybrid", hybrid_results[:3])]:
                            st.write(f"**{search_name} ê²€ìƒ‰:**")
                            for i, result in enumerate(results, 1):
                                st.write(f"{i}. {result['filename']} (ì ìˆ˜: {result['score']:.3f})")
                                st.write(f"   {result['content'][:100]}...")
                            st.write("")
                        
                except Exception as e:
                    st.error(f"ê²€ìƒ‰ ë¹„êµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

with tab4:
    st.header("ğŸ“Š ê²€ìƒ‰ í’ˆì§ˆ ë¶„ì„")
    
    # í’ˆì§ˆ ë¶„ì„ì„ ìœ„í•œ ì„¤ì •
    st.subheader("ğŸ”§ ë¶„ì„ ì„¤ì •")
    
    col1, col2 = st.columns(2)
    
    with col1:
        analysis_query = st.text_input(
            "ë¶„ì„í•  ì¿¼ë¦¬ ì…ë ¥",
            placeholder="ì˜ˆ: ì†Œë“ì„¸ìœ¨ì´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
            help="í’ˆì§ˆ ë¶„ì„ì„ ìœ„í•œ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
        )
        
        k_values = st.multiselect(
            "ë¶„ì„í•  K ê°’ ì„ íƒ",
            [1, 3, 5, 10, 20],
            default=[3, 5, 10],
            help="ìƒìœ„ ëª‡ ê°œì˜ ê²°ê³¼ë¥¼ ë¶„ì„í• ì§€ ì„ íƒí•˜ì„¸ìš”"
        )
    
    with col2:
        # Ground truth ë¬¸ì„œ ì„ íƒ (ì„ íƒì )
        st.subheader("ê´€ë ¨ ë¬¸ì„œ ì„ íƒ (ì„ íƒì‚¬í•­)")
        
        # ë¬¸ì„œ ì„ íƒ ë°©ë²• ì„ íƒ
        selection_method = st.radio(
            "ë¬¸ì„œ ì„ íƒ ë°©ë²•:",
            ["ë¬¸ì„œ ëª©ë¡ì—ì„œ ì„ íƒ", "ì§ì ‘ ID ì…ë ¥"],
            help="ë¬¸ì„œ ëª©ë¡ì—ì„œ ì„ íƒí•˜ê±°ë‚˜ ì§ì ‘ IDë¥¼ ì…ë ¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        )
        
        ground_truth = None
        
        if selection_method == "ë¬¸ì„œ ëª©ë¡ì—ì„œ ì„ íƒ":
            # DB ì—°ê²° ìƒíƒœ í™•ì¸ ë° ë³´ì¥
            ensure_db_connection()
            
            # ChromaDBì—ì„œ ë¬¸ì„œ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            db_manager = st.session_state.get('db_manager')
            if db_manager and db_manager.db and hasattr(db_manager, 'get_document_metadata'):
                try:
                    doc_metadata = db_manager.get_document_metadata()
                    
                    if doc_metadata:
                        # ë¬¸ì„œ í•„í„°ë§ ê¸°ëŠ¥
                        search_filter = st.text_input(
                            "ë¬¸ì„œ ê²€ìƒ‰ (íŒŒì¼ëª…ìœ¼ë¡œ í•„í„°ë§):",
                            placeholder="ì˜ˆ: ì„¸ë²•, ì†Œë“ì„¸, 2025...",
                            help="ì…ë ¥í•œ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¬¸ì„œë§Œ í‘œì‹œí•©ë‹ˆë‹¤."
                        )
                        
                        # í•„í„°ë§ëœ ë¬¸ì„œ ëª©ë¡ ìƒì„±
                        filtered_metadata = doc_metadata
                        if search_filter.strip():
                            filtered_metadata = [
                                doc for doc in doc_metadata 
                                if search_filter.lower() in doc['filename'].lower() 
                                or search_filter.lower() in doc['preview'].lower()
                            ]
                        
                        if filtered_metadata:
                            # ë¬¸ì„œ ì„ íƒì„ ìœ„í•œ ì˜µì…˜ ìƒì„±
                            doc_options = {}
                            for doc in filtered_metadata:
                                display_name = f"ğŸ“„ {doc['filename']} (ID: {doc['id'][:8]}...)"
                                doc_options[display_name] = doc['id']
                            
                            st.write(f"**ì‚¬ìš© ê°€ëŠ¥í•œ ë¬¸ì„œ: {len(filtered_metadata)}ê°œ**")
                            
                            selected_docs = st.multiselect(
                                "ê´€ë ¨ ë¬¸ì„œ ì„ íƒ:",
                                options=list(doc_options.keys()),
                                help="ì¿¼ë¦¬ì™€ ê´€ë ¨ìˆëŠ” ë¬¸ì„œë“¤ì„ ì„ íƒí•˜ì„¸ìš”. ì„ íƒí•œ ë¬¸ì„œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì •í™•í•œ í’ˆì§ˆ ì§€í‘œë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."
                            )
                            
                            # ë¬¸ì„œ ë¯¸ë¦¬ë³´ê¸° í† ê¸€
                            if st.checkbox("ğŸ“– ë¬¸ì„œ ë¯¸ë¦¬ë³´ê¸° í‘œì‹œ", help="ì„ íƒí•˜ê¸° ì „ì— ë¬¸ì„œ ë‚´ìš©ì„ ë¯¸ë¦¬ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."):
                                st.write("**ë¬¸ì„œ ë¯¸ë¦¬ë³´ê¸°:**")
                                for doc in filtered_metadata:
                                    with st.expander(f"ğŸ“„ {doc['filename']} (ID: {doc['id'][:8]}...)"):
                                        st.write(f"**íŒŒì¼ëª…:** {doc['filename']}")
                                        st.write(f"**ë¬¸ì„œ ID:** `{doc['id']}`")
                                        st.write(f"**íŒŒì¼ ê²½ë¡œ:** {doc['source']}")
                                        st.write("**ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°:**")
                                        st.write(doc['preview'])
                        else:
                            st.warning(f"'{search_filter}' í‚¤ì›Œë“œì— í•´ë‹¹í•˜ëŠ” ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
                            selected_docs = []
                        
                        if selected_docs:
                            ground_truth = [doc_options[doc] for doc in selected_docs]
                            st.success(f"âœ… ì„ íƒëœ ë¬¸ì„œ: {len(ground_truth)}ê°œ")
                            
                            # ì„ íƒëœ ë¬¸ì„œ ì •ë³´ í‘œì‹œ
                            with st.expander("ì„ íƒëœ ë¬¸ì„œ ìƒì„¸ ì •ë³´"):
                                for doc_display, doc_id in zip(selected_docs, ground_truth):
                                    doc_info = next((d for d in doc_metadata if d['id'] == doc_id), None)
                                    if doc_info:
                                        st.write(f"**{doc_info['filename']}**")
                                        st.write(f"- ID: `{doc_info['id']}`")
                                        st.write(f"- ë¯¸ë¦¬ë³´ê¸°: {doc_info['preview']}")
                                        st.write("---")
                    else:
                        st.warning("ì¸ë±ì‹±ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. 'ë™ê¸°í™”' íƒ­ì—ì„œ ë¬¸ì„œë¥¼ ë¨¼ì € ì¸ë±ì‹±í•´ì£¼ì„¸ìš”.")
                except Exception as e:
                    st.error(f"ë¬¸ì„œ ëª©ë¡ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
                    st.info("ì§ì ‘ ID ì…ë ¥ ë°©ì‹ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”.")
            else:
                st.warning("ë¬¸ì„œ ë°ì´í„°ë² ì´ìŠ¤ê°€ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'ë™ê¸°í™”' íƒ­ì—ì„œ ë¨¼ì € ì´ˆê¸°í™”í•´ì£¼ì„¸ìš”.")
        
        else:  # ì§ì ‘ ID ì…ë ¥
            ground_truth_input = st.text_area(
                "ê´€ë ¨ ë¬¸ì„œ ID ì§ì ‘ ì…ë ¥",
                placeholder="doc1, doc2, doc3 (ì‰¼í‘œë¡œ êµ¬ë¶„)",
                help="ì •ë‹µ ë¬¸ì„œ IDë¥¼ ì§ì ‘ ì…ë ¥í•˜ì„¸ìš”. ì—†ìœ¼ë©´ ê¸°ë³¸ì ì¸ ë¶„ì„ë§Œ ìˆ˜í–‰ë©ë‹ˆë‹¤."
            )
            
            if ground_truth_input.strip():
                ground_truth = [doc.strip() for doc in ground_truth_input.split(',') if doc.strip()]
                st.info(f"ì…ë ¥ëœ ë¬¸ì„œ: {len(ground_truth)}ê°œ")
    
    # ë¶„ì„ ì‹¤í–‰
    if st.button("ğŸ” í’ˆì§ˆ ë¶„ì„ ì‹¤í–‰", type="primary"):
        if not analysis_query.strip():
            st.error("ë¶„ì„í•  ì¿¼ë¦¬ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        elif not st.session_state.hybrid_search_manager:
            st.error("í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ë§¤ë‹ˆì €ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰' íƒ­ì—ì„œ ë¨¼ì € ì´ˆê¸°í™”í•´ì£¼ì„¸ìš”.")
        else:
            with st.spinner("ê²€ìƒ‰ í’ˆì§ˆì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                try:
                    # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ë§¤ë‹ˆì € ê°€ì ¸ì˜¤ê¸°
                    hybrid_manager = st.session_state.hybrid_search_manager
                    
                    # ê²€ìƒ‰ ê°€ìš©ì„± í™•ì¸
                    availability = hybrid_manager.check_search_availability()
                    
                    # ë‹¤ì–‘í•œ ê²€ìƒ‰ ë°©ë²•ìœ¼ë¡œ ê²€ìƒ‰ ìˆ˜í–‰
                    search_results = {}
                    
                    if availability['vector_search']:
                        try:
                            vector_results = hybrid_manager.vector_search(analysis_query, k=max(k_values) if k_values else 10)
                            search_results['Vector Search'] = vector_results
                        except Exception as e:
                            st.warning(f"Vector ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
                    
                    if availability['bm25_search']:
                        try:
                            bm25_results = hybrid_manager.bm25_search(analysis_query, k=max(k_values) if k_values else 10)
                            search_results['BM25 Search'] = bm25_results
                        except Exception as e:
                            st.warning(f"BM25 ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
                    
                    if availability['hybrid_search']:
                        try:
                            # í˜„ì¬ ìµœì í™” ì„¤ì • ì‚¬ìš©
                            optimizer = hybrid_manager.parameter_optimizer
                            if optimizer.mode == "auto":
                                weights = optimizer.get_auto_weights(analysis_query)
                            else:
                                weights = {
                                    "bm25_weight": optimizer.bm25_weight, 
                                    "vector_weight": optimizer.vector_weight
                                }
                            
                            hybrid_results = hybrid_manager.hybrid_search(
                                analysis_query, 
                                k=max(k_values) if k_values else 10,
                                bm25_weight=weights["bm25_weight"],
                                vector_weight=weights["vector_weight"]
                            )
                            search_results['Hybrid Search'] = hybrid_results
                        except Exception as e:
                            st.warning(f"í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
                    
                    # ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš° í’ˆì§ˆ ë¶„ì„ ëŒ€ì‹œë³´ë“œ í‘œì‹œ
                    if search_results:
                        create_quality_analysis_dashboard(
                            query=analysis_query,
                            search_results=search_results,
                            ground_truth=ground_truth
                        )
                    else:
                        st.error("ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²€ìƒ‰ ì‹œìŠ¤í…œì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
                
                except Exception as e:
                    st.error(f"í’ˆì§ˆ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    # ë„ì›€ë§ ì„¹ì…˜
    with st.expander("ğŸ“– í’ˆì§ˆ ë¶„ì„ ë„ì›€ë§"):
        st.markdown("""
        ### í’ˆì§ˆ ë¶„ì„ ì§€í‘œ ì„¤ëª…
        
        **Precision@K**: ìƒìœ„ Kê°œ ê²°ê³¼ ì¤‘ ê´€ë ¨ ìˆëŠ” ë¬¸ì„œì˜ ë¹„ìœ¨
        - ê°’ì´ ë†’ì„ìˆ˜ë¡ ì •í™•í•œ ê²°ê³¼ë¥¼ ìƒìœ„ì— ë°°ì¹˜
        
        **Recall@K**: ì „ì²´ ê´€ë ¨ ë¬¸ì„œ ì¤‘ ìƒìœ„ Kê°œì— í¬í•¨ëœ ë¬¸ì„œì˜ ë¹„ìœ¨  
        - ê°’ì´ ë†’ì„ìˆ˜ë¡ ê´€ë ¨ ë¬¸ì„œë¥¼ ë†“ì¹˜ì§€ ì•ŠìŒ
        
        **NDCG@K**: ìˆœìœ„ë¥¼ ê³ ë ¤í•œ ì •ê·œí™”ëœ ëˆ„ì  ì´ë“
        - ìƒìœ„ ê²°ê³¼ì¼ìˆ˜ë¡ ë†’ì€ ê°€ì¤‘ì¹˜, 0~1 ì‚¬ì´ ê°’
        
        **MRR**: ì²« ë²ˆì§¸ ê´€ë ¨ ë¬¸ì„œì˜ ìˆœìœ„ ì—­ìˆ˜
        - ê´€ë ¨ ë¬¸ì„œê°€ ìƒìœ„ì— ìˆì„ìˆ˜ë¡ ë†’ì€ ê°’
        
        ### ì‚¬ìš© íŒ
        1. **ì •ë‹µ ë¬¸ì„œ ID**ë¥¼ ì…ë ¥í•˜ë©´ ë” ì •í™•í•œ ë¶„ì„ ê°€ëŠ¥
        2. **ì—¬ëŸ¬ K ê°’**ì„ ì„ íƒí•´ ë‹¤ì–‘í•œ ê´€ì ì—ì„œ ë¶„ì„
        3. **ê²€ìƒ‰ ë°©ë²•ë³„ ë¹„êµ**ë¡œ ìµœì  ë°©ë²• ì„ íƒ
        """)

with tab5:
    st.header("âš–ï¸ ê°€ì¤‘ì¹˜ ìµœì í™”")
    
    # Weight optimization experiment and visualization
    weight_experiment = get_weight_experiment()
    viz_manager = get_visualization_manager()
    
    # Check DB connection
    if st.session_state.db is None or not hasattr(st.session_state, 'hybrid_search_manager'):
        st.warning("ë¨¼ì € 'ë¬¸ì„œ ì²­í‚¹ ë° ì¸ë±ì‹±' íƒ­ì—ì„œ ë¬¸ì„œë¥¼ ë™ê¸°í™”í•˜ê³  í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì„ ì„¤ì •í•´ ì£¼ì„¸ìš”.")
    else:
        hybrid_search_manager = st.session_state.hybrid_search_manager
        
        # Ensure SearchParameterOptimizer is initialized
        if not hasattr(st.session_state, 'search_optimizer') or st.session_state.search_optimizer is None:
            st.session_state.search_optimizer = SearchParameterOptimizer()
        
        # Sidebar for experiment control
        with st.sidebar:
            st.subheader("ğŸ§ª ì‹¤í—˜ ì„¤ì •")
            
            # Log file path
            log_path = st.text_input("ë¡œê·¸ íŒŒì¼ ê²½ë¡œ", value="./weight_search.log")
            
            # Clear log button
            if st.button("ğŸ—‘ï¸ ë¡œê·¸ íŒŒì¼ ì‚­ì œ"):
                if weight_experiment.clear_experiment_log():
                    st.success("ë¡œê·¸ íŒŒì¼ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
                else:
                    st.error("ë¡œê·¸ íŒŒì¼ ì‚­ì œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            
            st.markdown("---")
            
            # Experiment parameters
            st.subheader("ì‹¤í—˜ íŒŒë¼ë¯¸í„°")
            min_weight = st.slider("ìµœì†Œ ê°€ì¤‘ì¹˜", 0.0, 1.0, 0.0, 0.1)
            max_weight = st.slider("ìµœëŒ€ ê°€ì¤‘ì¹˜", 0.0, 1.0, 1.0, 0.1) 
            step_size = st.selectbox("ìŠ¤í… í¬ê¸°", [0.1, 0.2, 0.25, 0.5], index=0)
            max_workers = st.slider("ë³‘ë ¬ ì²˜ë¦¬ ìˆ˜", 1, 5, 3)
        
        # Main content area
        col1, col2 = st.columns([2, 1])
        
        with col1:
            # Tab selection for manual vs automated
            tuning_mode = st.radio(
                "íŠœë‹ ëª¨ë“œ ì„ íƒ:",
                ["ğŸ›ï¸ ìˆ˜ë™ íŠœë‹", "ğŸ§ª ìë™ ì‹¤í—˜"],
                horizontal=True
            )
            
            if tuning_mode == "ğŸ›ï¸ ìˆ˜ë™ íŠœë‹":
                st.subheader("ğŸ›ï¸ ìˆ˜ë™ ê°€ì¤‘ì¹˜ íŠœë‹")
                
                # Check for preset values first
                if 'preset_values' in st.session_state and st.session_state.preset_values:
                    current_bm25, current_vector = st.session_state.preset_values
                    # Clear preset values after using them
                    st.session_state.preset_values = None
                else:
                    # Get current optimizer settings
                    search_optimizer = st.session_state.get('search_optimizer')
                    if search_optimizer:
                        current_bm25 = search_optimizer.bm25_weight
                        current_vector = search_optimizer.vector_weight
                    else:
                        current_bm25 = 0.5
                        current_vector = 0.5
                
                # Manual weight sliders
                manual_col1, manual_col2 = st.columns(2)
                
                with manual_col1:
                    manual_bm25 = st.slider(
                        "BM25 ê°€ì¤‘ì¹˜",
                        min_value=0.0,
                        max_value=1.0,
                        value=current_bm25,
                        step=0.05,
                        key="manual_bm25"
                    )
                
                with manual_col2:
                    manual_vector = st.slider(
                        "ë²¡í„° ê°€ì¤‘ì¹˜", 
                        min_value=0.0,
                        max_value=1.0,
                        value=current_vector,
                        step=0.05,
                        key="manual_vector"
                    )
                
                # Normalized weights display
                total_weight = manual_bm25 + manual_vector
                if total_weight > 0:
                    norm_bm25 = manual_bm25 / total_weight
                    norm_vector = manual_vector / total_weight
                else:
                    norm_bm25 = 0.5
                    norm_vector = 0.5
                
                st.info(f"ì •ê·œí™”ëœ ê°€ì¤‘ì¹˜: BM25 {norm_bm25:.3f} | ë²¡í„° {norm_vector:.3f}")
                
                # Weight presets
                st.write("**ê°€ì¤‘ì¹˜ í”„ë¦¬ì…‹:**")
                preset_cols = st.columns(5)
                
                presets = {
                    "ê· í˜•": (0.5, 0.5),
                    "í‚¤ì›Œë“œ": (0.7, 0.3), 
                    "ì˜ë¯¸": (0.3, 0.7),
                    "BM25": (1.0, 0.0),
                    "ë²¡í„°": (0.0, 1.0)
                }
                
                for i, (preset_name, (bm25, vector)) in enumerate(presets.items()):
                    with preset_cols[i]:
                        if st.button(f"{preset_name}", key=f"preset_{preset_name}"):
                            # Immediately apply preset to SearchParameterOptimizer
                            search_optimizer = st.session_state.get('search_optimizer')
                            if search_optimizer:
                                success = search_optimizer.set_weights(bm25, vector, mode="manual")
                                if success:
                                    st.success(f"âœ… {preset_name} í”„ë¦¬ì…‹ ì ìš©! (BM25: {search_optimizer.bm25_weight:.3f}, ë²¡í„°: {search_optimizer.vector_weight:.3f})")
                                else:
                                    st.error("âŒ í”„ë¦¬ì…‹ ì ìš©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                            # Also store for slider update
                            st.session_state.preset_values = (bm25, vector)
                            st.rerun()
                
                # Apply weights button
                if st.button("âš™ï¸ ê°€ì¤‘ì¹˜ ì ìš©", type="primary"):
                    if search_optimizer:
                        success = search_optimizer.set_weights(manual_bm25, manual_vector, mode="manual")
                        if success:
                            # Display the actual weights stored in optimizer
                            actual_bm25 = search_optimizer.bm25_weight
                            actual_vector = search_optimizer.vector_weight
                            st.success(f"âœ… ê°€ì¤‘ì¹˜ê°€ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤! (BM25: {actual_bm25:.3f}, ë²¡í„°: {actual_vector:.3f})")
                        else:
                            st.error("âŒ ê°€ì¤‘ì¹˜ ì ìš©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                    else:
                        st.warning("ê²€ìƒ‰ ìµœì í™” ë§¤ë‹ˆì €ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                
                # Real-time test section
                st.markdown("---")
                st.subheader("ğŸ” ì‹¤ì‹œê°„ í…ŒìŠ¤íŠ¸")
                
                test_query = st.text_input(
                    "í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬:",
                    placeholder="ì˜ˆ: ì†Œë“ì„¸ ê³µì œ ë°©ë²•",
                    key="manual_test_query"
                )
                
                test_k = st.slider("ê²€ìƒ‰ ê²°ê³¼ ìˆ˜", 1, 10, 5, key="manual_test_k")
                
                if st.button("ğŸš€ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸", disabled=not test_query):
                    if test_query:
                        try:
                            start_time = time.time()
                            
                            # Apply current weights temporarily for test
                            # Use weights from search optimizer if available, otherwise use normalized UI weights
                            search_optimizer = st.session_state.get('search_optimizer')
                            if search_optimizer:
                                test_bm25 = search_optimizer.bm25_weight
                                test_vector = search_optimizer.vector_weight
                            else:
                                test_bm25 = norm_bm25
                                test_vector = norm_vector
                            
                            results, search_info = hybrid_search_manager.hybrid_search(
                                query=test_query,
                                k=test_k,
                                bm25_weight=test_bm25,
                                vector_weight=test_vector
                            )
                            
                            search_time = (time.time() - start_time) * 1000
                            
                            st.success(f"âœ… ê²€ìƒ‰ ì™„ë£Œ! ({search_time:.1f}ms, {len(results)}ê°œ ê²°ê³¼)")
                            st.info(f"ì‚¬ìš©ëœ ê°€ì¤‘ì¹˜: BM25 {test_bm25:.3f} | ë²¡í„° {test_vector:.3f}")
                            
                            # Display results
                            if results:
                                st.write("**ê²€ìƒ‰ ê²°ê³¼:**")
                                for i, result in enumerate(results, 1):
                                    with st.expander(f"{i}. {result.get('filename', 'Unknown')} (ì ìˆ˜: {result.get('score', 0):.3f})"):
                                        st.write(result.get('content', '')[:300] + "..." if len(result.get('content', '')) > 300 else result.get('content', ''))
                            else:
                                st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                                
                        except Exception as e:
                            st.error(f"ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
                
                # Performance comparison section
                st.markdown("---")
                st.subheader("ğŸ“Š ì„±ëŠ¥ ë¹„êµ")
                
                if st.button("ğŸ”¬ ë‹¤ì¤‘ ê°€ì¤‘ì¹˜ ë¹„êµ í…ŒìŠ¤íŠ¸"):
                    if test_query:
                        try:
                            comparison_results = []
                            test_weights = [
                                ("ê· í˜•", 0.5, 0.5),
                                ("í‚¤ì›Œë“œ ì¤‘ì‹¬", 0.7, 0.3),
                                ("ì˜ë¯¸ ì¤‘ì‹¬", 0.3, 0.7),
                                ("í˜„ì¬ ì„¤ì •", norm_bm25, norm_vector)
                            ]
                            
                            progress_bar = st.progress(0)
                            
                            for i, (name, bm25_w, vector_w) in enumerate(test_weights):
                                start_time = time.time()
                                
                                results, _ = hybrid_search_manager.hybrid_search(
                                    query=test_query,
                                    k=test_k,
                                    bm25_weight=bm25_w,
                                    vector_weight=vector_w
                                )
                                
                                search_time = (time.time() - start_time) * 1000
                                
                                comparison_results.append({
                                    'name': name,
                                    'bm25_weight': bm25_w,
                                    'vector_weight': vector_w,
                                    'result_count': len(results),
                                    'search_time_ms': search_time,
                                    'avg_score': np.mean([r.get('score', 0) for r in results]) if results else 0.0
                                })
                                
                                progress_bar.progress((i + 1) / len(test_weights))
                            
                            # Display comparison table
                            comparison_df = pd.DataFrame(comparison_results)
                            st.dataframe(
                                comparison_df[['name', 'bm25_weight', 'vector_weight', 'result_count', 'search_time_ms', 'avg_score']],
                                use_container_width=True
                            )
                            
                            # Best performer highlight
                            best_idx = comparison_df['avg_score'].idxmax()
                            best_result = comparison_df.iloc[best_idx]
                            st.success(f"ğŸ† ìµœê³  ì„±ëŠ¥: **{best_result['name']}** (í‰ê·  ì ìˆ˜: {best_result['avg_score']:.4f})")
                            
                        except Exception as e:
                            st.error(f"ë¹„êµ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
                    else:
                        st.warning("ë¨¼ì € í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            
            else:  # ìë™ ì‹¤í—˜ ëª¨ë“œ
                st.subheader("ğŸ¯ ìë™ ìµœì í™” ì‹¤í—˜")
                
                # Test queries input
                st.write("**í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ì„¤ì •:**")
                use_default_queries = st.checkbox("ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ì‚¬ìš©", value=True)
                
                if use_default_queries:
                    test_queries = weight_experiment.get_default_test_queries()
                    st.info(f"ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ {len(test_queries)}ê°œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                    
                    # Show default queries in expander
                    with st.expander("ê¸°ë³¸ ì¿¼ë¦¬ ëª©ë¡ ë³´ê¸°"):
                        for i, query in enumerate(test_queries, 1):
                            st.write(f"{i}. {query}")
                else:
                    custom_queries = st.text_area(
                        "ì»¤ìŠ¤í…€ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ (í•œ ì¤„ì— í•˜ë‚˜ì”©)",
                        placeholder="ì†Œë“ì„¸ ê³µì œ ë°©ë²•\në¶€ê°€ê°€ì¹˜ì„¸ ì‹ ê³  ê¸°í•œ\n...",
                        height=150
                    )
                    test_queries = [q.strip() for q in custom_queries.split('\n') if q.strip()]
                    
                    if not test_queries:
                        st.warning("í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                
                # Run experiment button
                if st.button("ğŸš€ ê°€ì¤‘ì¹˜ ìµœì í™” ì‹¤í—˜ ì‹¤í–‰", type="primary", disabled=not test_queries):
                    if test_queries:
                        # Generate weight combinations
                        weight_combinations = weight_experiment.generate_weight_combinations(
                            min_weight=min_weight,
                            max_weight=max_weight, 
                            step=step_size
                        )
                        
                        st.info(f"ìƒì„±ëœ ê°€ì¤‘ì¹˜ ì¡°í•© ìˆ˜: {len(weight_combinations)}ê°œ")
                        
                        # Run experiment
                        try:
                            log_file = weight_experiment.run_weight_experiment(
                                hybrid_search_manager=hybrid_search_manager,
                                test_queries=test_queries,
                                weight_combinations=weight_combinations,
                                max_workers=max_workers
                            )
                            
                            st.success(f"âœ… ì‹¤í—˜ ì™„ë£Œ! ê²°ê³¼ê°€ {log_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                            
                            # Automatically load and show initial results
                            if viz_manager.load_weight_data(log_file):
                                st.rerun()
                                
                        except Exception as e:
                            st.error(f"ì‹¤í—˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                    else:
                        st.warning("í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        
        with col2:
            st.subheader("ğŸ“Š ì‹¤í—˜ í˜„í™©")
            
            # Load existing data
            if os.path.exists(log_path):
                if viz_manager.load_weight_data(log_path):
                    df = viz_manager.df
                    
                    st.metric("ì´ ì‹¤í—˜ ìˆ˜", len(df))
                    
                    if viz_manager.best_combination:
                        best = viz_manager.best_combination
                        st.metric("ìµœê³  ì ìˆ˜", f"{best['score']:.4f}")
                        
                        st.write("**ìµœì  ê°€ì¤‘ì¹˜ ì¡°í•©:**")
                        st.write(f"â€¢ BM25: {best['bm25_weight']:.3f}")
                        st.write(f"â€¢ Vector: {best['vector_weight']:.3f}")
                        st.write(f"â€¢ ì‘ë‹µì‹œê°„: {best['avg_latency_ms']:.1f}ms")
                        st.write(f"â€¢ ì˜¤ë¥˜ìœ¨: {best['error_rate']:.1%}")
                else:
                    st.info("ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.info("ì•„ì§ ì‹¤í—˜ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        st.markdown("---")
        
        # Visualization section
        if os.path.exists(log_path) and viz_manager.load_weight_data(log_path):
            st.subheader("ğŸ“ˆ ì‹¤í—˜ ê²°ê³¼ ì‹œê°í™”")
            
            # Visualization options
            viz_col1, viz_col2 = st.columns(2)
            
            with viz_col1:
                chart_type = st.selectbox(
                    "ì°¨íŠ¸ ìœ í˜• ì„ íƒ",
                    ["2D ì‚°ì ë„", "3D í‘œë©´ ì°¨íŠ¸", "íˆíŠ¸ë§µ", "ì„±ëŠ¥ ë¹„êµ ì°¨íŠ¸"],
                    index=0
                )
            
            with viz_col2:
                if chart_type == "2D ì‚°ì ë„":
                    color_metric = st.selectbox(
                        "ìƒ‰ìƒ ê¸°ì¤€ ë©”íŠ¸ë¦­",
                        ["score", "avg_latency_ms", "error_rate", "score_std"],
                        index=0
                    )
                elif chart_type == "íˆíŠ¸ë§µ":
                    heat_metric = st.selectbox(
                        "íˆíŠ¸ë§µ ë©”íŠ¸ë¦­",
                        ["score", "avg_latency_ms", "error_rate", "score_std"],
                        index=0
                    )
            
            # Display selected chart
            try:
                if chart_type == "2D ì‚°ì ë„":
                    fig = viz_manager.create_2d_scatter_plot(color_metric)
                    if fig:
                        st.plotly_chart(fig, use_container_width=True)
                
                elif chart_type == "3D í‘œë©´ ì°¨íŠ¸":
                    fig = viz_manager.create_3d_surface_plot()
                    if fig:
                        st.plotly_chart(fig, use_container_width=True)
                
                elif chart_type == "íˆíŠ¸ë§µ":
                    fig = viz_manager.create_heatmap(heat_metric)
                    if fig:
                        st.plotly_chart(fig, use_container_width=True)
                
                elif chart_type == "ì„±ëŠ¥ ë¹„êµ ì°¨íŠ¸":
                    fig = viz_manager.create_performance_comparison_chart()
                    if fig:
                        st.plotly_chart(fig, use_container_width=True)
                        
            except Exception as e:
                st.error(f"ì°¨íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            
            st.markdown("---")
            
            # Analysis insights
            st.subheader("ğŸ” ë¶„ì„ ì¸ì‚¬ì´íŠ¸")
            
            insights = viz_manager.get_optimization_insights()
            if insights:
                insight_col1, insight_col2, insight_col3 = st.columns(3)
                
                with insight_col1:
                    st.metric("ì´ ì‹¤í—˜ ì¡°í•©", insights['total_combinations'])
                    st.metric("ìµœê³  ì ìˆ˜", f"{insights['best_score']:.4f}")
                
                with insight_col2:
                    st.metric("í‰ê·  ì ìˆ˜", f"{insights['avg_score']:.4f}")
                    st.metric("ì ìˆ˜ í‘œì¤€í¸ì°¨", f"{insights['score_std']:.4f}")
                
                with insight_col3:
                    best = insights['best_combination']
                    st.write("**ìµœì  ì¡°í•©:**")
                    st.write(f"BM25: {best['bm25_weight']:.3f}")
                    st.write(f"Vector: {best['vector_weight']:.3f}")
                
                # Recommendations
                st.subheader("ğŸ’¡ ê¶Œì¥ì‚¬í•­")
                for i, rec in enumerate(insights.get('recommendations', []), 1):
                    st.write(f"{i}. {rec}")
            
            # Raw data table (expandable)
            with st.expander("ğŸ“‹ ì‹¤í—˜ ë°ì´í„° ìƒì„¸ë³´ê¸°"):
                df_display = viz_manager.df[[
                    'bm25_weight', 'vector_weight', 'score', 
                    'avg_latency_ms', 'error_rate', 'score_std'
                ]].copy()
                
                # Sort by score descending
                df_display = df_display.sort_values('score', ascending=False)
                
                st.dataframe(
                    df_display,
                    use_container_width=True,
                    height=300
                )
                
                # Download button
                csv = df_display.to_csv(index=False)
                st.download_button(
                    label="ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ",
                    data=csv,
                    file_name=f"weight_optimization_results_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv"
                )
        
        # Usage instructions
        st.markdown("---")
        st.subheader("ğŸ’¡ ì‚¬ìš© ë°©ë²•")
        st.info("""
        **ê°€ì¤‘ì¹˜ ìµœì í™” ì‹¤í—˜ ìˆœì„œ:**
        1. **ì‹¤í—˜ íŒŒë¼ë¯¸í„° ì„¤ì •**: ì‚¬ì´ë“œë°”ì—ì„œ ê°€ì¤‘ì¹˜ ë²”ìœ„ì™€ ìŠ¤í… í¬ê¸° ì¡°ì •
        2. **í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ì¤€ë¹„**: ê¸°ë³¸ ì¿¼ë¦¬ ì‚¬ìš© ë˜ëŠ” ì»¤ìŠ¤í…€ ì¿¼ë¦¬ ì…ë ¥
        3. **ì‹¤í—˜ ì‹¤í–‰**: 'ê°€ì¤‘ì¹˜ ìµœì í™” ì‹¤í—˜ ì‹¤í–‰' ë²„íŠ¼ í´ë¦­
        4. **ê²°ê³¼ ë¶„ì„**: ë‹¤ì–‘í•œ ì°¨íŠ¸ë¡œ ê²°ê³¼ ì‹œê°í™” ë° ë¶„ì„
        5. **ìµœì  ê°€ì¤‘ì¹˜ ì ìš©**: ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì  ê°€ì¤‘ì¹˜ ì„ íƒ
        
        **íŒ:**
        - ìŠ¤í… í¬ê¸°ê°€ ì‘ì„ìˆ˜ë¡ ì •ë°€í•˜ì§€ë§Œ ì‹¤í—˜ ì‹œê°„ì´ ê¸¸ì–´ì§‘ë‹ˆë‹¤
        - ë³‘ë ¬ ì²˜ë¦¬ ìˆ˜ë¥¼ ëŠ˜ë¦¬ë©´ ì‹¤í—˜ ì†ë„ê°€ í–¥ìƒë©ë‹ˆë‹¤
        - 3D í‘œë©´ ì°¨íŠ¸ë¡œ ì „ì²´ì ì¸ ì„±ëŠ¥ ë¶„í¬ë¥¼ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
        """)

with tab6:
    st.header("ğŸ’¬ RAG í…ŒìŠ¤íŠ¸")
    
    if st.session_state.db is None:
        st.warning("ë¨¼ì € 'ë¬¸ì„œ ì²­í‚¹ ë° ì¸ë±ì‹±' íƒ­ì—ì„œ ë¬¸ì„œë¥¼ ë™ê¸°í™”í•´ ì£¼ì„¸ìš”.")
    else:
        # RAG Configuration
        st.subheader("RAG ì„¤ì •")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            chat_model = st.selectbox(
                "Answer Model",
                ["gpt-3.5-turbo", "gpt-4o-mini", "gpt-4o", "gpt-4-turbo"],
                index=0,
                key="chat_model"
            )
        
        with col2:
            chat_temperature = st.slider("ë‹µë³€ ìƒì„± ì˜¨ë„", min_value=0.0, max_value=1.0, value=0.0, step=0.1, key="chat_temp")
        
        with col3:
            search_k = st.slider("ê²€ìƒ‰í•  ì²­í¬ ê°œìˆ˜", min_value=1, max_value=10, value=3, key="chat_k")
        
        # RAG ë§¤ë‹ˆì € ì„¤ì •
        rag_manager = st.session_state.rag_manager
        rag_manager.set_llm(chat_model, chat_temperature)
        rag_manager.set_retriever(st.session_state.db, "similarity", {"k": search_k})
        
        # ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ ë§¤ë‹ˆì €
        chat_interface = st.session_state.chat_interface
        
        # Clear chat button and LangSmith dashboard
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™”"):
                chat_interface.clear_messages()
                st.rerun()
        
        with col2:
            # LangSmith dashboard link
            langsmith_project = os.getenv("LANGSMITH_PROJECT", "rag_lab_project")
            langsmith_url = f"https://smith.langchain.com/projects/{langsmith_project}"
            st.markdown(f"[ğŸ” LangSmith ëŒ€ì‹œë³´ë“œ ì—´ê¸°]({langsmith_url})", unsafe_allow_html=True)
        
        # Display chat messages
        st.subheader("ì±„íŒ…")
        
        # Chat container
        chat_container = st.container()
        
        with chat_container:
            chat_interface.display_messages()
        
        # Chat input
        user_question = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...")
        
        if user_question:
            # Add user message to chat
            chat_interface.add_message("user", user_question)
            
            try:
                with st.spinner("ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                    # Get answer using RAG manager (LangChain ìë™ ì¶”ì )
                    answer, contexts = rag_manager.get_answer(user_question)
                    
                    # Add assistant message to chat
                    chat_interface.add_message("assistant", answer, contexts)
                    
                    st.rerun()
                    
            except Exception as e:
                st.error(f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                # Add error message to chat
                chat_interface.add_message("assistant", f"ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

with tab7:
    st.header("ğŸ“ ì§ˆë¬¸ ìƒì„±í•˜ê¸°")
    
    if st.session_state.db is None:
        st.warning("ë¨¼ì € 'ë¬¸ì„œ ì²­í‚¹ ë° ì¸ë±ì‹±' íƒ­ì—ì„œ ë¬¸ì„œë¥¼ ë™ê¸°í™”í•´ ì£¼ì„¸ìš”.")
    else:
        # LLM configuration for question generation
        st.subheader("LLM ì„¤ì •")
        
        col1, col2 = st.columns(2)
        
        with col1:
            question_model = st.selectbox(
                "Question Generation Model",
                ["gpt-4o-mini", "gpt-3.5-turbo", "gpt-4o", "gpt-4-turbo"],
                index=0
            )
        
        with col2:
            question_temperature = st.slider("ì§ˆë¬¸ ìƒì„± ì˜¨ë„", min_value=0.0, max_value=1.0, value=0.9, step=0.1)
        
        # Number of questions
        num_questions = st.slider("ìƒì„±í•  ì§ˆë¬¸ ê°œìˆ˜", min_value=1, max_value=10, value=5)
        
        # ì§ˆë¬¸ ìƒì„± ë§¤ë‹ˆì € ì„¤ì •
        question_manager = st.session_state.question_manager
        question_manager.set_llm(question_model, question_temperature)
        
        # Generate questions
        if st.button("ì§ˆë¬¸ ìƒì„±", type="primary"):
            try:
                # Update workflow status to in_progress
                workflow_manager = st.session_state.workflow_manager
                workflow_manager.update_step_status("question_generation", "in_progress", 0)
                
                with st.spinner("ì§ˆë¬¸ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                    if st.session_state.db is None:
                        workflow_manager.update_step_status("question_generation", "error", 0, 
                                                          error="DBê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € ë™ê¸°í™”ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
                        st.error("DBê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € ë™ê¸°í™”ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
                    else:
                        # Update progress
                        workflow_manager.update_step_status("question_generation", "in_progress", 25, {
                            "model_used": question_model,
                            "target_count": num_questions
                        })
                        
                        # Generate questions using manager
                        questions = question_manager.generate_questions(st.session_state.db, num_questions)
                        
                        # Store generated questions
                        st.session_state.generated_questions = questions
                        st.session_state.edited_questions = questions.copy()
                        
                        # Update workflow status to completed
                        workflow_manager.update_step_status("question_generation", "completed", 100, {
                            "question_count": len(questions),
                            "model_used": question_model
                        })
                        
                        st.success(f"{len(questions)}ê°œì˜ ì§ˆë¬¸ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    
            except Exception as e:
                workflow_manager.update_step_status("question_generation", "error", 0, 
                                                  error=str(e))
                st.error(f"ì§ˆë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        
        # Display and edit questions
        if st.session_state.generated_questions:
            st.subheader("ìƒì„±ëœ ì§ˆë¬¸ ìˆ˜ì •")
            st.write("ì•„ë˜ì—ì„œ ì§ˆë¬¸ì„ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:")
            
            # Edit questions
            for i, question in enumerate(st.session_state.generated_questions):
                edited_question = st.text_area(
                    f"ì§ˆë¬¸ {i+1}",
                    value=st.session_state.edited_questions[i] if i < len(st.session_state.edited_questions) else question,
                    key=f"question_{i}"
                )
                
                # Update edited questions in session state
                if len(st.session_state.edited_questions) <= i:
                    st.session_state.edited_questions.append(edited_question)
                else:
                    st.session_state.edited_questions[i] = edited_question
            
            # Add/Remove questions
            col1, col2 = st.columns(2)
            
            with col1:
                if st.button("ì§ˆë¬¸ ì¶”ê°€"):
                    question_manager.add_question("ìƒˆë¡œìš´ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")
                    st.session_state.generated_questions = question_manager.get_questions()
                    st.session_state.edited_questions = question_manager.get_questions()
                    st.rerun()
            
            with col2:
                if st.button("ë§ˆì§€ë§‰ ì§ˆë¬¸ ì‚­ì œ") and len(st.session_state.generated_questions) > 1:
                    question_manager.remove_question(len(question_manager.get_questions()) - 1)
                    st.session_state.generated_questions = question_manager.get_questions()
                    st.session_state.edited_questions = question_manager.get_questions()
                    st.rerun()
            
            # Display final questions
            st.subheader("ìµœì¢… ì§ˆë¬¸ ëª©ë¡")
            for i, question in enumerate(st.session_state.edited_questions):
                st.write(f"{i+1}. {question}")

with tab8:
    st.header("ğŸ” RAG í‰ê°€í•˜ê¸°")
    
    if st.session_state.db is None:
        st.warning("ë¨¼ì € 'ë¬¸ì„œ ì²­í‚¹ ë° ì¸ë±ì‹±' íƒ­ì—ì„œ ë¬¸ì„œë¥¼ ë™ê¸°í™”í•´ ì£¼ì„¸ìš”.")
    elif not st.session_state.edited_questions:
        st.warning("ë¨¼ì € 'ì§ˆë¬¸ ìƒì„±í•˜ê¸°' íƒ­ì—ì„œ ì§ˆë¬¸ì„ ìƒì„±í•´ ì£¼ì„¸ìš”.")
    else:
        # Retriever configuration
        st.subheader("ê²€ìƒ‰ê¸° ì„¤ì •")
        
        col1, col2 = st.columns(2)
        
        with col1:
            search_type = st.selectbox(
                "Search Type",
                ["mmr", "similarity", "similarity_score_threshold"],
                index=0
            )
        
        with col2:
            k = st.slider("ê²€ìƒ‰í•  ì²­í¬ ê°œìˆ˜ (k)", min_value=1, max_value=20, value=5)
        
        # Additional parameters based on search type
        if search_type == "mmr":
            col1, col2 = st.columns(2)
            with col1:
                lambda_mult = st.slider("ëŒë‹¤ ê°€ì¤‘ì¹˜", min_value=0.0, max_value=1.0, value=0.25, step=0.05)
            with col2:
                fetch_k = st.slider("Fetch K (ê²€ìƒ‰ í›„ë³´ ìˆ˜)", min_value=k, max_value=50, value=10)
            
            search_kwargs = {"k": k, "lambda_mult": lambda_mult, "fetch_k": fetch_k}
        
        elif search_type == "similarity_score_threshold":
            score_threshold = st.slider("ì ìˆ˜ ì„ê³„ê°’", min_value=-1.0, max_value=1.0, value=0.5, step=0.1)
            search_kwargs = {"k": k, "score_threshold": score_threshold}
        
        else:
            search_kwargs = {"k": k}
        
        # LLM configuration
        st.subheader("LLM ì„¤ì •")
        
        answer_model = st.selectbox(
            "Answer Generation Model",
            ["gpt-3.5-turbo", "gpt-4o-mini", "gpt-4o", "gpt-4-turbo"],
            index=0
        )
        answer_temperature = st.slider("ë‹µë³€ ìƒì„± ì˜¨ë„", min_value=0.0, max_value=1.0, value=0.0, step=0.1)
        
        # RAGAS metrics selection
        st.subheader("RAGAS í‰ê°€ ì§€í‘œ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            use_faithfulness = st.checkbox("ì •í™•ì„±(Faithfulness)", value=True)
            use_answer_relevancy = st.checkbox("ë‹µë³€ ê´€ë ¨ì„±(Answer Relevancy)", value=True)
        
        with col2:
            use_context_precision = st.checkbox("ë¬¸ë§¥ ì •ë°€ë„(Context Precision)", value=True)
            use_context_recall = st.checkbox("ë¬¸ë§¥ ì¬í˜„ìœ¨(Context Recall)", value=True)
        
        # Display questions to be evaluated
        st.subheader("í‰ê°€í•  ì§ˆë¬¸ ëª©ë¡")
        for i, question in enumerate(st.session_state.edited_questions):
            st.write(f"{i+1}. {question}")
        
        # í‰ê°€ ë§¤ë‹ˆì € ì„¤ì •
        evaluation_manager = st.session_state.evaluation_manager
        rag_manager = st.session_state.rag_manager
        
        # RAG ë§¤ë‹ˆì € ì„¤ì •
        rag_manager.set_llm(answer_model, answer_temperature)
        rag_manager.set_retriever(st.session_state.db, search_type, search_kwargs)
        
        # Evaluate questions
        if st.button("RAG í‰ê°€ ì‹¤í–‰", type="primary"):
            try:
                # Update workflow status to in_progress
                workflow_manager = st.session_state.workflow_manager
                workflow_manager.update_step_status("evaluation", "in_progress", 0)
                
                with st.spinner("ì§ˆë¬¸ì„ í‰ê°€ ì¤‘ì…ë‹ˆë‹¤..."):
                    st.write("RAGASë¡œ í‰ê°€ ì¤‘...")
                    
                    # Update progress
                    workflow_manager.update_step_status("evaluation", "in_progress", 10, {
                        "total_questions": len(st.session_state.edited_questions),
                        "model_used": answer_model
                    })
                    
                    # í‰ê°€ ë©”íŠ¸ë¦­ ì„¤ì •
                    metrics_config = {
                        'use_faithfulness': use_faithfulness,
                        'use_answer_relevancy': use_answer_relevancy,
                        'use_context_precision': use_context_precision,
                        'use_context_recall': use_context_recall
                    }
                    
                    # Progress update
                    workflow_manager.update_step_status("evaluation", "in_progress", 30)
                    
                    # í‰ê°€ ì‹¤í–‰
                    results_df = evaluation_manager.evaluate_rag_system(
                        st.session_state.edited_questions,
                        st.session_state.db,
                        rag_manager,
                        metrics_config
                    )
                    
                    # Store results
                    st.session_state.evaluation_results = results_df
                    
                    # Get average scores for workflow status
                    avg_scores = evaluation_manager.get_average_scores()
                    
                    # Update workflow status to completed
                    workflow_manager.update_step_status("evaluation", "completed", 100, {
                        "total_questions": len(st.session_state.edited_questions),
                        "model_used": answer_model,
                        "average_scores": avg_scores
                    })
                    
                    st.success("í‰ê°€ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                    
            except Exception as e:
                workflow_manager.update_step_status("evaluation", "error", 0, 
                                                  error=str(e))
                st.error(f"í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        
        # Display results
        if st.session_state.evaluation_results is not None:
            st.subheader("í‰ê°€ ê²°ê³¼")
            
            results_df = st.session_state.evaluation_results
            
            # Display dataframe
            st.dataframe(results_df)
            
            # Calculate and display average scores
            avg_scores = evaluation_manager.get_average_scores()
            
            if avg_scores:
                st.subheader("í‰ê·  ì ìˆ˜")
                col1, col2 = st.columns(2)
                
                avg_scores_items = list(avg_scores.items())
                with col1:
                    for i, (metric, score) in enumerate(avg_scores_items):
                        if i < len(avg_scores_items) // 2 + len(avg_scores_items) % 2:
                            st.metric(metric.replace("_", " ").title(), f"{score:.3f}")
                
                with col2:
                    for i, (metric, score) in enumerate(avg_scores_items):
                        if i >= len(avg_scores_items) // 2 + len(avg_scores_items) % 2:
                            st.metric(metric.replace("_", " ").title(), f"{score:.3f}")
                
                # Visualizations
                st.subheader("Visualizations")
                
                # Bar chart for each metric
                metric_columns = [col for col in results_df.columns if col not in ["question", "answer"]]
                for metric in metric_columns:
                    fig = VisualizationUtils.create_metric_bar_chart(results_df, metric)
                    st.pyplot(fig)
                
                # Radar chart for average scores
                radar_fig = VisualizationUtils.create_radar_chart(avg_scores)
                if radar_fig:
                    st.pyplot(radar_fig)
            
            # Q&A Display
            st.subheader("ì§ˆë¬¸ê³¼ ë‹µë³€")
            for i, row in results_df.iterrows():
                with st.expander(f"Q{i+1}: {row['question']}"):
                    st.write("**ë‹µë³€:**")
                    st.write(row['answer'])
                    
                    if avg_scores:
                        st.write("**ì ìˆ˜:**")
                        for metric in avg_scores.keys():
                            if metric in row:
                                st.write(f"- {metric.replace('_', ' ').title()}: {row[metric]:.3f}")

# Workflow Status Sidebar
def display_workflow_sidebar():
    """Display workflow status in sidebar"""
    workflow_manager = st.session_state.workflow_manager
    
    st.sidebar.title("ğŸ”„ RAG Workflow Status")
    st.sidebar.markdown("---")
    
    # Overall progress
    overall_progress = workflow_manager.get_overall_progress()
    st.sidebar.progress(overall_progress / 100)
    st.sidebar.text(f"Overall Progress: {overall_progress:.1f}%")
    
    # Current status
    workflow_status = workflow_manager.get_workflow_status()
    status_emoji = {"pending": "â³", "in_progress": "ğŸ”„", "completed": "âœ…"}.get(workflow_status, "â“")
    st.sidebar.text(f"Status: {status_emoji} {workflow_status.title()}")
    
    st.sidebar.markdown("---")
    
    # Individual steps
    st.sidebar.subheader("ğŸ“‹ Workflow Steps")
    
    # Step 1: Document Embedding
    embedding_info = workflow_manager.get_step_display_info("embedding")
    with st.sidebar.expander(f"{embedding_info['emoji']} Document Embedding", expanded=True):
        st.text(f"Status: {embedding_info['status'].title()}")
        if embedding_info['progress'] > 0:
            st.progress(embedding_info['progress'] / 100)
        st.text(f"Updated: {embedding_info['last_updated']}")
        
        if embedding_info['details']:
            if 'document_count' in embedding_info['details']:
                st.text(f"Documents: {embedding_info['details']['document_count']}")
            if 'new_files' in embedding_info['details']:
                st.text(f"New files: {embedding_info['details']['new_files']}")
        
        if embedding_info['error']:
            st.error(f"Error: {embedding_info['error']}")
    
    # Step 2: Question Generation
    question_info = workflow_manager.get_step_display_info("question_generation")
    with st.sidebar.expander(f"{question_info['emoji']} Question Generation"):
        st.text(f"Status: {question_info['status'].title()}")
        if question_info['progress'] > 0:
            st.progress(question_info['progress'] / 100)
        st.text(f"Updated: {question_info['last_updated']}")
        
        if question_info['details']:
            if 'question_count' in question_info['details']:
                st.text(f"Questions: {question_info['details']['question_count']}")
            if 'model_used' in question_info['details']:
                st.text(f"Model: {question_info['details']['model_used']}")
        
        if question_info['error']:
            st.error(f"Error: {question_info['error']}")
    
    # Step 3: Question Evaluation
    evaluation_info = workflow_manager.get_step_display_info("evaluation")
    with st.sidebar.expander(f"{evaluation_info['emoji']} Question Evaluation"):
        st.text(f"Status: {evaluation_info['status'].title()}")
        if evaluation_info['progress'] > 0:
            st.progress(evaluation_info['progress'] / 100)
        st.text(f"Updated: {evaluation_info['last_updated']}")
        
        if evaluation_info['details']:
            if 'average_scores' in evaluation_info['details']:
                st.text("Average Scores:")
                for metric, score in evaluation_info['details']['average_scores'].items():
                    st.text(f"  {metric}: {score:.3f}")
        
        if evaluation_info['error']:
            st.error(f"Error: {evaluation_info['error']}")
    
    st.sidebar.markdown("---")
    
    # Quick Actions
    st.sidebar.subheader("ğŸš€ Quick Actions")
    
    # Next step suggestion
    next_step = workflow_manager.get_next_step()
    if next_step:
        step_names = {
            "embedding": "Document Sync",
            "question_generation": "Question Generation", 
            "evaluation": "Evaluation"
        }
        st.sidebar.info(f"Next: {step_names.get(next_step, next_step)}")
    
    # Reset workflow button
    if st.sidebar.button("ğŸ”„ Reset Workflow"):
        workflow_manager.reset_workflow()
        st.rerun()
    
    # Workflow completion celebration
    if workflow_manager.workflow_completed:
        st.sidebar.success("ğŸ‰ Workflow Completed!")
        completion_time = workflow_manager.completion_time
        start_time = workflow_manager.start_time
        if completion_time and start_time:
            duration = completion_time - start_time
            st.sidebar.text(f"Duration: {duration:.1f} seconds")

# Display sidebar
display_workflow_sidebar()