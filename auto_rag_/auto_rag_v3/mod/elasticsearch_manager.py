"""Elasticsearch management module for hybrid search"""

import os
import json
import streamlit as st
from typing import List, Dict, Any, Optional
from datetime import datetime


class ElasticsearchManager:
    """Elasticsearch management class for hybrid search"""
    
    def __init__(self, 
                 host: str = "http://localhost:9200", 
                 index_name: str = "tax_documents",
                 username: str = "",
                 password: str = "",
                 embedding_dims: int = None):
        self.host = host
        self.index_name = index_name
        self.username = username
        self.password = password
        self.client = None
        self.embedding_dims = embedding_dims  # ë™ì ìœ¼ë¡œ ì„¤ì •ë¨ (Noneì´ë©´ ìë™ ê°ì§€)
        
    def _detect_embedding_dimensions(self, embeddings) -> int:
        """ì„ë² ë”© ëª¨ë¸ì˜ ì‹¤ì œ ì°¨ì›ì„ ê°ì§€"""
        try:
            # í…ŒìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±ìœ¼ë¡œ ì°¨ì› í™•ì¸
            test_embedding = embeddings.embed_query("dimension test")
            detected_dims = len(test_embedding)
            st.info(f"ğŸ” ì„ë² ë”© ëª¨ë¸ ì°¨ì› ìë™ ê°ì§€: {detected_dims}")
            return detected_dims
        except Exception as e:
            st.warning(f"âš ï¸ ì°¨ì› ê°ì§€ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: {str(e)}")
            return 1536  # ì•ˆì „í•œ ê¸°ë³¸ê°’
    
    def set_embedding_dimensions(self, embeddings):
        """ì„ë² ë”© ì°¨ì›ì„ ì„¤ì • (ì¸ë±ìŠ¤ ìƒì„± ì „ í˜¸ì¶œ í•„ìš”)"""
        if self.embedding_dims is None:
            self.embedding_dims = self._detect_embedding_dimensions(embeddings)
        
    def _get_client(self):
        """Get Elasticsearch client with lazy loading"""
        if self.client is None:
            try:
                # elasticsearch ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë™ì ìœ¼ë¡œ import (ì„¤ì¹˜ ì•ˆë˜ì–´ ìˆì„ ìˆ˜ë„)
                from elasticsearch import Elasticsearch
                
                if self.username and self.password:
                    self.client = Elasticsearch(
                        hosts=[self.host],
                        basic_auth=(self.username, self.password),
                        request_timeout=30,
                        max_retries=3,
                        retry_on_timeout=True
                    )
                else:
                    self.client = Elasticsearch(
                        hosts=[self.host],
                        request_timeout=30,
                        max_retries=3,
                        retry_on_timeout=True
                    )
                    
            except ImportError:
                st.error("elasticsearch ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. 'pip install elasticsearch>=8.0.0' ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
                return None
            except Exception as e:
                st.error(f"Elasticsearch í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")
                return None
                
        return self.client
    
    def check_connection(self) -> bool:
        """Check Elasticsearch connection"""
        try:
            client = self._get_client()
            if client is None:
                return False
                
            # í´ëŸ¬ìŠ¤í„° ìƒíƒœ í™•ì¸
            health = client.cluster.health()
            return health['status'] in ['green', 'yellow']
            
        except Exception as e:
            st.warning(f"Elasticsearch ì—°ê²° í™•ì¸ ì‹¤íŒ¨: {str(e)}")
            return False
    
    def check_index_exists(self) -> bool:
        """Check if index exists"""
        try:
            client = self._get_client()
            if client is None:
                return False
                
            return client.indices.exists(index=self.index_name)
            
        except Exception as e:
            st.error(f"ì¸ë±ìŠ¤ ì¡´ì¬ í™•ì¸ ì‹¤íŒ¨: {str(e)}")
            return False
    
    def create_index(self, force_recreate: bool = False) -> bool:
        """Create Elasticsearch index with hybrid search mapping"""
        try:
            client = self._get_client()
            if client is None:
                return False
            
            # ì¸ë±ìŠ¤ê°€ ì´ë¯¸ ì¡´ì¬í•˜ê³  ì¬ìƒì„±ì´ ì•„ë‹Œ ê²½ìš°
            if self.check_index_exists():
                if not force_recreate:
                    st.info(f"ì¸ë±ìŠ¤ '{self.index_name}'ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.")
                    return True
                else:
                    # ê¸°ì¡´ ì¸ë±ìŠ¤ ì‚­ì œ
                    client.indices.delete(index=self.index_name)
                    st.info(f"ê¸°ì¡´ ì¸ë±ìŠ¤ '{self.index_name}' ì‚­ì œ ì™„ë£Œ")
            
            # ì¸ë±ìŠ¤ ë§¤í•‘ ì„¤ì •
            index_mapping = {
                "settings": {
                    "number_of_shards": 1,
                    "number_of_replicas": 0,  # ë¡œì»¬ í™˜ê²½ì—ì„œëŠ” ë³µì œë³¸ ë¶ˆí•„ìš”
                    "analysis": {
                        "analyzer": {
                            "korean_analyzer": {
                                "type": "standard",  # nori ì—†ì„ ë•Œ fallback
                                "stopwords": "_korean_"
                            }
                        }
                    }
                },
                "mappings": {
                    "properties": {
                        "content": {
                            "type": "text",
                            "analyzer": "korean_analyzer",
                            "fields": {
                                "keyword": {
                                    "type": "keyword",
                                    "ignore_above": 256
                                }
                            }
                        },
                        "embedding": {
                            "type": "dense_vector",
                            "dims": self.embedding_dims,
                            "index": True,
                            "similarity": "cosine"
                        },
                        "source": {
                            "type": "keyword"
                        },
                        "filename": {
                            "type": "keyword"
                        },
                        "doc_id": {
                            "type": "keyword"
                        },
                        "chunk_id": {
                            "type": "keyword"
                        },
                        "created_at": {
                            "type": "date"
                        }
                    }
                }
            }
            
            # ì¸ë±ìŠ¤ ìƒì„±
            client.indices.create(index=self.index_name, body=index_mapping)
            st.success(f"ì¸ë±ìŠ¤ '{self.index_name}' ìƒì„± ì™„ë£Œ")
            return True
            
        except Exception as e:
            st.error(f"ì¸ë±ìŠ¤ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return False
    
    def index_documents(self, documents: List[Any], embeddings: List[List[float]]) -> bool:
        """Index documents with embeddings to Elasticsearch"""
        try:
            client = self._get_client()
            if client is None:
                return False
            
            # ì¸ë±ìŠ¤ê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒì„±
            if not self.check_index_exists():
                if not self.create_index():
                    return False
            
            # bulk ì¸ë±ì‹±ì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„
            bulk_data = []
            current_time = datetime.now().isoformat()
            
            for i, (doc, embedding) in enumerate(zip(documents, embeddings)):
                # ë¬¸ì„œ ë©”íƒ€ë°ì´í„°ì—ì„œ ì •ë³´ ì¶”ì¶œ
                source = doc.metadata.get('source', '')
                filename = os.path.basename(source) if source else f'doc_{i}'
                
                # ê³ ìœ  ID ìƒì„±
                doc_id = f"{filename}_{i}_{hash(doc.page_content) % 10000}"
                
                # ì¸ë±ì‹±í•  ë¬¸ì„œ ë°ì´í„°
                doc_data = {
                    "content": doc.page_content,
                    "embedding": embedding,
                    "source": source,
                    "filename": filename,
                    "doc_id": doc_id,
                    "chunk_id": f"chunk_{i}",
                    "created_at": current_time
                }
                
                # bulk API í˜•ì‹ìœ¼ë¡œ ì¶”ê°€
                bulk_data.append({"index": {"_index": self.index_name, "_id": doc_id}})
                bulk_data.append(doc_data)
            
            # bulk ì¸ë±ì‹± ì‹¤í–‰
            if bulk_data:
                response = client.bulk(body=bulk_data, refresh=True)
                
                # ì˜¤ë¥˜ í™•ì¸
                if response.get("errors"):
                    error_count = sum(1 for item in response["items"] if "error" in item.get("index", {}))
                    st.warning(f"Elasticsearch ì¸ë±ì‹± ì¤‘ {error_count}ê°œ ì˜¤ë¥˜ ë°œìƒ")
                    return False
                else:
                    indexed_count = len(documents)
                    st.success(f"Elasticsearchì— {indexed_count}ê°œ ë¬¸ì„œ ì¸ë±ì‹± ì™„ë£Œ")
                    return True
            
            return True
            
        except Exception as e:
            st.error(f"Elasticsearch ë¬¸ì„œ ì¸ë±ì‹± ì‹¤íŒ¨: {str(e)}")
            return False
    
    def get_document_count(self) -> int:
        """Get number of documents in index"""
        try:
            client = self._get_client()
            if client is None:
                return 0
            
            if not self.check_index_exists():
                return 0
                
            response = client.count(index=self.index_name)
            return response.get("count", 0)
            
        except Exception as e:
            st.error(f"Elasticsearch ë¬¸ì„œ ê°œìˆ˜ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            return 0
    
    def get_index_stats(self) -> Dict[str, Any]:
        """Get comprehensive index statistics"""
        try:
            client = self._get_client()
            if client is None:
                return {}
            
            if not self.check_index_exists():
                return {'document_count': 0, 'index_exists': False}
            
            # ë¬¸ì„œ ìˆ˜ ì¡°íšŒ
            count_response = client.count(index=self.index_name)
            document_count = count_response.get("count", 0)
            
            # ì¸ë±ìŠ¤ í†µê³„ ì¡°íšŒ
            stats_response = client.indices.stats(index=self.index_name)
            index_stats = stats_response.get("indices", {}).get(self.index_name, {})
            
            return {
                'document_count': document_count,
                'index_exists': True,
                'index_size_bytes': index_stats.get("total", {}).get("store", {}).get("size_in_bytes", 0),
                'index_docs': index_stats.get("total", {}).get("docs", {}).get("count", 0),
            }
            
        except Exception as e:
            st.warning(f"Elasticsearch í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            return {'document_count': 0, 'index_exists': False, 'error': str(e)}
    
    def get_files_in_index(self) -> List[str]:
        """Get list of filenames in index"""
        try:
            client = self._get_client()
            if client is None:
                return []
            
            if not self.check_index_exists():
                return []
            
            # filename í•„ë“œì˜ unique ê°’ë“¤ ì¡°íšŒ
            query = {
                "size": 0,
                "aggs": {
                    "unique_filenames": {
                        "terms": {
                            "field": "filename",
                            "size": 1000
                        }
                    }
                }
            }
            
            response = client.search(index=self.index_name, body=query)
            
            filenames = []
            buckets = response.get("aggregations", {}).get("unique_filenames", {}).get("buckets", [])
            for bucket in buckets:
                filenames.append(bucket["key"])
                
            return filenames
            
        except Exception as e:
            st.error(f"Elasticsearch íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def delete_index(self) -> bool:
        """Delete entire index"""
        try:
            client = self._get_client()
            if client is None:
                return False
            
            if self.check_index_exists():
                client.indices.delete(index=self.index_name)
                st.success(f"ì¸ë±ìŠ¤ '{self.index_name}' ì‚­ì œ ì™„ë£Œ")
            else:
                st.info("ì‚­ì œí•  ì¸ë±ìŠ¤ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                
            return True
            
        except Exception as e:
            st.error(f"ì¸ë±ìŠ¤ ì‚­ì œ ì‹¤íŒ¨: {str(e)}")
            return False
    
    def get_status(self) -> Dict[str, Any]:
        """Get Elasticsearch status information"""
        connection_ok = self.check_connection()
        index_exists = self.check_index_exists() if connection_ok else False
        document_count = self.get_document_count() if index_exists else 0
        
        return {
            'connection_ok': connection_ok,
            'index_exists': index_exists,
            'document_count': document_count,
            'index_name': self.index_name,
            'host': self.host,
            'embedding_dims': self.embedding_dims
        }
    
    def search_documents(self, query: str, size: int = 5) -> List[Dict]:
        """Simple BM25 text search (ë²¡í„° ê²€ìƒ‰ì€ ë³„ë„ êµ¬í˜„)"""
        try:
            client = self._get_client()
            if client is None:
                return []
            
            if not self.check_index_exists():
                return []
            
            search_query = {
                "query": {
                    "match": {
                        "content": query
                    }
                },
                "size": size,
                "_source": ["content", "filename", "source", "doc_id"]
            }
            
            response = client.search(index=self.index_name, body=search_query)
            
            results = []
            for hit in response["hits"]["hits"]:
                results.append({
                    "content": hit["_source"]["content"],
                    "filename": hit["_source"]["filename"],
                    "source": hit["_source"]["source"],
                    "doc_id": hit["_source"]["doc_id"],
                    "score": hit["_score"]
                })
                
            return results
            
        except Exception as e:
            st.error(f"Elasticsearch ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            return []