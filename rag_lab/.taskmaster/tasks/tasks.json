{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "프로젝트 저장소 스캐폴딩 및 기본 FastAPI 헬스체크",
        "description": "Poetry 기반 패키지 관리, pre-commit, lint, 테스트 폴더를 설정하고 FastAPI 서버에 헬스체크 라우트를 노출한다.",
        "details": "• poetry new tax_rag_backend && cd tax_rag_backend\n• pyproject.toml 에 fastapi==0.111, uvicorn[standard]==0.30, pydantic==2 추가\n• pre-commit: ruff, black, isort, mypy 훅 설정\n• main.py\n    from fastapi import FastAPI\n    app = FastAPI(title=\"Tax RAG API\")\n    @app.get(\"/health\")\n    async def health():\n        return {\"status\": \"ok\"}\n• uvicorn main:app --reload 로 수동 기동 확인",
        "testStrategy": "pytest 에서 /health 호출 → 200 & {\"status\":\"ok\"} 검증\nCI(GitHub Actions) 에 pytest + ruff + mypy 워크플로우 추가",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": null
      },
      {
        "id": 2,
        "title": "Redis 세션 메모리 레이어 구축",
        "description": "ConversationBufferWindowMemory 를 RedisChatMessageHistory 로 래핑하여 세션별 k턴(6) 단기 컨텍스트를 저장/조회한다.",
        "details": "• poetry add redis>=5.0 langchain==0.2\n• settings.py: REDIS_URL env 로드, redis.asyncio.Redis 풀 생성\n• memory.py\n    class RedisSessionMemory(ConversationBufferWindowMemory):\n        def __init__(self,k:int=6):\n            super().__init__(chat_memory=RedisChatMessageHistory(\n                 session_id=\"\", k=k, ttl=1800, client=redis_client))\n• LPUSH/LTRIM 구현, HistoryItem 모델 직렬화는 orjson 사용",
        "testStrategy": "pytest-asyncio 로 세션 생성→ 8회 메시지 삽입 후 길이 6 확인\nTTL 만료 모킹하여 자동 삭제 검증",
        "priority": "medium",
        "dependencies": [],
        "status": "deferred",
        "subtasks": null
      },
      {
        "id": 3,
        "title": "임베딩 파이프라인 및 Chroma 벡터 DB 초기화",
        "description": "세법 문서 크롤링 결과를 text-embedding-3-large 로 임베딩한 뒤 Chroma 0.5 영구 클라이언트에 적재한다.",
        "details": "• poetry add chromadb==0.5 openai==1.25 duckdb\n• ingest.py\n    docs = load_documents(\"data/tax_docs/*.md\")\n    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\",chunk_size=512)\n    vectordb = Chroma(collection_name=\"tax_docs\",embedding_function=embeddings,persist_directory=\".chroma\")\n    vectordb.add_documents(docs)\n    vectordb.persist()\n• nightly_backup.sh → aws s3 sync .chroma s3://backup",
        "testStrategy": "pytest 로 3개 샘플 문서 임베딩 후 vectordb.similarity_search(\"양도소득세\") 결과 top-k>0 확인\nS3 모킹으로 백업 스크립트 exit 0 검증",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": null
      },
      {
        "id": 4,
        "title": "RAG 검색 체인 구성",
        "description": "LangChain StuffDocumentsChain 을 이용해 검색→응답 파이프라인을 생성하고 citations 메타데이터를 유지한다.",
        "details": "• poetry add langchain-openai==0.2\n• rag_chain.py\n    retriever = vectordb.as_retriever(search_kwargs={\"k\":4})\n    llm = ChatOpenAI(model_name=\"gpt-4o-mini\",temperature=0.2)\n    chain = (RunnableWithMessageHistory(\n        StuffDocumentsChain(llm=llm,retriever=retriever),\n        memory=RedisSessionMemory()))\n    chain = chain.with_config(tags=[\"rag\",\"tax\"],callbacks=[langsmith_tracer])\n• output_parser 에 citation_index 삽입",
        "testStrategy": "로컬 함수 호출로 \"ISA 세금 면제 한도?\" 질의 → chain 반환 dict 에 \"citations\" 리스트 길이>0 검증",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 5,
        "title": "SSE 스트리밍 어댑터 및 /chat 엔드포인트 구현",
        "description": "LangChain Runnable 과 FastAPI StreamingResponse 를 연결하여 GPT 토큰을 실시간으로 SSE 포맷으로 전송한다.",
        "details": "• poetry add sse-starlette\n• sse_adapter.py\n    async def stream_chain(request,chat_req):\n        async for chunk in chain.astream(chat_req.message,session_id=chat_req.session_id):\n            yield f\"data:{chunk.json()}\\n\\n\"\n• routes/chat.py\n    @router.post(\"/chat\")\n    async def chat(req:ChatRequest):\n        return EventSourceResponse(stream_chain(req))\n• JWT 헤더 검증: fastapi-security==0.7, upstream JWKS 캐시\n• CORS 미들웨어 *허용",
        "testStrategy": "pytest-asyncio + httpx.AsyncClient 로 /chat 호출 → 이벤트 스트림을 수신, finish==True 포함 검증",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 6,
        "title": "세금 계산기 Python 모듈 개발",
        "description": "국세청 세율 표를 기반으로 종합과세·ISA·연금저축 시나리오별 세후 수익률을 결정론적으로 계산하는 엔진을 구현하고, LangChain-Agent가 호출할 수 있도록 RAG 체인에 도구(StructuredTool) 형태로 통합한다.",
        "status": "deferred",
        "dependencies": [],
        "priority": "medium",
        "details": "구현 위치 변경 및 모듈 구조 통합\n• api/services/tax_calculator.py\n    – 세율 테이블 상수화(국세청 기준)\n    – calc(input:TaxCalcInput) -> TaxCalcOutput  : 종합과세·ISA·연금저축 로직\n• api/models/tax_models.py\n    – TaxCalcInput(BaseModel): income:int, invest:int, product:str, horizon:int\n    – TaxCalcOutput(BaseModel): after_tax_return:Decimal, saved_tax:Decimal, breakdown:dict[str, Decimal]\n• api/services/tax_tools.py\n    – TaxCalcTool(StructuredTool) : 위 calc 함수 래핑, Agent 호출 인터페이스 제공\n• rag_config_service.py\n    – 기존 RAG 검색 체인 + TaxCalcTool 를 Agent 하나로 통합, 스트리밍 응답 유지\n",
        "testStrategy": "pytest 단위 테스트: 국세청 공식 예시와 동일한 세액·세후수익률 산출(assert Decimal('0.1543'))\npytest-asyncio 통합 테스트: FastAPI 엔드포인트 → RAG+TaxCalc Agent 호출 시 JSON 스트리밍 응답 검증\ncoverage-xml 기준 95% 이상",
        "subtasks": [
          {
            "id": 1,
            "title": "세금 계산 엔진 개발",
            "description": "세율 테이블 상수화(국세청 기준) 및 핵심 계산 로직(종합과세, ISA, 연금저축)을 구현한다.",
            "status": "pending",
            "dependencies": [],
            "details": "파일: api/services/tax_calculator.py\n• TAX_BRACKETS 딕셔너리/튜플 리스트로 세율, 누진공제액 정의\n• def calc(input:TaxCalcInput) -> TaxCalcOutput:\n      – 각 상품타입별 과세 방식 분기\n      – horizon<=0, 음수 투자금 등 예외 처리\n      – Decimal 사용해 반올림 오차 방지\n• breakdown 필드에 구간별 세액·세후금액 포함",
            "testStrategy": "pytest: 경계 구간·음수 입력·0기간 등 10개 이상 케이스"
          },
          {
            "id": 2,
            "title": "Pydantic 데이터 모델 정의",
            "description": "입력 모델(소득, 투자금액, 상품타입, 투자기간)과 출력 모델(세후수익률, 절약세액, 세부계산내역)을 정의한다.",
            "status": "pending",
            "dependencies": [
              1
            ],
            "details": "파일: api/models/tax_models.py\nclass TaxCalcInput(BaseModel):\n    income:int\n    invest:int\n    product:str  # 'composite'|'isa'|'pension'\n    horizon:int  # 년\nclass TaxCalcOutput(BaseModel):\n    after_tax_return:Decimal\n    saved_tax:Decimal\n    breakdown:dict[str, Decimal]",
            "testStrategy": "pydantic 모델 유효성 테스트(잘못된 product, 음수 값 ValidationError 확인)"
          },
          {
            "id": 3,
            "title": "LangChain Tool 통합",
            "description": "StructuredTool 래퍼 클래스를 구현하여 계산 엔진을 LangChain Agent에서 호출 가능하도록 한다.",
            "status": "pending",
            "dependencies": [
              2
            ],
            "details": "파일: api/services/tax_tools.py\nTaxCalcTool = StructuredTool.from_function(\n    name='tax_calculator',\n    description='국세청 기준 세금 계산기',\n    func=calc,\n    args_schema=TaxCalcInput,\n    return_schema=TaxCalcOutput,\n)",
            "testStrategy": "tool.invoke 샘플 호출 → TaxCalcOutput 검증"
          },
          {
            "id": 4,
            "title": "RAG Chain에 Agent 통합",
            "description": "rag_config_service.py를 수정하여 RAG 검색 체인과 TaxCalcTool을 하나의 Agent로 통합하고 스트리밍 응답을 유지한다.",
            "status": "pending",
            "dependencies": [
              3
            ],
            "details": "• RunnableWithMessageHistory → AgentExecutor 변경\n• Tools=[TaxCalcTool, retriever_tool] 로 등록\n• StreamingStdOutCallbackHandler 사용해 스트리밍 유지\n• 기존 기능 회귀 테스트 포함",
            "testStrategy": "pytest-asyncio: 사용자 질문→Agent 스트리밍 응답에 세금 계산 결과 포함 확인"
          },
          {
            "id": 5,
            "title": "통합 테스트 및 검증",
            "description": "단위 테스트(계산 정확성)와 통합 테스트(챗봇 응답)를 포함하여 전체 기능을 검증하고 95% 이상 커버리지를 달성한다.",
            "status": "pending",
            "dependencies": [
              4
            ],
            "details": "• pytest-cov 설정\n• FastAPI TestClient로 /chat POST → 세금 계산 + RAG 답변 시나리오 검증\n• 국세청 PDF 예제값 대비 오차 ±1원 이내",
            "testStrategy": "coverage run -m pytest && coverage html → 95% 이상 여부 CI에서 체크"
          }
        ]
      },
      {
        "id": 7,
        "title": "/history 엔드포인트 구현",
        "description": "Redis 에 저장된 최근 k턴 대화내역을 조회하여 반환한다.",
        "details": "• routes/history.py\n    @router.get(\"/history/{session_id}\")\n    async def history(session_id:UUID):\n        msgs = redis_client.lrange(f\"session:{session_id}\",0,k-1)\n        return [HistoryItem.model_validate_json(m) for m in msgs]\n• FastAPI response_model=List[HistoryItem]",
        "testStrategy": "pytest 로 대화 3턴 입력 후 GET /history 반환 길이 3 확인 및 순서 역순 아님 확인",
        "priority": "medium",
        "dependencies": [],
        "status": "deferred",
        "subtasks": []
      },
      {
        "id": 8,
        "title": "/evaluate 엔드포인트 및 RAGAS 배치 스크립트",
        "description": "이미 구현-완료된 auto_rag/mod/evaluation_manager.py 를 활용해 POST /evaluate 로 들어온 dataset_id 를 Celery 비동기 작업으로 전달하고 RAGAS 메트릭( faithfulness, answer_relevancy, context_precision, context_recall )을 산출‧저장한다.",
        "status": "done",
        "dependencies": [],
        "priority": "medium",
        "details": "• poetry add ragas==0.2 celery[redis] 은 선행 작업에서 반영 완료\n• auto_rag/mod/evaluation_manager.py\n    class EvaluationManager:\n        @staticmethod\n        def evaluate(dataset_id:str)->dict:  # faithfulness, answer_relevancy, context_precision, context_recall\n            ...  # 구현 완료\n• tasks/eval.py\n    @celery_app.task(name=\"run_ragas\")\n    def run_ragas(dataset_id:str):\n        metrics = EvaluationManager.evaluate(dataset_id)\n        store_results(metrics)  # DB 또는 S3 저장 모듈 재사용\n        return metrics\n• routes/evaluate.py\n    @router.post(\"/evaluate\")\n    async def evaluate(req:EvalRequest):\n        task_id = run_ragas.delay(req.dataset_id)\n        return {\"task_id\": task_id}\n• GitHub Actions 배치 실행 유지: schedule: \"0 3 * * *\" → poetry run celery -A tasks.eval\n",
        "testStrategy": "pytest 에서 dataset fixture 로 run_ragas.s(dataset_id).apply().get() 호출 후 반환 dict 에 faithfulness, answer_relevancy, context_precision, context_recall 키가 모두 존재하고 float 값임을 확인한다.",
        "subtasks": []
      },
      {
        "id": 9,
        "title": "LangSmith 및 OpenTelemetry 관측성 통합",
        "description": "auto_rag 모듈 전반(RAG 코어, Streamlit, FastAPI 서버)에 LangSmith 및 OpenTelemetry 기반 분산 추적을 적용해 모든 문서 검색·LLM 호출·API 요청의 지연시간과 오류율을 LangSmith 대시보드에서 확인할 수 있도록 한다.",
        "status": "done",
        "dependencies": [],
        "priority": "medium",
        "details": "• poetry add langsmith==0.3 opentelemetry-sdk opentelemetry-exporter-otlp\n• auto_rag/mod/langsmith_monitor.py: LangSmith Client, trace 컨텍스트 매니저, get_tracer 헬퍼 구현\n• rag_system_manager.py: get_answer() 내부에서 문서 검색 span, LLM 호출 span 분리\n• FastAPIInstrumentor.instrument_app(app, excluded_urls=\"/health,/docs\")\n• Streamlit·WebSocket 경로에도 langsmith_monitor.trace 사용\n• settings(.env): LANGSMITH_API_KEY, LANGSMITH_PROJECT, OTEL_EXPORTER_OTLP_ENDPOINT 등 환경 변수 정의",
        "testStrategy": "1) pytest -k \"langsmith\" → get_answer() 호출 시 run_id·parent span 구조 확인\n2) Streamlit 앱에서 실제 질문 입력 후 LangSmith UI에서 트레이스 트리 확인\n3) Locust 100 rps 부하 → OTLP Collector에서 샘플링 100% 및 Span 수 = 요청 수 * 3(get_answer, search, call_llm) 검증\n4) FastAPI WebSocket 채널 /chat 스트리밍 호출 시 Span 누락 없는지 확인",
        "subtasks": [
          {
            "id": 1,
            "title": "LangSmith 기본 설정 및 모니터링 모듈 생성",
            "description": "auto_rag/mod/langsmith_monitor.py를 생성하여 LangSmith Client 래퍼, trace 컨텍스트 매니저, get_tracer를 구현하고 LANGSMITH_API_KEY 등 환경 변수를 설정한다.",
            "status": "done",
            "dependencies": [],
            "details": "• poetry add langsmith==0.3 opentelemetry-sdk opentelemetry-exporter-otlp\n• .env 및 settings.py에 LANGSMITH_API_KEY, LANGSMITH_PROJECT, OTEL_EXPORTER_OTLP_ENDPOINT, OTEL_SDK_DISABLED=false 추가\n• langsmith_monitor.py\n    from langsmith import Client\n    from opentelemetry import trace\n    _client = Client()\n    def trace_span(name: str):\n        ...  # contextmanager로 Span 시작/종료 및 LangSmith 기록\n• 초깃값으로 trace_span(\"init\") 호출하여 모듈 import 시 LangSmith 연결 확인",
            "testStrategy": "pytest auto_rag/tests/test_monitor.py → trace_span(\"dummy\") 사용 시 LangSmith run_id 반환 여부 확인"
          },
          {
            "id": 2,
            "title": "auto_rag RAG 시스템에 LangSmith 추적 적용",
            "description": "rag_system_manager.py의 get_answer() 메서드에 LangSmith 추적을 추가하고, 문서 검색과 LLM 호출을 별도 Span으로 분리한다.",
            "status": "done",
            "dependencies": [
              1
            ],
            "details": "• rag_system_manager.py\n    from auto_rag.mod.langsmith_monitor import trace_span\n    def get_answer(question):\n        with trace_span(\"get_answer\"):\n            with trace_span(\"vector_search\"):\n                docs = vectordb.similarity_search(question)\n            with trace_span(\"call_llm\"):\n                answer = llm.invoke(docs, question)\n            return answer\n• 호출 스택에 tags={\"component\":\"RAG\"} 부여",
            "testStrategy": "pytest → get_answer('세율은?') 호출 후 LangSmith 대시보드에서 get_answer > vector_search > call_llm 계층 구조 확인"
          },
          {
            "id": 3,
            "title": "Streamlit 앱에서 LangSmith 통합 테스트",
            "description": "rag_streamlit_v2.py에서 모니터링된 RAG 시스템을 사용해 실제 질문을 입력하고 LangSmith 대시보드에서 트레이스를 시각적으로 검증한다.",
            "status": "done",
            "dependencies": [
              2
            ],
            "details": "• rag_streamlit_v2.py\n    from auto_rag.mod.langsmith_monitor import trace_span\n    with trace_span(\"streamlit_session\"):\n        answer = rag_manager.get_answer(query)\n• st.button(\"LangSmith 열기\") 클릭 시 대시보드 링크 제공",
            "testStrategy": "streamlit run rag_streamlit_v2.py → '장기보유특별공제' 질문 후 LangSmith에서 streamlit_session 포함 여부 확인"
          },
          {
            "id": 4,
            "title": "API 서버로 확장 및 FastAPI 인스트루먼트 적용",
            "description": "api/services/rag_config_service.py, server.py(WebSocket) 등에 LangSmith 추적을 적용하고 FastAPIInstrumentor를 사용해 전체 시스템 성능을 검증한다.",
            "status": "done",
            "dependencies": [
              3
            ],
            "details": "• api/services/rag_config_service.py\n    with trace_span(\"rag_api_request\"):\n        answer = rag_manager.get_answer(req.question)\n• server.py\n    FastAPIInstrumentor.instrument_app(app, excluded_urls=\"/health,/docs\")\n    WebSocket 엔드포인트 on_receive 내부에 trace_span(\"ws_message\") 적용\n• Locustfile.py에서 100 rps 부하 시 모든 Span 수집 확인",
            "testStrategy": "Locust 부하 테스트 결과 → OTLP Collector에서 rag_api_request + vector_search + call_llm span 누락 0건, P95 지연시간 < 400ms"
          }
        ]
      },
      {
        "id": 10,
        "title": "OpenAPI 문서 검수 및 전면 단위 테스트 보강",
        "description": "FastAPI 자동 스키마를 검토하고 pydantic 모델 예제 추가, pytest 에서 모든 라우트 케이스를 커버 후 CI 배지 표시.",
        "details": "• main.py 에 app = FastAPI(openapi_tags=[...])\n• 각 모델 Config.model_config[\"json_schema_extra\"] 로 example 삽입\n• pytest-cov 및 fastapi-testclient 로 /chat,/history,/evaluate 표준 시나리오 작성\n• README.md 에 coverage badge, docs url 명시",
        "testStrategy": "pytest-cov 90% 기준을 GH Actions에서 강제, schemathesis 로 openapi.yaml fuzz => 0 error 통과",
        "priority": "medium",
        "dependencies": [],
        "status": "deferred",
        "subtasks": [
          {
            "id": 1,
            "title": "FastAPI OpenAPI 스키마 및 태그 메타데이터 검토",
            "description": "main.py에서 FastAPI 인스턴스의 openapi_tags 및 메타데이터 구성을 검토하고, API 문서의 태그 구조와 설명이 명확하게 정의되어 있는지 확인한다.",
            "dependencies": [],
            "details": "app = FastAPI(openapi_tags=[...]) 구문을 점검하고, 각 태그의 name, description, externalDocs 등 필드가 적절히 작성되어 있는지 검토한다.",
            "status": "done",
            "testStrategy": "Swagger UI(/docs)와 ReDoc(/redoc)에서 태그별 분류 및 설명이 올바르게 노출되는지 시각적으로 확인한다."
          },
          {
            "id": 2,
            "title": "Pydantic 모델에 예제(example) 추가",
            "description": "각 Pydantic 모델의 Config.model_config[\"json_schema_extra\"]에 example 데이터를 삽입하여 OpenAPI 문서에 예시가 노출되도록 보강한다.",
            "dependencies": [
              "10.1"
            ],
            "details": "모든 요청/응답 모델에 대해 realistic한 예제 값을 작성하고, model_config[\"json_schema_extra\"]에 example 필드를 추가한다.",
            "status": "done",
            "testStrategy": "Swagger UI에서 각 모델의 example이 정상적으로 노출되는지 확인한다."
          },
          {
            "id": 3,
            "title": "pytest-cov 및 fastapi-testclient 기반 라우트 단위 테스트 작성",
            "description": "/chat, /history, /evaluate 등 모든 주요 라우트에 대해 표준 시나리오 단위 테스트를 작성하고, pytest-cov로 커버리지를 측정한다.",
            "dependencies": [
              "10.2"
            ],
            "details": "pytest, pytest-cov, fastapi.testclient를 활용하여 정상/비정상 입력, 경계값 등 다양한 케이스를 테스트한다.",
            "status": "in-progress",
            "testStrategy": "pytest 실행 시 커버리지 90% 이상 달성 및 모든 테스트가 통과하는지 확인한다."
          },
          {
            "id": 4,
            "title": "CI 환경에서 커버리지 및 OpenAPI 문서 검증 자동화",
            "description": "GitHub Actions 등 CI 환경에서 pytest-cov, schemathesis 등을 활용해 커버리지 및 OpenAPI 스키마 기반 fuzz 테스트를 자동화한다.",
            "dependencies": [
              "10.3"
            ],
            "details": "pytest-cov로 커버리지 90% 미만 시 실패하도록 설정하고, schemathesis로 openapi.yaml 기반 fuzz 테스트를 수행해 0 error를 보장한다.",
            "status": "pending",
            "testStrategy": "CI 워크플로우에서 커버리지 미달 또는 스키마 오류 발생 시 빌드가 실패하는지 검증한다."
          },
          {
            "id": 5,
            "title": "README.md에 커버리지 배지 및 문서 링크 추가",
            "description": "최신 커버리지 상태를 보여주는 badge와 /docs, /redoc 등 API 문서 링크를 README.md에 명시한다.",
            "dependencies": [
              "10.4"
            ],
            "details": "shields.io 등에서 제공하는 커버리지 배지 URL을 삽입하고, API 문서 접근 경로를 명확히 안내한다.",
            "status": "pending",
            "testStrategy": "README.md 렌더링 시 배지와 문서 링크가 정상적으로 표시되는지 확인한다."
          }
        ]
      },
      {
        "id": 11,
        "title": "프로젝트 디렉터리 재설계 및 server 모듈 마이그레이션",
        "description": "기존 rag_lab 개발 구조(auto_rag 포함)는 그대로 유지하면서, 팀 배포용으로 완전히 독립적인 server 모듈을 추가한다. server 모듈은 오직 FastAPI 백엔드만 제공하며, 프론트엔드는 별도(Next.js/Streamlit) 애플리케이션에서 API·WebSocket 형태로 접근한다.",
        "status": "done",
        "dependencies": [
          8,
          9
        ],
        "priority": "high",
        "details": "핵심 변경점\n1. 기존 소스는 건드리지 않는다.\n2. rag_lab/server/ 이하에 배포 전용 모듈을 구성한다.\n3. auto_rag 코드와 공용 유틸을 server/modules 로 ‘복사’(rsync) 하여 독립 패키지화한다.\n4. server 내 모든 import 는 server.*** 또는 상대경로로 정리해 외부 의존을 제거한다.\n5. server/main.py 는 FastAPI 백엔드만 실행한다(uvicorn).\n6. CORS 미들웨어를 추가하여 외부 도메인(프론트엔드) 접근을 허용한다.\n7. 팀원은 server/ 폴더만 받아서 `PYTHONPATH=. python main.py` 로 즉시 실행 가능해야 한다.",
        "testStrategy": "1. 정적 검사\n   cd server && ruff check . && mypy modules api\n   → ModuleNotFound / import cycle 0건\n\n2. 독립 실행 확인\n   cd server && PYTHONPATH=. python main.py &\n   → http://localhost:8000/health 200 OK\n   → 응답 헤더 Access-Control-Allow-Origin: * 확인\n\n3. 원본 개발 환경 회귀\n   cd .. && poetry run pytest\n   → 기존 Task 8·9 테스트 100% 통과\n\n4. Docker-Compose\n   docker-compose -f deploy/docker-compose.yml up -d\n   → 컨테이너 내부에서 server/main.py 자동 기동, 로그 에러 0\n\n5. 패키징 테스트\n   tar -czf server.tgz server && mkdir /tmp/test && cd /tmp/test && tar -xzf ~/server.tgz\n   PYTHONPATH=. python server/main.py → 모든 API 엔드포인트 정상 동작",
        "subtasks": [
          {
            "id": 1,
            "title": "server 폴더 및 하위 구조 생성",
            "description": "rag_lab 루트에 server 폴더를 만들고 raw_data, chroma_db, api, modules, web 디렉터리를 생성한다.",
            "status": "done",
            "dependencies": [],
            "details": "mkdir -p server/{raw_data,chroma_db,api,modules,web} && touch server/__init__.py",
            "testStrategy": "ls -R server | grep -E \"raw_data|chroma_db|api|modules|web\" 가 모두 확인된다."
          },
          {
            "id": 2,
            "title": "기존 auto_rag 코드 server/modules 로 복사하여 독립성 확보",
            "description": "auto_rag 디렉터리 전체를 server/modules 로 ‘복사’하고, 원본은 그대로 두어 개발 환경을 유지한다.",
            "status": "done",
            "dependencies": [
              1
            ],
            "details": "rsync -a auto_rag/ server/modules/ --exclude tests\n복사 후 server/modules/__init__.py 에 패키지 초기화 코드만 추가하고 shim 은 두지 않는다.",
            "testStrategy": "복사 완료 후 server/modules 내 소스 수량이 auto_rag 와 동일하고, git status 에 auto_rag 변경이 없는지 확인한다."
          },
          {
            "id": 3,
            "title": "server 내부 import 및 실행 스크립트 일괄 수정",
            "description": "server 폴더 안에서만 auto_rag → server.modules 로 import 경로를 치환하고 외부 참조를 제거한다.",
            "status": "done",
            "dependencies": [
              2
            ],
            "details": "grep -Rl \"auto_rag\" server | xargs sed -i 's/auto_rag/server.modules/g'\n하드코딩된 상대경로, 환경 변수 등을 server 기준으로 수정한다.",
            "testStrategy": "cd server && python -m compileall . 로 SyntaxError, ImportError 가 없는지 확인한다."
          },
          {
            "id": 4,
            "title": "main.py FastAPI 런처 구현",
            "description": "server/main.py 하나로 FastAPI API만 실행하도록 uvicorn 런처 및 CORS 설정을 추가한다.",
            "status": "done",
            "dependencies": [
              3
            ],
            "details": "main.py 예시\n    from fastapi import FastAPI\n    from fastapi.middleware.cors import CORSMiddleware\n\n    app = FastAPI(title=\"Tax RAG API\")\n    app.add_middleware(\n        CORSMiddleware,\n        allow_origins=[\"*\"],\n        allow_credentials=True,\n        allow_methods=[\"*\"],\n        allow_headers=[\"*\"],\n    )\n\n    @app.get(\"/health\")\n    async def health():\n        return {\"status\": \"ok\"}\n\n    if __name__ == \"__main__\":\n        import uvicorn\n        uvicorn.run(\"server.api.main:app\", host=\"0.0.0.0\", port=8000)\n\n<info added on 2025-07-20T19:45:30.930Z>\n업데이트 내역  \n• Streamlit 관련 파일·requirements·Docker layer 전부 삭제 완료  \n• server/modules/fastapi_app.py  \n    from fastapi import FastAPI  \n    from fastapi.middleware.cors import CORSMiddleware  \n\n    app = FastAPI(title=\"Tax RAG API\")  \n    app.add_middleware(  \n        CORSMiddleware,  \n        allow_origins=[\"*\"],  \n        allow_credentials=True,  \n        allow_methods=[\"*\"],  \n        allow_headers=[\"*\"],  \n    )  \n\n    @app.get(\"/health\")  \n    async def health():  \n        return {\"status\": \"ok\"}  \n\n• server/main.py  \n    def run():  \n        import uvicorn  \n        uvicorn.run(\"server.modules.fastapi_app:app\", host=\"0.0.0.0\", port=8000)  \n\n    if __name__ == \"__main__\":  \n        run()  \n\n• poetry [tool.poetry.scripts] 섹션에 ‘tax-rag-api = \"server.main:run\"’ 추가 → `poetry run tax-rag-api` 로 단일 포트(8000) 기동  \n• CI 테스트: httpx.AsyncClient 로 GET /health → 200 & {\"status\":\"ok\"} 확인\n</info added on 2025-07-20T19:45:30.930Z>",
            "testStrategy": "PYTHONPATH=. python server/main.py & 후 8000/health 접속 및 CORS 헤더 확인"
          },
          {
            "id": 5,
            "title": "server 전용 패키징 및 CI 설정",
            "description": "server/ 폴더에 독립 pyproject.toml 또는 requirements.txt를 두고 GitHub Actions 워크플로우를 추가한다.",
            "status": "done",
            "dependencies": [
              4
            ],
            "details": "server/pyproject.toml 에 include = [\"server\"] 설정, dependency 목록에서 streamlit 제거\n.github/workflows/server.yml → cd server && poetry install && pytest 단계 추가",
            "testStrategy": "PR 생성 시 server 워크플로우가 실행되고 모든 단계가 green 인지 확인"
          },
          {
            "id": 6,
            "title": "문서 및 README, 배포 가이드 작성",
            "description": "README에 server 모듈 사용법을 추가하고 docs/server_migration.md에 복사 전략·import 변경·실행 방법 등을 기록한다.",
            "status": "done",
            "dependencies": [
              5
            ],
            "details": "PlantUML 구조도(개발 vs 배포) 삽입, ‘server만 전달’ 절차와 환경 변수(.env.sample) 설명 작성",
            "testStrategy": "팀원 1명이 README만 보고 server 폴더를 ZIP으로 받아 실행해 보며 피드백을 수집한다."
          },
          {
            "id": 7,
            "title": "문서 업데이트: Streamlit 관련 내용 제거 및 CORS 설명 추가",
            "description": "기존 배포 문서와 README에서 Streamlit/웹 실행 섹션을 삭제하고, 외부 프론트엔드와의 API·WebSocket 사용 예시 및 CORS 설정 방법을 반영한다.",
            "status": "done",
            "dependencies": [
              6
            ],
            "details": "docs/server_migration.md, README.md 에서 8501 포트·Streamlit 언급 제거\n`curl` 예시, Next.js fetch 예시 추가\n개발/운영 환경에서 ALLOWED_ORIGINS 설정 방법 명시",
            "testStrategy": "팀원 1명이 수정된 문서만 보고 로컬 프론트엔드에서 API 호출해 성공 여부 확인"
          }
        ]
      },
      {
        "id": 12,
        "title": "문서 관리 API 리팩토링 및 기능 개선",
        "description": "/api/documents 라우트를 전면 개편하여 문서별 청킹 설정 저장, 업로드·삭제·동기화 로직을 개선하고, 메타데이터·보안·비동기 처리를 강화한다.",
        "status": "done",
        "dependencies": [],
        "priority": "high",
        "details": "본 리팩토링은 기존 요구사항(청킹 설정·업로드·삭제·동기화) 위에 아래와 같은 아키텍처 개선 사항을 추가 반영한다.\n\n1) 디렉터리/파일 구조 고도화\n   • server/raw_data/{doc_id}/original_file.xxx\n   • server/raw_data/{doc_id}/config.json  (DocumentConfig 모델 직렬화)\n   • server/raw_data/{doc_id}/metadata.json (파일명·MIME·페이지 수 등 저장)\n\n2) Pydantic 기반 DocumentConfig 스키마 도입\n   class DocumentConfig(BaseModel):\n       chunk_size: int = Field(gt=0, le=2000)\n       chunk_overlap: int = Field(ge=0)\n       created_at: datetime\n       updated_at: datetime\n       version: int = 1\n       @validator('chunk_overlap')\n       def overlap_lt_size(cls, v, values):\n           if 'chunk_size' in values and v >= values['chunk_size']:\n               raise ValueError('chunk_overlap must be less than chunk_size')\n           return v\n\n3) 보안 & 유효성 계층 강화\n   • server/modules/utils/security.py → validate_document_path(doc_id, base_path) 구현(정규식, resolve, startswith 검증)\n   • ChunkConfigValidator(MIN/MAX/비율 규칙) 추가, 모든 입력 검증에 활용.\n   • DirectoryTraversalError, ConfigurationError 등 커스텀 예외와 FastAPI Global ExceptionHandler 등록.\n\n4) 서비스 계층 분리\n   • DocumentLifecycleService(create_document, update_config, sync_single_document, sync_all_documents)\n   • DocumentStorageService, DocumentConfigService, ConfigurableIngestionService 등 세분화.\n   • create_document: 파일 저장 + metadata.json + 기본 config 작성 → 트랜잭션 롤백 지원.\n\n5) API 엔드포인트 변경 사항(Async & BackgroundTasks)\n   • POST /api/documents/upload-file      : 파일 Form 업로드, 201 Created {doc_id, status, processing}\n   • POST /api/documents/{doc_id}/config  : DocumentConfigUpdate 모델 수신, 200 OK {status:\"updated\"}\n   • DELETE /api/documents/{doc_id}       : 보안 검증 후 물리 삭제, 204 No Content\n   • GET   /api/documents/sync            : doc_id 선택/미지정, force 옵션, 대용량은 BackgroundTasks\n\n6) ingest_document 리팩토링\n   • ingest_document(doc_id, force_reindex=False) → config.json을 로드해 청킹 인수로 사용.\n\n7) 마이그레이션 스크립트 확장\n   • scripts/backfill_default_config.py : config.json 없는 문서는 DEFAULT 값으로 생성, metadata.json 없으면 자동 생성.\n\n8) 문서화(OpenAPI tags=[\"Documents\"]) 및 로깅(structlog) 추가.",
        "testStrategy": "1) 단위 테스트 (pytest + pytest-asyncio)\n   a. test_config_endpoint\n      • 정상: POST /documents/{doc_id}/config 로 size=800, overlap=200 → 200 OK & config.json 업데이트, vector invalidation 모의 확인\n      • 오류: size=40(<50) → 422, overlap=900(>=size) → 422, 잘못된 doc_id 형식 → 400\n   b. test_upload_file\n      • PDF 업로드 → 201 Created, 반환 JSON {doc_id, status:\"uploaded\"}; RAW_DATA_DIR/{doc_id}/original_file.pdf, config.json, metadata.json 존재\n      • 대용량(>LARGE_FILE_THRESHOLD) 업로드 시 processing==True, BackgroundTasks mock 호출 확인\n   c. test_delete_security\n      • DELETE /documents/../../evil → 400 DirectoryTraversalError\n      • DELETE /documents/{valid_doc_id} → 204 & 폴더 미존재 확인\n   d. test_sync_endpoint\n      • GET /documents/sync?doc_id={doc_id} → 200, ingest_document 호출(config 기반) mock 확인\n      • GET /documents/sync?force=true 전체 대상 → BackgroundTasks 로 전체 문서 ingest 호출\n   e. security_validation\n      • validate_document_path 정규식 미일치 → 예외 발생\n      • ChunkConfigValidator 비율 초과(overlap>size*0.5) → ValueError\n\n2) 통합 테스트\n   • docker-compose up services 후 FastAPI TestClient 로 전체 플로우(업로드→config수정→sync→삭제) 검증, 커버리지 90% 이상.\n   • schemathesis run http://localhost:8000/openapi.json -E \"^/chat|/history\" : 0 error.\n\n3) 회귀 테스트\n   • 기존 /chat, /evaluate 워크플로 실행 → 결과 동일·에러 없음 확인.\n\n4) 보안 테스트\n   • OWASP ZAP baseline 스캔: path traversal, 파일 업로드 취약점 0건.",
        "subtasks": [
          {
            "id": 1,
            "title": "Config 엔드포인트 구현 및 유효성 검사",
            "description": "POST /api/documents/{doc_id}/config 엔드포인트를 DocumentConfig 모델 기반으로 구현하고, doc_id 형식·경로·비즈니스 규칙(MIN/MAX, overlap 비율) 검증 및 vector 재인덱스 무효화를 포함한다.",
            "status": "done",
            "dependencies": [],
            "details": "• server/modules/document_service.py → update_config 구현\n• DocumentConfigService.save_config() 사용, validate_document_path 및 ChunkConfigValidator 적용\n• 성공 시 200 {status:\"updated\"}, 실패 시 404/422/400 반환\n• structlog 로깅 및 Global ExceptionHandler 연동\n<info added on 2025-07-20T20:02:24.161Z>\n• services/document_config_service.py 에서 비동기 update_config 구현: 기존 config 백업 → 임시 파일 쓰기 → atomic replace, 실패 시 백업 롤백 후 structlog error 로그 및 ConfigurationError 발생, 성공 시 vector_service.invalidate_document_cache 호출 및 config_updated 로그 기록  \n• validators/chunk_validator.py 추가: MIN(50)/MAX(2000) chunk_size, MAX_OVERLAP_RATIO(0.5) 검증 및 권장 비율 기반 warnings 반환  \n• api/routers/documents.py POST /{doc_id}/config 라우트 구현: Path regex 검증, Body(DocumentConfigUpdate) 수신 → ChunkConfigValidator.validate_config 실행, 오류 시 422(detail:{errors,warnings}), 성공 시 ConfigUpdateResponse(status=\"updated\", version, warnings) 반환  \n• exceptions/document_exceptions.py 정의 및 전역 핸들러 등록: DocumentNotFoundError(404), ConfigurationError(422), DirectoryTraversalError(400)  \n• tests/test_config_endpoint.py 작성: 성공 업데이트, 검증 실패, 잘못된/미존재 doc_id 케이스, vector_service.invalidate_document_cache 호출 여부 검증  \n• 의존성: aiofiles(비동기 I/O), structlog, pydantic, security utils(경로 검증), VectorService  \n• 성능/신뢰성: 원자적 파일 교체 + 백업·롤백, 비동기 I/O, config 버전 관리, 구조화 로깅\n</info added on 2025-07-20T20:02:24.161Z>\n<info added on 2025-07-20T22:11:14.641Z>\n• DocumentConfigService v2 설계  \n  – backend/config/document_config_service.py 로 이동, IConfigRepository 인터페이스 분리(파일·S3·DB 구현체 교체 용이)  \n  – set_config() 내부에서: tmp 파일 작성 → os.replace 로 원자적 교체 → 성공 시 `_history/{doc_id}-{timestamp}.json` 백업 저장 후 semver 패치 버전 부여  \n  – get_latest_config(doc_id, env=\"default\") 호출 시 ENV_OVERRIDES/{env}/{doc_id}.json 우선 → 없으면 기본값 병합(fallback) 후 반환  \n  – update 시 vector_service.invalidate_document_cache(doc_id) 비동기 publish → EventBus(\"config.updated\") 로 브로드캐스트, 수신자는 LRUVectorCache.clear(doc_id) 수행  \n  – __call__ 주입(Depends) 가능하도록 singleton FastAPIDependencyProvider 구현\n\n• FastAPI 라우터 /api/config/documents  \n  – GET /api/config/documents/{doc_id} → Query env, version(optional) 지원, 200 {version, config, warnings[]}  \n  – PUT /api/config/documents/{doc_id} → Body: DocumentConfigUpdate, 헤더 X-User-Id 로 호출 주체 확인, 성공 시 200 {status:\"updated\", version, warnings}  \n  – 라우터 레이어에서 RBAC: SecurityScopes([\"config:write\"]) 검사, 권한 없을 경우 403  \n  – Router 모듈: api/routers/document_configs.py, APIRouter(prefix=\"/api/config/documents\", tags=[\"document-config\"])  \n  – async def put_config(): validator.validate(), svc.set_config(), AuditLog.record(\"CONFIG_UPDATE\", user_id, doc_id, version)\n\n• Pydantic 스키마  \n  class DocumentChunkOptions(BaseModel):  \n      chunk_size: conint(ge=100, le=2000) = 512  \n      overlap_ratio: confloat(ge=0, le=0.5) = 0.1  \n  class DocumentConfigModel(BaseModel):  \n      chunk: DocumentChunkOptions  \n      metadata: dict[str, Any] | None = None  \n      model_config = ConfigDict(extra=\"forbid\")\n\n• 보안/검증 메커니즘  \n  – PathTraversalGuard.validate(doc_id, allowed_root) 로 디렉터리 탈출 차단  \n  – validator.validate() 에서 범위 초과 시 ValidationError ▶ 422  \n  – 권한 검사는 fastapi.security.HTTPBearer + RoleVerifier(role_map)  \n  – 감사 로그: structlog.bind(event=\"audit\", action, user, doc_id, version).info(\"config_update\")  \n  – 기본값 fallback: Model.model_validate(default_config | env_override | user_patch, validation_context=\"merge\")\n\n• 트랜잭션/에러 핸들링  \n  – Any I/O 실패 시 BackupRestorer.rollback(tmp_path, backup_path) 호출 후 ConfigurationError  \n  – GlobalExceptionHandler 등록: ConfigurationError→422, PermissionError→403, FileNotFoundError→404\n\n• 캐시 무효화 이벤트 시스템  \n  – infra/events.py: class EventBus(asyncio.Queue) publish/subscribe  \n  – put_config 에서 await event_bus.publish(ConfigUpdatedEvent(doc_id, version))  \n  – vector_cache_listener.py subscribe 후 invalidate_document_cache\n\n• 확장성 고려  \n  – 기존 ChromaDBManager 의 get_collection(doc_id) 호출부를 ConfigProvider 인터페이스로 치환 → 향후 다른 VectorDB 도 동일 컨피그 사용  \n  – DocumentService 에서 직접 파일 접근 제거 → DocumentConfigService 경유만 허용하여 계층 분리 완료\n</info added on 2025-07-20T22:11:14.641Z>",
            "testStrategy": "정상/비정상 config 업데이트, 잘못된 doc_id 형식, overlap>=size, 최소 chunk_size 미만 등 케이스 테스트"
          },
          {
            "id": 2,
            "title": "파일 업로드 엔드포인트 리팩토링",
            "description": "POST /api/documents/upload-file 엔드포인트를 비동기 Form 업로드로 구현하고, 파일 저장·metadata.json·기본 config.json 생성 및 대용량 BackgroundTasks 처리를 포함한다.",
            "status": "done",
            "dependencies": [],
            "details": "doc_id = slugify(filename)+timestamp(정규식 만족), DocumentLifecycleService.create_document() 호출, metadata.json에는 파일명·MIME·upload_ts 저장\n<info added on 2025-07-20T20:03:48.889Z>\n• 비동기 업로드 라우트  \n  POST /api/documents/upload-file → DocumentLifecycleService.create_document() 호출 후 DocumentUploadResponse 반환, Location 헤더 `/api/documents/{doc_id}` 설정\n\n• DocumentLifecycleService  \n  – _generate_doc_id(): slugify(파일명) + 13자리 millisecond 타임스탬프 → 정규식 `^[a-zA-Z0-9_-]+_\\d{13}$` 검증 실패 시 ValueError  \n  – create_document(): 디렉터리 생성 → 원본 파일 저장 → metadata.json → 기본 config.json 순으로 원자적 처리, 실패 시 _rollback_creation() 으로 복구\n\n• DocumentStorageService  \n  – 업로드 가능 MIME: pdf, txt, md, docx  \n  – 최대 크기 100 MB, 파일명에 `..` 금지  \n  – `raw_data/{doc_id}/original.{ext}` 로 스트림 저장(aiofiles, 8 KB 버퍼)\n\n• DocumentMetadataService  \n  – metadata.json 필드: original_filename, content_type, file_size, upload_timestamp, file_hash(SHA-256), page_count(PDF 한정), language, extracted_text_preview(옵션)  \n  – 파일 해시·페이지 수 추출 후 pydantic 직렬화\n\n• 대용량 파일 처리  \n  – `LARGE_FILE_THRESHOLD` 초과 시 BackgroundTasks 로 extract_full_text / generate_preview / index_document 실행, 응답에서 processing=true 및 예상 처리 시간(“2-5 minutes”) 포함\n\n• 오류 처리  \n  – FileValidationError → 400, DocumentCreationError → 500, 기타 예외 로깅 후 500\n\n• 단위 테스트(pytest-asyncio)  \n  1. PDF 정상 업로드(201, 파일 구조 검증)  \n  2. 대용량 업로드 → processing 플래그 확인  \n  3. 허용되지 않는 MIME → 400  \n  4. 크기 초과 → 400\n\n• 의존 패키지: aiofiles, python-slugify, PyPDF2, python-multipart, structlog\n\n• 성능·보안  \n  – 스트림 방식으로 메모리 사용 최소화  \n  – SHA-256 해시·파일 유형 검증으로 무결성 보장  \n  – 트랜잭션 유사 롤백으로 중간 실패 시 잔여 파일/디렉터리 자동 정리\n</info added on 2025-07-20T20:03:48.889Z>\n<info added on 2025-07-20T22:12:11.040Z>\n• DocumentLifecycleService 리디자인  \n  – UploadSession 모델(upload_id, total_bytes, received_bytes, status, started_at, finished_at)을 Redis Hash로 관리, Pub/Sub 로 진행률 이벤트 발행(`upload_progress:{upload_id}` 채널)  \n  – stream_to_storage(upload_file: UploadFile, session) → 8 KB 청크 단위로 aiofiles.write, 매 500 ms 마다 session.received_bytes 갱신 & 이벤트 전송  \n  – MetadataExtractor 추상 클래스(register_extractor) + 구체 구현(PDFExtractor, TxtExtractor, DocxExtractor), create_document() 내부에서 파일 저장 직후 extractor 선택 → extract() 결과를 pydantic MetadataModel 로 리턴  \n  – PostProcessPipeline(background=True) 단계화: full-text 추출 → preview 생성 → 검색 인덱싱, 각 스텝 실패 시 retry(3회, 지수 백오프) 및 session.status=“error” 갱신  \n\n• 파일 업로드 로우-레벨 최적화  \n  – UploadFile.read(CHUNK_SIZE) 대신 await upload_file.seek(0) + iter_chunked(upload_file.file, CHUNK_SIZE) 패턴으로 파일-like 객체 직접 스트림  \n  – CHUNK_SIZE=64 KB, aiofiles buffered writer(write_through=False) 사용으로 sys-call 감소  \n  – 임계치(500 MB) 초과 시 /tmp/%(uuid)s.part 에 임시 저장 후 move(atomic) → 종료 시 finally 블록에서 .part 파일 존재 여부 확인 후 삭제  \n\n• 메타데이터 파싱 세부 전략  \n  – PDF: PyPDF2 로 페이지 수, writer.Info 에서 author/title, pdfminer.six 로 첫 1,000 자 텍스트 미리보기  \n  – TXT: chardet 로 인코딩 감지 후 universal newline 변환, 첫 20 줄 요약 저장  \n  – DOCX: python-docx → core_properties, paragraph extract; 이미지 포함 여부 flag  \n  – 공통: hashlib.sha256 스트림 계산, file_size != os.path.getsize 검증 → 불일치 시 ValidationError  \n\n• 보안/성능 강화  \n  – 파일 저장 직전 clamdscan async wrapper로 바이러스 검사, 1 초 타임아웃 발생 시 즉시 중단 및 502 반환  \n  – create_document() 내부 asyncio.to_thread 로 CPU 바운드 해시·PDF 텍스트 추출 병렬 실행  \n  – AnyIO capacity limiter(uploads=4) 로 동시 업로드 수 제한, 초과 시 429 응답  \n  – FailedStepException 발생 시 _rollback_creation() + add_to_dead_letter(upload_id) 로 후속 재처리 큐에 적재  \n\n• API 레이어 개선  \n  – POST /api/documents/upload-file → 응답 본문에 upload_id 포함, 102 Processing 상황에서는 HTTP-PATCH /api/documents/{upload_id}/cancel 지원  \n  – GET  /api/documents/upload-status/{upload_id} → {status, progress:0-100, eta_seconds} JSON 반환  \n  – WebSocket /ws/uploads/{upload_id} → 서버 → 클라이언트로 progress 이벤트 전송(예: {\"progress\":57})  \n  – POST /api/documents/batch-upload (multipart mixed) → 최대 10 개 파일, 각 파트별 개별 upload_id 할당 후 배열 반환  \n\n• 기존 DocumentService.upload_document 리팩터링 방안  \n  1. 동기식 파일 전체 읽기 로직 제거, 위 stream_to_storage 로 대체  \n  2. 메타데이터 추출 코드를 Extractor 플러그인으로 분리, LSP(단일 책임) 준수  \n  3. 예외 처리 범위를 넓혀 FileValidationError, VirusDetectedError, ExtractorError 세분화  \n  4. unit test: pytest-asyncio 에서 fake UploadFile(iter_bytes) 활용, 100 MB 샘플 파일로 스트레스 테스트, progress 이벤트 수신 검증 (>=5 회)\n</info added on 2025-07-20T22:12:11.040Z>",
            "testStrategy": "PDF 업로드 201 Created, 반환 JSON 검증, RAW_DATA_DIR 구조 및 BackgroundTasks 호출 여부 확인"
          },
          {
            "id": 3,
            "title": "문서 삭제 엔드포인트 강화 및 보안 처리",
            "description": "DELETE /api/documents/{doc_id} 엔드포인트에서 validate_document_path 사용으로 경로 탈출 방지, 미존재 문서 처리, 삭제 후 로그 기록 및 204 응답을 구현한다.",
            "status": "done",
            "dependencies": [],
            "details": "DirectoryTraversalError, DocumentNotFoundError 커스텀 예외 정의 및 FastAPI ExceptionHandler 등록\n<info added on 2025-07-20T22:03:42.713Z>\n추가 구현 세부사항  \n\n• server/modules/utils/security.py  \n  – DocumentSecurityService.validate_document_path(): doc_id 정규식·길이 검증, realpath 기반 디렉터리 탈출 차단  \n  – audit_delete_operation(): structlog 기반 삭제 감사 로그 기록  \n  – DirectoryTraversalError 등 SecurityError 계층 정의  \n\n• server/modules/services/document_delete_service.py  \n  – delete_document():  \n     1) validate_document_path 호출  \n     2) 존재 여부 확인 후 DocumentNotFoundError 발생 처리  \n     3) _validate_deletion_permissions(추후 권한 체크용)  \n     4) _backup_metadata로 삭제 전 메타데이터 스냅샷 확보  \n     5) vector_service.remove_document → 실패해도 파일 삭제 지속  \n     6) _delete_directory_safely(shutil.rmtree)  \n     7) 성공/실패 모두 audit_delete_operation 기록  \n  – DeleteResult Pydantic 모델 반환  \n\n• server/modules/api/routers/documents.py  \n  – DELETE /api/documents/{doc_id} 엔드포인트 강화  \n     · Path 파라미터에 동일 정규식 적용  \n     · DirectoryTraversalError → 400, DocumentNotFoundError → 404, DocumentDeletionError → 500 매핑  \n\n• server/modules/exceptions/document_exceptions.py  \n  – DocumentDeletionError 추가 및 글로벌 ExceptionHandler 등록  \n\n• server/modules/api/models/document.py  \n  – DeleteResult, DocumentDeleteResponse 모델 정의(삭제 파일 수, vector 제거 여부 포함)  \n\n• tests/test_delete_endpoint.py  \n  – 정상 삭제, 경로 탈출 시도, 잘못된 형식, 미존재 문서, 벡터 서비스 실패, 감사 로그 생성 등 6개 시나리오 비동기 테스트 구현  \n\n보안·성능 고려사항  \n- 입력 정규식 및 resolve() 기반 경로 검증으로 DoS·Traversal 차단  \n- 삭제 전 vector DB 제거 → 원자성 확보  \n- 모든 시도에 대해 구조화된 감사 로그 저장, 오류 메시지 최소화 노출  \n\n위 내용을 반영하여 코드·테스트 작성 후 204 No Content 응답이 통과하도록 한다.\n</info added on 2025-07-20T22:03:42.713Z>\n<info added on 2025-07-20T22:12:44.851Z>\n세부 구현 계획(업데이트)\n\n1. DocumentDeleteService 아키텍처\n• SecurityValidator → 모든 입력값·경로·시스템 파일 여부 사전 검증  \n• AccessControlService(RBAC) → user_id·role 기반 소유권·권한 확인  \n• FileDeletionEngine → 원자적 파일 삭제·백업·복구 책임, shutil.rmtree 대신 send2trash + tmp 스테이징 폴더로 안전성 확보  \n• VectorSyncAdapter → Chroma 컬렉션에서 해당 doc_id 임베딩 제거 후 persist  \n• AuditTrailService → structlog + OpenTelemetry trace_id 로 삭제 이력 상시 기록  \n• DeleteOrchestrator → 위 모듈을 순차 실행하고 예외 발생 시 롤백 트리거\n\n2. 보안 검증 메커니즘\n• pathlib.Path.resolve(strict=False) 비교로 디렉터리 탈출·심볼릭 링크 공격 차단  \n• metadata.json 의 owner 필드와 요청자 비교, 불일치 시 PermissionDeniedError 발생  \n• 권한 매트릭스: ADMIN(읽기/삭제/배치)·EDITOR(읽기/삭제)·VIEWER(읽기)  \n• /etc, ~/.ssh 등 시스템 경로 패턴 블랙리스트 및 파일 확장자 화이트리스트 적용\n\n3. 삭제 프로세스 최적화\n• tmp_backup_dir 에 zip 아카이브 후 삭제 실행 → 성공 시 백업 retention=7일 cron 자동 정리  \n• VectorSyncAdapter 실패 시에도 파일 삭제 완료 후 재시도 큐(RQ) 등록  \n• dependency_checker.py 로 하위 파생 파일, 파싱 캐시, 이미지 썸네일 등 연관 아티팩트 동시 정리  \n• sqlite 트랜잭션 + 파일시스템 스테이징 폴더 조합으로 'all-or-nothing' 보장\n\n4. 에러 처리 및 복구\n• 단계별 CustomError 계층: ValidationError → 400, PermissionDeniedError → 403, PartialDeletionError → 409, SystemDeletionError → 500  \n• FileDeletionEngine 실패 시 tmp_backup_dir 을 원위치 복원하고 AuditTrailService 에 rollback=true 플래그 기록  \n• 복구 가능 항목은 DELETE 결과 객체에 recoverable=true 포함, /recover/{doc_id} POST 로 즉시 복구 지원  \n• Sentry 연동으로 상세 stacktrace, doc_id, user_id, trace_id 자동 전송\n\n5. API 엔드포인트 강화\n• DELETE /api/documents/{doc_id}: 헤더 X-Confirm-Delete: true 없으면 428 PreconditionRequired  \n• DELETE /api/documents?ids=doc1,doc2: 최대 20개까지 배치 처리, DeleteBatchResult 반환  \n• 삭제 요청 시 202 Accepted + Location: /delete-jobs/{job_id} 비동기 모드 지원 → SSE 로 진행률 0~100 전송  \n• OpenAPI 문서에 보안 스키마(BearerAuth)·권한 필요 등급·예상 오류 코드(400/403/409/500) 명시\n\n추가 작업 항목\n• tests/test_document_delete_service.py 에 롤백·배치·권한·백업·복구 케이스 10종 작성  \n• docs/openapi/delete.yml 업데이트 및 삭제 플로우 순서도 다이어그램 첨부\n</info added on 2025-07-20T22:12:44.851Z>",
            "testStrategy": "경로 탈출·미존재·정상 삭제 케이스에서 400/404/204 코드 확인"
          },
          {
            "id": 4,
            "title": "동기화(sync) 엔드포인트 개선 및 ingest 리팩토링",
            "description": "GET /api/documents/sync 엔드포인트를 config-driven Ingestion 서비스로 리팩토링하고, 단일/전체 문서 sync, force 옵션, BackgroundTasks 배치 처리 로직을 구현한다.",
            "status": "done",
            "dependencies": [],
            "details": "ConfigurableIngestionService.ingest_document(force_reindex) 사용, DocumentLifecycleService.sync_* 메서드 작성\n<info added on 2025-07-20T22:05:47.000Z>\n• 설정 기반 문서 인제스트 로직(ingest_document) 전체 구현: 문서 별 config 로드→파일 검사→재색인 필요 여부 판단→텍스트 분할→벡터 upsert→ingestion_metadata.json 저장. <server/modules/services/configurable_ingestion_service.py> 추가  \n• DocumentLifecycleService 확장: sync_single_document / sync_all_documents / _discover_documents / _sync_document_safe 등 구현, 배치 크기 10, force 플래그·진행 로그·에러 격리 포함  \n• /api/documents/sync 라우트 리팩토링: 단일·전체 sync 처리, BACKGROUND_SYNC_THRESHOLD 초과 시 BackgroundTasks 로 비동기 실행, SyncResponse·BatchSyncResponse 반환  \n• Pydantic 모델 추가 및 갱신: IngestionResult, SyncResult, BatchSyncResult, SyncResponse, BatchSyncResponse  \n• 테스트 케이스 6종 작성(test_sync_endpoint.py): 단일 sync, 강제 sync, 소규모·대규모 배치, 존재하지 않는 문서, 잘못된 doc_id, config-driven chunking 검증  \n• 성능/아키텍처 개선 사항 문서화: Intelligent Skipping, Batch & Concurrent Processing, Progress Logging, Error Isolation 등\n</info added on 2025-07-20T22:05:47.000Z>\n<info added on 2025-07-20T22:13:37.072Z>\n추가 백엔드 구현 계획\n\n1. ConfigurableIngestionService 아키텍처 확장  \n• BatchOptimizer: 문서 크기·우선순위·IO 대기시간을 고려하여 동적 배치 크기 결정.  \n• BackgroundSyncTracker: BackgroundTasks·Celery 양쪽을 지원하는 추상 레이어, task_id ↔ document_id 매핑 및 상태 저장(redis hash).  \n• ProgressPublisher: ingest 단계별(검사→파싱→분할→업서트) 진행률을 pub/sub(WebSocket, SSE)로 송신.  \n• RetryHandler: 단계별 오류 코드를 분석하여 지수백오프·최대 3회 재시도, 복구 실패 시 dead-letter 큐로 이동.  \n\n2. 동기화 성능 향상 전략  \n• asyncio.TaskGroup + semaphore 로 동시 8~16개 문서 병렬 처리, CPU bound 단계는 run_in_threadpool.  \n• 대용량 파일은 mmap·iter_chunk() 제너레이터로 스트리밍하여 peak 메모리 <100 MB 유지.  \n• incremental_hash(meta, content_hash) 비교로 변경된 블록만 재색인, vecdb.upsert(batch_diff).  \n• DuplicateDetector(redis set)로 같은 해시 재인제스트 방지, hit 시 즉시 skip 로그 기록.  \n\n3. 백그라운드 작업 관리  \n• fastapi_celery.Router 도입: /sync 요청이 BACKGROUND_SYNC_THRESHOLD 초과 시 Celery queue=enrich 로 디스패치.  \n• TaskStatus 모델(id, state, progress, retries, started_at, finished_at) → redis sorted-set(타임라인) 저장, /sync/status/{task_id} API 제공.  \n• on_failure signal 에서 RetryHandler.trigger(); 최대 재시도 초과 시 slack_webhook 알림.  \n• prometheus_client 로 작업 큐 길이·실행 시간·메모리 사용량 지표 노출.  \n\n4. 설정 기반 처리 고도화  \n• ingest_config.yml:  \n  └─default: chunk_size, overlap, profile  \n  └─file_types: pdf→pdfminer, csv→pandas, md→markdown-it …  \n  └─rules: include_glob, exclude_regex, pre_processors[]  \n• ConfigLoader 가 환경·문서 태그를 기준으로 최적 profile(quick/balanced/deep) 선택.  \n• RuleEngine.apply() 단계에서 사용자 정의 Python 플러그인(importlib) 호출 가능.  \n\n5. API 개선 사항  \n• GET /api/documents/sync?ids=&force=&profile= : 선택적 파일·프로파일 동기화 지원.  \n• GET /api/documents/sync/status/{task_id} : 200 OK {state, progress%, current_doc}.  \n• GET /api/documents/sync/history?limit=50 : 최근 작업 로그·결과 반환.  \n• /sync 엔드포인트 내부에서 RawDataSyncManager → DocumentLifecycleService 로 완전 이관, 의존성 주입(Repository 패턴)으로 테스트 용이성 확보.  \n\n기존 RawDataSyncManager·sync_documents 분석 결과  \n• 파일 시스템 순회 로직이 I/O-bound 임에도 동기 실행 → _discover_documents() 를 async-fs(read_dir) + semaphore 로 교체.  \n• 중복 upsert 방어 로직 미흡 → DuplicateDetector 추가.  \n• 단일 try/except 블록으로 오류가 섞여 로그 추적이 어려움 → 단계별 에러 격리 구조로 재설계.  \n\n이 계획을 기준으로 모듈별 PR 분할(ingestion_core, background_tasks, api_routes) 및 단계별 마이그레이션 일정을 수립한다.\n</info added on 2025-07-20T22:13:37.072Z>\n<info added on 2025-07-21T06:17:13.447Z>\n• Sync API 개선: 기존 벡터 DB를 DocumentService.delete_database()로 완전 삭제 후 재생성(DELETE + RECREATE)하는 로직 추가, 충돌 문제 해결  \n• /api/documents/add POST 엔드포인트 신규 구현: doc_id · chunk_size · chunk_overlap 쿼리 파라미터 지원, 기존 DB에 신규 문서만 추가  \n• ConfigurableIngestionService 리팩토링: _perform_ingestion 최적화, PyPDFLoader→RecursiveCharacterTextSplitter→ChromaDBManager 직접 연동, 문서별 메타데이터(doc_id · source_file) 저장, add_documents()/create_new_db 분기 처리  \n• API 테스트 완료: Add API 56개 청크 생성, Sync API 정상 작동 확인  \n• 버그 수정: Unicode(이모지) 제거, ChunkConfig import 경로 재정비, 쿼리 파라미터 형식 통일  \n→ 동기화·추가 기능 완전 분리 및 정상 동작 확인\n</info added on 2025-07-21T06:17:13.447Z>",
            "testStrategy": "단일/전체 sync, force=true, BackgroundTasks 동작을 모킹하여 검증"
          },
          {
            "id": 5,
            "title": "마이그레이션 및 테스트 스크립트 작성",
            "description": "scripts/backfill_default_config.py를 작성해 legacy 문서에 config.json·metadata.json을 생성하고, 전체 API에 대한 pytest 기반 단위·통합 테스트를 작성한다.",
            "status": "done",
            "dependencies": [],
            "details": "DocumentMigrationService.migrate_legacy_documents() 사용, DEFAULT 값은 settings.py에서 읽어옴\n<info added on 2025-07-20T22:07:29.358Z>\n세부 구현 계획\n\n1. 마이그레이션 스크립트 아키텍처\n• scripts/migrate_v2.py: click CLI + rich.Progress 적용\n• Alembic revision → ① documents_v2 테이블, ② foreign key/인덱스 추가, downgrade 단계 포함\n• DataMigrationRunner:\n    ‑ pre_check(): 레거시 ChromaDBManager로 doc 수, 상태 스냅샷\n    ‑ migrate_data(): 각 doc_id별 벡터 → JSONB 필드, 신규 파일 경로(server/raw_data/{doc_id}/)로 이동\n    ‑ migrate_config(): 기존 settings.yaml → DocumentConfig 모델 직렬화\n    ‑ migrate_file_path(): legacy/{doc_id}.pdf → raw_data/{doc_id}/original_file.pdf\n• checkpoints.json 저장(마이그레이션 단계별 완료 플래그) → 실패 시 rollback_handler()로 체크포인트 이전 단계로 자동 복귀\n\n2. 테스트 프레임워크\n• pytest-asyncio + FastAPI TestClient(fixture: app_override)로 전 API 경로 테스트\n• tests/integration/test_document_flow.py: 업로드→동기화→삭제 전체 사이클 검증\n• tests/security/test_path_traversal.py: “../../etc/passwd” 업로드 시 400 반환 확인\n• locustfile.py: 1~10MB PDF 1,000건 처리 TPS 측정, p95 < 500ms 목표\n• WebSocket Test: websockets.connect(“ws://test/documents/ws”) → 실시간 진행률 이벤트 수신 여부 검증\n\n3. 구현 세부 항목\n• MigrationValidator: pre_migration_state.json/ post_migration_state.json diff → 무결성 체크\n• AtomicTransactionManager(SQLAlchemy session.begin_nested) + file_system_tx(ctx.rm_on_error)로 원자성 보장\n• 실패 시 rollback.sh 자동 실행(Alembic downgrade + 파일 이동 복구)\n• tests/_data_factory.py: Faker+pdfkit로 50개 샘플 PDF/metadata 생성\n• benchmark/perf_runner.py: asyncio.gather + time.perf_counter() 로 함수별 latency 기록\n• bandit ‑r server/ & safety check requirements.txt → CI 파이프라인에 편입\n\n4. 코드 예시(발췌)\n```python\n# tests/conftest.py\n@pytest.fixture\ndef migrated_app(tmp_path):\n    os.environ[\"RAW_DATA_ROOT\"] = tmp_path.as_posix()\n    run_cli([\"python\", \"scripts/migrate_v2.py\", \"--dry-run\"])\n    yield TestClient(app)\n\n# scripts/migrate_v2.py (발췌)\nwith engine.begin() as conn:\n    context.configure(connection=conn, target_metadata=Base.metadata)\n    context.run_migrations()\n\nfor doc in legacy_docs:\n    progress.update(task, advance=1, description=f\"doc:{doc.id}\")\n    try:\n        new_id = migrate_single_document(doc)\n        checkpoints.store(new_id)\n    except Exception as e:\n        logger.exception(e)\n        rollback_handler()\n        sys.exit(1)\n```\n위 계획에 따라 코드/테스트를 병행 개발하고, GH Actions 워크플로우(migration-tests.yml)에서 `pytest -m \"not e2e\" && alembic upgrade head` 성공 시에만 배포 단계로 진행한다.\n</info added on 2025-07-20T22:07:29.358Z>",
            "testStrategy": "마이그레이션 실행 후 모든 문서에 두 JSON 파일 생성 확인, 주요 엔드포인트 회귀 테스트"
          }
        ]
      },
      {
        "id": 14,
        "title": "문서 관리 API 리팩토링 및 엔드포인트 구조 개선",
        "description": "api/documents 라우트의 엔드포인트를 RESTful 원칙에 맞게 리팩토링하고, config POST 추가, 업로드/삭제/동기화 기능 개선, 불필요한 엔드포인트 제거를 수행한다.",
        "details": "1. 엔드포인트 설계 및 리팩토링: RESTful 원칙에 따라 HTTP 메서드와 리소스 명명 규칙을 일관성 있게 적용한다. 예를 들어, /api/documents/{doc_id}/config는 POST로 설정 저장, /api/documents/upload-file은 파일 업로드, /api/documents/{doc_id}/delete는 삭제 등으로 명확히 구분한다. 불필요한 엔드포인트(/api/rag/chat, generate-questions, evaluate)는 완전히 제거한다.\n\n2. config POST 엔드포인트 추가: /api/documents/{doc_id}/config에 POST 요청 시, body로 chunk_size와 chunk_overlap을 받아 해당 문서별 config.json에 저장한다. 유효성 검사를 강화하여 잘못된 값(예: overlap > size 등)에 대해 422 에러를 반환한다.\n\n3. upload-file 엔드포인트 개선: chunk 파라미터를 제거하고, 업로드 시 server/raw_data/{doc_id} 디렉터리를 자동 생성한다. PDF와 TXT 파일만 허용하며, 파일 확장자 및 MIME 타입 검사를 추가한다. 업로드 성공 시 201 Created와 Location 헤더에 doc_id를 반환한다.\n\n4. delete 엔드포인트 개선: 삭제는 raw_data 폴더 내에서만 동작하도록 제한하고, 존재하지 않는 파일/폴더 삭제 시 404, 권한 문제 등 예외 상황에 대해 명확한 에러 메시지와 HTTP 상태 코드를 반환한다.\n\n5. sync 엔드포인트 GET 방식으로 변경: 동기화 작업은 GET /api/documents/{doc_id}/sync?force=true 등 파라미터 기반으로 동작하도록 변경한다. 파라미터 유효성 검사 및 동기화 결과를 JSON으로 반환한다.\n\n6. 코드 구조: server/api/documents.py와 server/modules/document_service.py로 라우트와 서비스 로직을 분리한다. 모든 예외는 FastAPI의 HTTPException을 활용해 일관된 에러 응답 포맷을 유지한다.\n\n7. 문서화 및 버전 관리: 엔드포인트 변경 및 제거 내역을 changelog에 기록하고, OpenAPI 문서에 반영한다. 기존 클라이언트 호환성에 유의하며, 변경된 엔드포인트에 대한 명확한 안내를 제공한다.\n\n8. 테스트: 단위 테스트와 통합 테스트를 강화하여 모든 주요 시나리오(정상/에러/경계값)를 커버한다. pytest 및 FastAPI TestClient를 활용한다.\n\n참고: 엔드포인트 설계와 리팩토링 시 일관성, 명확한 네이밍, HTTP 상태 코드 및 에러 메시지 표준화, 버전 관리, 문서화 등 최신 REST API 베스트 프랙티스를 준수한다[1][3][4].",
        "testStrategy": "1. 단위 테스트: pytest로 각 엔드포인트별 정상/에러 케이스(유효성 검사, 파일 업로드/삭제, config 저장, sync 동작 등)를 테스트한다. 2. 통합 테스트: FastAPI TestClient로 실제 파일 업로드/삭제/설정/동기화 플로우를 검증한다. 3. 에러 처리 테스트: 잘못된 파라미터, 미지원 파일, 없는 문서/폴더 등 예외 상황에서 올바른 HTTP 상태 코드와 메시지가 반환되는지 확인한다. 4. OpenAPI 문서 검증: 변경된 엔드포인트가 문서화되어 있고, 예제 및 설명이 최신 상태인지 확인한다. 5. 엔드포인트 제거 검증: 삭제된 엔드포인트 호출 시 404 또는 적절한 에러가 반환되는지 테스트한다.",
        "status": "done",
        "dependencies": [],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "RESTful 엔드포인트 구조 설계 및 불필요한 엔드포인트 제거",
            "description": "api/documents 라우트의 모든 엔드포인트를 RESTful 원칙에 따라 명확하게 재설계하고, 불필요한 엔드포인트(/api/rag/chat, generate-questions, evaluate 등)를 완전히 제거한다.",
            "dependencies": [],
            "details": "HTTP 메서드와 리소스 명명 규칙을 일관성 있게 적용하며, 엔드포인트는 명확한 명사 기반 경로로 구성한다. 엔드포인트 변경 및 제거 내역을 changelog에 기록한다.\n<info added on 2025-07-19T13:06:07.458Z>\nPOST /api/documents/{doc_id}/config 엔드포인트 상세 설계\n\n• Request\n  - Content-Type: application/json\n  - Body 스키마\n    {\n      \"chunk_size\": int,        // 100-2000 범위\n      \"chunk_overlap\": int      // 0 ≤ overlap < chunk_size\n    }\n  - 필드 누락, 타입 불일치, 범위 초과 시 422 ValidationError 반환\n  - 오타 호환성: “chunk_overlab” 키가 들어오면 chunk_overlap 에 매핑하여 처리\n\n• Service 로직\n  1. RAW_DATA_DIR / {doc_id} 경로가 없으면 404, 존재하지 않으면 201 시 자동 생성\n  2. save_config(doc_id, chunk_size, chunk_overlap, *, overwrite: bool = False)\n     - 이미 config.json 존재 시 overwrite 파라미터가 false 이면 409, true 이면 덮어씀\n     - json.dump({\"chunk_size\":…, \"chunk_overlap\":…}, fp, ensure_ascii=False, indent=2)\n  3. 성공 시 201 Created + {\"doc_id\": ..., \"chunk_size\": ..., \"chunk_overlap\": ...}\n\n• 테스트 케이스\n  a. 정상 입력(800/200) → 201\n  b. chunk_overlap ≥ chunk_size → 422\n  c. 음수 또는 0 chunk_size → 422\n  d. 존재하지 않는 doc_id → 404\n  e. 중복 저장 overwrite=false → 409, overwrite=true → 201\n\n• 추가 작업\n  - OpenAPI 예제 및 설명 업데이트\n  - 변경 내역을 changelog.md 에 “ADD /api/documents/{doc_id}/config” 항목으로 기록\n  - upload-file, sync 엔드포인트와 연동되는 chunk 파라미터 제거 사항을 문서화하여 호환성 이슈 방지\n</info added on 2025-07-19T13:06:07.458Z>",
            "status": "done",
            "testStrategy": "엔드포인트 목록을 점검하여 RESTful 원칙(명사 기반, HTTP 메서드 일치, 불필요한 엔드포인트 미존재 등) 준수 여부를 검증한다."
          },
          {
            "id": 2,
            "title": "Config POST 엔드포인트 구현 및 유효성 검사 강화",
            "description": "/api/documents/{doc_id}/config에 POST 요청 시 chunk_size, chunk_overlap 값을 받아 config.json에 저장하고, 유효성 검사(예: overlap > size 등)를 강화한다.",
            "dependencies": [
              1
            ],
            "details": "body로 전달된 파라미터를 검증하여 잘못된 값에 대해 422 에러를 반환하고, 정상 입력 시 해당 문서별 config.json 파일에 저장한다.",
            "status": "done",
            "testStrategy": "정상/비정상 파라미터로 POST 요청 시 각각 200 OK, 422 반환 여부 및 파일 저장 결과를 단위 테스트로 검증한다."
          },
          {
            "id": 3,
            "title": "파일 업로드 엔드포인트 개선 및 파일 검증 로직 추가",
            "description": "파일 업로드 시 chunk 파라미터를 제거하고, server/raw_data/{doc_id} 디렉터리 자동 생성, PDF/TXT 파일만 허용, 확장자 및 MIME 타입 검증을 추가한다.",
            "dependencies": [
              1
            ],
            "details": "업로드 성공 시 201 Created와 Location 헤더에 doc_id를 반환하며, 미지원 파일 업로드 시 적절한 에러 메시지와 상태 코드를 반환한다.\n<info added on 2025-07-19T13:06:28.475Z>\n• /api/documents/upload-file 엔드포인트는 multipart/form-data의 file 필드만 수신하도록 수정한다. 추가 파라미터(chunk_size, chunk_overlap)는 허용하지 않으며, 전달될 경우 422 Unprocessable Entity로 응답한다.  \n• 업로드 처리 로직  \n  1) server/raw_data 디렉터리가 존재하지 않으면 우선 생성한다.  \n  2) 업로드 요청이 들어오면 UUID4로 doc_id를 생성하고 server/raw_data/{doc_id} 하위에 디렉터리를 만든다.  \n  3) 파일 확장자(.pdf, .txt)와 MIME 타입(application/pdf, text/plain)을 모두 검사해 일치할 때만 저장한다.  \n  4) 저장 경로: server/raw_data/{doc_id}/{original_filename}  \n• 성공 시 응답  \n  – HTTP 201 Created  \n  – Location: /api/documents/{doc_id}  \n  – Body: {\"doc_id\": \"<생성된 id>\", \"file_name\": \"<업로드된 파일명>\"}  \n• 실패 시 응답  \n  – 파일 미첨부: 400 Bad Request {\"detail\": \"file field is required\"}  \n  – 지원하지 않는 형식: 415 Unsupported Media Type {\"detail\": \"Only PDF and TXT files are allowed\"}  \n  – 기타 서버 오류: 500 Internal Server Error  \n• 테스트 추가  \n  – pdf, txt 정상 업로드 → 201 & Location 헤더, raw_data/{doc_id} 디렉터리와 파일 존재 확인  \n  – 다른 확장자(jpg 등) 업로드 → 415  \n  – chunk_size 파라미터 포함 요청 → 422\n</info added on 2025-07-19T13:06:28.475Z>",
            "status": "done",
            "testStrategy": "PDF/TXT 파일 정상 업로드, 미지원 파일 업로드, Location 헤더 반환 등 다양한 케이스를 FastAPI TestClient로 통합 테스트한다."
          },
          {
            "id": 4,
            "title": "삭제 및 동기화 엔드포인트 개선",
            "description": "삭제 엔드포인트는 raw_data 폴더 내에서만 동작하도록 제한하고, sync 엔드포인트는 GET 방식으로 변경하여 파라미터 기반 동작 및 결과 JSON 반환을 구현한다.",
            "dependencies": [
              1
            ],
            "details": "존재하지 않는 파일/폴더 삭제 시 404, 권한 문제 등 예외 상황에 대해 명확한 에러 메시지와 HTTP 상태 코드를 반환한다. sync는 force 등 파라미터 유효성 검사를 포함한다.\n<info added on 2025-07-19T13:06:55.037Z>\n• DELETE /api/documents/delete  \n  – raw_data 디렉터리 내부 경로만 허용하도록 Path.resolve()로 절대경로 검사 후, 벗어나는 경우 403 Forbidden 반환  \n  – 요청한 파일명이 존재하지 않을 때 404 Not Found 대신  \n    { \"detail\": \"file_not_found\", \"deletable_files\": [\"a.pdf\", \"b.docx\", …] } 형태로 현재 삭제 가능한 파일 리스트를 함께 반환  \n  – 단일 파일뿐 아니라 files[]=a.pdf&files[]=b.pdf 형식의 다중 삭제 지원, 일부만 실패 시 207 Multi-Status로 개별 결과 제공  \n  – OS/권한 오류, 디렉터리 삭제 시도 등은 409 Conflict + 원인 메시지\n\n• GET /api/documents/sync  \n  – query string: chunk_size(int>0), chunk_overlap(int≥0), force(bool, default=false)  \n  – 미지정 시 doc별 config.json → 전역 DEFAULT_CHUNK_SIZE/OVERLAP 순으로 fallback  \n  – chunk_overlap ≥ chunk_size 일 경우 422 Unprocessable Entity  \n  – raw_data 하위 모든 문서를 지정된 파라미터로 split 후 embedding 수행  \n  – 응답 예시  \n    {  \n      \"processed_docs\": 12,  \n      \"total_chunks\": 487,  \n      \"used_chunk_size\": 800,  \n      \"used_chunk_overlap\": 200  \n    }\n\n• 테스트 시나리오 추가  \n  1) 삭제 엔드포인트: 존재하지 않는 파일 요청 → 404 & deletable_files 포함  \n  2) sync 엔드포인트:  \n     a. GET /sync?chunk_size=600&chunk_overlap=100 → 200 & used_* 필드 검증  \n     b. overlap≥size → 422  \n     c. 파라미터 미지정 → config.json 값 사용 여부 확인\n</info added on 2025-07-19T13:06:55.037Z>",
            "status": "done",
            "testStrategy": "존재/미존재 파일 삭제, 권한 오류, sync 파라미터 유효성 등 정상/에러 케이스를 단위 및 통합 테스트로 검증한다."
          },
          {
            "id": 5,
            "title": "코드 구조 분리, 문서화 및 테스트 강화",
            "description": "server/api/documents.py와 server/modules/document_service.py로 라우트와 서비스 로직을 분리하고, 모든 예외는 FastAPI HTTPException으로 처리하며, OpenAPI 문서 및 changelog를 최신화한다.",
            "dependencies": [
              2,
              3,
              4
            ],
            "details": "엔드포인트 변경사항을 OpenAPI 문서에 반영하고, 단위/통합 테스트(pytest, TestClient)로 모든 주요 시나리오(정상/에러/경계값)를 커버한다.",
            "status": "done",
            "testStrategy": "OpenAPI 문서 자동화, changelog 기록, 테스트 커버리지 90% 이상 달성 여부를 검증한다."
          }
        ]
      },
      {
        "id": 15,
        "title": "통합 실행 시스템 개발",
        "description": "루트 디렉토리에 main.py 실행 파일을 생성하여 FastAPI(uvicorn) 서버를 실행하고, 서버 상태를 모니터링하며 안전한 종료 및 장애 복구를 보장하는 실행 시스템을 개발한다.",
        "status": "deferred",
        "dependencies": [],
        "priority": "medium",
        "details": "## 구현 세부사항\n\n1. **실행 파일(main.py) 구조**\n   - 루트 디렉토리에 `main.py` 생성. 서버 프로세스만을 관리하며 웹(Next.js) 관련 코드는 포함하지 않는다.\n   - 핵심 함수\n     - `start_server(port: int, debug: bool=False)` : FastAPI 서버를 `subprocess.Popen` 으로 기동하고 `/health` 가 200 을 반환할 때까지 폴링(최대 30초).\n     - `stop_service()` : 서버 프로세스 정상 종료·강제 종료 로직.\n     - `check_service_health()` : 프로세스 종료 여부 및 `/health` 응답 코드로 서버 상태를 판단.\n     - `restart_service()` : 장애 감지 시 자동 재기동.\n     - `signal_handler()` : SIGINT / SIGTERM 수신 시 안전 종료.\n   - CLI 인자\n     - `--server-port`(기본 8000), `--debug`, `--monitor-interval` 만 지원. `--mode`, `--web-port` 등 웹 관련 옵션 제거.\n   - 예시 명령: `python main.py --server-port 9000 --debug`.\n\n2. **환경 변수 설정 파일(.env.example)**\n   ```ini\n   # 서버 설정\n   SERVER_PORT=8000\n   LOG_LEVEL=info\n   \n   # 데이터베이스 설정\n   DB_HOST=localhost\n   DB_PORT=5432\n   DB_USER=postgres\n   DB_PASSWORD=postgres\n   DB_NAME=rag_lab\n   \n   # Redis 설정\n   REDIS_HOST=localhost\n   REDIS_PORT=6379\n   \n   # Chroma 설정\n   CHROMA_HOST=localhost\n   CHROMA_PORT=8001\n   ```\n   - WEB_PORT, NEXT_PUBLIC_API_URL 등 프론트엔드 변수 제거.\n\n3. **실행 스크립트**\n   - `run.sh` / `run.bat` 는 `python main.py \"$@\"` 만 호출한다. 추가 변경 없음.\n\n4. **서버 상태 확인 엔드포인트 보강**\n   - `server/main.py` 에 `/health`, `/health/detailed` 구현(프론트엔드 제거와 무관).\n\n5. **에러 처리 및 복구 메커니즘**\n   - `restart_service()` 를 통해 서버 장애(프로세스 종료, 헬스체크 실패) 발생 시 자동 재시작.\n\n6. **로깅 시스템 강화**\n   - `setup_logging()` : 콘솔, `rag_lab.log`, `rag_lab_structured.log`(JSON) 순환 로그 설정. 웹 태그 제거.\n\n7. **의존성 관리**\n   ```toml\n   [tool.poetry.dependencies]\n   python = \"^3.9\"\n   requests = \"^2.31.0\"\n   psutil = \"^5.9.5\"\n   ```",
        "testStrategy": "## 테스트 전략\n\n1. **단위 테스트**\n   - `tests/test_main.py` 에서 다음 함수들을 모킹하여 검증:\n     - `start_server`, `stop_service`, `check_service_health`, `restart_service`\n   - 웹 관련 테스트 항목(`start_web`, `WEB_PORT` 등) 제거.\n\n2. **통합 테스트**\n   - 실제 서버만 기동하여 `/health` 상태를 확인 후 SIGINT 로 종료.\n   ```python\n   @pytest.mark.integration\n   def test_server_start_stop():\n       proc = subprocess.Popen([\n           \"python\", \"main.py\", \"--server-port\", \"8001\"\n       ], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n       try:\n           time.sleep(5)\n           res = requests.get(\"http://localhost:8001/health\")\n           assert res.status_code == 200 and res.json()[\"status\"] == \"ok\"\n       finally:\n           proc.send_signal(signal.SIGINT)\n           proc.wait(timeout=10)\n   ```\n\n3. **시스템 테스트**\n   - 기본 실행: `python main.py`\n   - 디버그 모드: `python main.py --debug`\n   - 포트 변경: `python main.py --server-port 9000`\n   - 각 실행 시 로그, 종료 신호 처리, 장애 재시작 로직 확인.\n\n4. **에러 처리 테스트**\n   - 이미 사용 중인 포트로 실행, 프로세스 강제 종료 등 시나리오에서 자동 복구 동작 검증.\n\n5. **로그 검증 & 성능 테스트**\n   - 로그 파일 생성·순환 및 24시간 이상 장기 실행 중 메모리 누수 여부 확인.",
        "subtasks": [
          {
            "id": 1,
            "title": "main.py 통합 실행 파일 설계 및 구현",
            "description": "루트 디렉토리에 main.py 파일을 생성하여 FastAPI(uvicorn) 서버를 실행하고, 프로세스 관리·신호 처리·상태 모니터링·안전한 종료·자동 복구 로직을 포함한다.",
            "status": "pending",
            "dependencies": [],
            "details": "subprocess, signal, threading, requests 등을 이용해 서버 프로세스를 관리하고, /health 엔드포인트 폴링(최대 30초)으로 준비 여부를 확인한다. 종료 신호(SIGINT, SIGTERM) 수신 시 child.terminate() 후 5초 대기, 미종료 시 kill()로 강제 종료한다.\n<info added on 2025-07-19T13:07:22.158Z>\n• 실행 진입점(run.py)이 아닌 main.py 로 통일한다.\n• 서버 실행 명령은 .env 또는 CLI 인자로 주입 가능하도록 한다 (예: SERVER_CMD=\"uvicorn server.api.main:app --host 0.0.0.0 --port 8000\").\n• tests/run_test.py: pytest 에서 main.py 를 subprocess 로 띄운 뒤 /health, /docs 응답 확인 후 SIGINT 전송 → 하위 PID 소멸 검증.\n</info added on 2025-07-19T13:07:22.158Z>",
            "testStrategy": "pytest 및 unittest.mock을 활용해 start_server, stop_service, check_service_health, restart_service 함수의 단위 테스트를 작성한다."
          },
          {
            "id": 2,
            "title": "환경 변수 및 실행 스크립트 구성",
            "description": ".env.example 파일을 루트에 생성하여 서버, 데이터베이스, Redis, Chroma 등 주요 환경 변수를 정의하고, run.sh 및 run.bat 실행 스크립트를 추가한다.",
            "status": "pending",
            "dependencies": [
              1
            ],
            "details": ".env.example 에 SERVER_PORT, DB_HOST 등의 필수 환경 변수와 예시 값을 명시한다. run.sh(run.bat)는 main.py 를 실행하도록 작성하며 Linux/macOS 에서는 실행 권한을 부여한다.",
            "testStrategy": "환경 변수 로딩 및 스크립트 실행 시 main.py 가 정상적으로 기동되는지 자동화 테스트를 수행한다."
          },
          {
            "id": 3,
            "title": "서버 헬스체크 및 상세 상태 엔드포인트 보강",
            "description": "FastAPI 서버에 /health 및 /health/detailed 엔드포인트를 구현하여 API, 데이터베이스, Redis, Chroma 등 주요 컴포넌트의 상태를 반환한다.",
            "status": "pending",
            "dependencies": [
              1
            ],
            "details": "server/main.py 에 각 컴포넌트의 연결 상태를 점검하는 로직을 추가하고, 정상/오류/미확인 상태를 구분하여 JSON 형태로 응답한다.",
            "testStrategy": "pytest 및 FastAPI TestClient 로 /health, /health/detailed 엔드포인트의 정상 응답 및 장애 상황을 모킹하여 테스트한다."
          },
          {
            "id": 4,
            "title": "에러 감지 및 자동 복구 메커니즘 구현",
            "description": "서버 장애(프로세스 종료, 헬스체크 실패) 감지 시 자동으로 서버를 재시작하는 로직을 main.py 에 추가한다.",
            "status": "pending",
            "dependencies": [
              1,
              3
            ],
            "details": "check_service_health 함수에서 비정상 상태 감지 시 stop_service 및 restart_service 를 호출하여 자동 복구를 시도한다.",
            "testStrategy": "프로세스 강제 종료 및 헬스체크 실패 상황을 시뮬레이션하여 자동 재시작 동작을 검증한다."
          },
          {
            "id": 5,
            "title": "구조화된 로깅 및 로그 파일 순환 시스템 구축",
            "description": "RotatingFileHandler와 JSON 포맷터를 활용하여 일반 로그와 구조화된 로그를 rag_lab.log, rag_lab_structured.log 파일에 기록하고, 로그 파일 용량 초과 시 자동 순환되도록 한다.",
            "status": "pending",
            "dependencies": [
              1
            ],
            "details": "setup_logging 함수를 구현하여 콘솔, 일반 파일, JSON 파일 핸들러를 등록하고, 로그 레벨 및 포맷을 일관되게 관리한다.",
            "testStrategy": "로그 파일 생성, 순환, JSON 구조 검증 및 로그 레벨별 출력 테스트를 수행한다."
          }
        ]
      },
      {
        "id": 16,
        "title": "프론트엔드 설정 및 테스트 통합 페이지 개발",
        "description": "분리된 Next.js 프론트엔드 애플리케이션에 RAG 시스템의 설정·테스트·대시보드 화면을 구현한다. 백엔드 서버는 별도 저장소에서 독립적으로 구동되며, 프론트엔드는 REST API 및 WebSocket으로만 서버와 통신한다. 서버 실행 스크립트나 통합 dev-server 기동 로직은 프론트엔드 저장소에 포함하지 않는다.",
        "status": "deferred",
        "dependencies": [],
        "priority": "medium",
        "details": "## 구현 원칙\n\n* 본 작업은 **Next.js 전용 프론트엔드 저장소**에서 진행한다. FastAPI 백엔드(tax_rag_backend)와의 실행·배포 파이프라인은 분리하며, 프론트엔드는 API 호출 및 WebSocket 통신만 담당한다.\n* `npm run dev`(Next.js) 실행 시 프론트엔드만 기동되고, 서버 주소는 환경 변수(`NEXT_PUBLIC_API_URL`, `NEXT_PUBLIC_WS_URL`)로 주입한다.\n* README 및 코드 주석에서 백엔드 기동 명령이나 통합 start 스크립트를 명시하지 않는다.\n\n## 핵심 구현 항목(변경 없음)\n1. **서버 연결 모듈 (web/util/api.ts)**\n   * axios 인스턴스(`api`) 생성, 문서/설정/RAG 쿼리 관련 함수 제공\n2. **WebSocket 훅 (web/util/websocket.ts)**\n   * 연결/해제, 메시지 송수신, 재연결 로직\n3. **Settings 페이지 (web/pages/settings.tsx)**\n   * 문서 청킹 파라미터 관리, WebSocket 상태 뱃지\n4. **Test 페이지 (web/pages/test.tsx)**\n   * 문서 선택 후 RAG 쿼리 실행, 결과·실시간 로그 표시\n5. **Dashboard, Layout, Navigation**\n   * 문서 업로드/삭제, 서버 상태 카드, 전역 레이아웃\n6. **_app.tsx**\n   * 전역 레이아웃 적용\n7. **.env.local 예시**\n   * 외부 서버 주소만 포함(서버 기동 명령 삭제)\n\n기존 코드 조각은 변경 없이 유지하되, 주석/README 및 향후 PR 설명에서 \"서버와 프론트엔드를 동시에 실행\" 같은 표현을 제거하고 \"백엔드 별도 실행\"을 명확히 한다.",
        "testStrategy": "## 테스트 전략 (서버 별도 구동 전제)\n\n1. **단위 테스트 (Jest/React Testing Library)**\n   - API 모듈: axios mock 으로 각 함수의 URL·메서드·페이로드 검증\n   - WebSocket 훅: mock-socket 으로 연결/재연결/메시지 처리 검증\n   - 각 페이지 컴포넌트: UI 상호작용, 상태 변화 테스트\n\n2. **통합 테스트 (프론트엔드 ↔ 실제 서버)**\n   - 백엔드가 별도 포트에서 기동된 상태에서 `NEXT_PUBLIC_API_URL` 을 해당 주소로 설정 후 테스트\n   - 문서 CRUD, 설정 저장, RAG 쿼리 end-to-end 시나리오 검증\n\n3. **E2E 테스트 (Cypress)**\n   - 사용자가 브라우저에서 수행할 전체 플로우(문서 업로드→설정→테스트) 자동화\n   - cypress 실행 전 백엔드가 기동되어 있어야 하며, start 명령은 프론트엔드 repo 에 포함하지 않음\n\n4. **브라우저·반응형·접근성·성능 테스트**\n   - 기존 계획과 동일\n\n5. **수동 체크리스트**\n   - [ ] 프론트엔드 단독 `npm run dev` 로 정상 기동되는지 확인\n   - [ ] 환경 변수만 변경하여 서로 다른 서버(로컬/스테이징/프로덕션)와 문제없이 통신하는지 확인",
        "subtasks": [
          {
            "id": 1,
            "title": "서버 API 연결 모듈 구현",
            "description": "Next.js 환경에서 백엔드 API와 통신하는 axios 기반의 중앙화된 API 모듈(api.ts)을 개발한다.",
            "status": "pending",
            "dependencies": [],
            "details": "문서 목록 조회, 문서 설정 조회/저장, 문서 업로드/삭제, RAG 쿼리 테스트 등 모든 API 호출을 담당하는 함수들을 구현한다. 환경 변수 기반으로 API 엔드포인트를 설정하고, 예외 처리 및 응답 구조를 표준화한다.\n<info added on 2025-07-19T13:07:42.826Z>\n• RAG 시스템 파라미터(temperature, top_k, 모델명 등)를 GET/PUT 할 수 있는 api.ragSettings(), 이를 사용하는 useRagSettings 훅과 /settings 페이지(가벼운 폼 UI) 추가  \n• RAG 쿼리 결과를 실시간 확인할 /playground 페이지 구현: 질문 입력 → api.ragQuery() 호출 → 응답·citations 출력  \n• WebSocket 연결 상태를 주기적 ping(5s 간격)으로 점검하는 useWsStatus 훅 작성, 실패 시 reconnect() 및 화면 배지(red/green) 표시  \n• AppRouter에 /settings, /playground 경로 배치, Chakra UI 기본 컴포넌트로 최소 스타일링 적용\n</info added on 2025-07-19T13:07:42.826Z>",
            "testStrategy": "Jest를 사용해 각 API 함수의 정상/에러 응답을 axios mock으로 검증한다. 요청 URL, 메서드, 헤더, 데이터 전달을 단위 테스트한다."
          },
          {
            "id": 2,
            "title": "WebSocket 연결 모듈 및 상태 훅 개발",
            "description": "WebSocket 연결을 관리하는 커스텀 훅(websocket.ts)을 구현하여 실시간 서버 상태 및 메시지 송수신 기능을 제공한다.",
            "status": "pending",
            "dependencies": [
              1
            ],
            "details": "WebSocket 연결/해제, 메시지 수신/전송, 연결 상태 및 에러 관리, 메시지 배열 관리 등 실시간 통신을 위한 공통 로직을 커스텀 훅으로 구현한다.",
            "testStrategy": "Jest 및 React Testing Library로 WebSocket 연결/해제, 메시지 송수신, 에러 처리 등 각 기능의 동작을 mock 서버로 단위 테스트한다."
          },
          {
            "id": 3,
            "title": "RAG 시스템 설정 페이지 개발",
            "description": "문서 청킹 설정, 서버 연결 상태 점검 등 RAG 시스템의 주요 설정을 관리하는 설정 페이지(settings.tsx)를 개발한다.",
            "status": "pending",
            "dependencies": [
              1,
              2
            ],
            "details": "문서 목록 및 설정 조회, 설정 변경/저장, 서버 WebSocket 연결 상태 표시 및 제어, 입력값 검증, 사용자 피드백 메시지 표시 등 UX를 고려한 UI/로직을 구현한다.",
            "testStrategy": "React Testing Library로 문서 선택, 설정 변경/저장, 서버 연결 상태 표시 등 주요 UI/로직의 동작을 단위 및 통합 테스트한다."
          },
          {
            "id": 4,
            "title": "RAG 테스트 페이지 개발",
            "description": "문서 선택 및 쿼리 입력을 통한 RAG 테스트, WebSocket 실시간 메시지 확인 등 테스트 기능을 제공하는 페이지(test.tsx)를 개발한다.",
            "status": "pending",
            "dependencies": [
              1,
              2
            ],
            "details": "문서 선택, 쿼리 입력 및 실행, REST 및 WebSocket 기반 RAG 쿼리 결과 표시, 에러 및 로딩 상태 관리, 실시간 메시지 로그 표시 등 테스트 워크플로우를 구현한다.",
            "testStrategy": "React Testing Library로 쿼리 실행, 결과 표시, WebSocket 메시지 수신 등 주요 기능의 정상/에러 시나리오를 테스트한다."
          },
          {
            "id": 5,
            "title": "통합 대시보드 및 공통 레이아웃/네비게이션 구축",
            "description": "문서 업로드/삭제, 서버 상태, 빠른 링크 등 통합 관리 기능을 제공하는 대시보드(dashboard.tsx)와 공통 레이아웃(Layout.tsx), 네비게이션(Navigation.tsx) 컴포넌트를 개발한다.",
            "status": "pending",
            "dependencies": [
              1,
              2,
              3,
              4
            ],
            "details": "대시보드에서 문서 목록 관리, 서버 연결 상태 표시, 페이지 간 이동 링크 제공, 전체 앱에 일관된 레이아웃과 네비게이션 적용을 위한 컴포넌트 구조를 설계/구현한다.",
            "testStrategy": "React Testing Library로 대시보드의 문서 업로드/삭제, 서버 상태 표시, 네비게이션 동작 등 주요 UI/로직을 통합 테스트한다."
          }
        ]
      },
      {
        "id": 17,
        "title": "동적 프로그래밍 기반 세금 계산 최적화 기능 추가",
        "description": "세법 RAG 검색 결과를 이용해 동적 프로그래밍(DP)으로 최적의 세금 계산 방안을 제시하는 LangChain Tool & Chain 을 구현한다.",
        "details": "1. 시나리오 파서 모듈(tax_dp/parser.py)\n   • 자연어·JSON 형태 입력을 Pydantic TaxScenario 모델로 정규화(소득, 공제, 사업 유형, 세율표 등 필드화)\n   • 불완전 입력 보정: 기본값/LLM 추론으로 누락 항목 채우기\n\n2. 세법 규정 RAG 검색\n   • 기존 StuffDocumentsChain(작업 #4) 을 래핑하여 `retrieve_tax_rules(scenario)` 함수 구현\n   • 검색 k 값은 시나리오 복잡도(항목 수)에 따라 동적 조정(k=4~10)\n   • 반환 값: [(rule_text, metadata{article,law_name}), …]\n\n3. DP 최적화 엔진(tax_dp/dp_engine.py)\n   • sympy 이용, 상태 = (과세표준, 공제 선택 여부, 과세 구간)\n   • 전이함수: f(state, action) → (next_state, cost)\n   • 메모이제이션으로 O(N·M) 복잡도 유지, numpy array cache 사용\n   • 다세목 지원: 시나리오.tax_type 이 list 인 경우 tax_type 별 부분 DP 후 결합\n   • 결과 객체 TaxOptimizationResult(optimized_tax:int, path:list[Step], complexity:int)\n\n4. LangChain Tool 통합(tax_dp/tool.py)\n   ```python\n   class TaxOptimizerTool(BaseTool):\n       name, description = \"tax_optimizer\", \"세법 규정을 인용하여 세금을 최소화하는 DP 계산기\"\n       def _run(self, scenario:str):\n           parsed = parse_scenario(scenario)\n           rules = retrieve_tax_rules(parsed)\n           result = dp_optimize(parsed, rules)\n           return serialize(result, rules)\n   ```\n   • 출력: {\"optimized_tax\":…, \"steps\":[…], \"citations\":[…]}\n\n5. RAG+DP 체인(tax_dp/chain.py)\n   • SimpleSequentialChain([TaxOptimizerTool, AnswerFormatterChain])\n   • Formatter 는 steps & citations 를 markdown 표 형태로 변환, 각 citation 에 rule.metadata.article 태그\n\n6. 벡터DB 규정 삽입 스크립트(scripts/index_tax_rules.py)\n   • raw 세법 PDF/HTML → langchain.text_splitter → vectordb.add_documents\n   • tax, law, article 메타데이터 필수\n\n7. 투명성 & 로깅\n   • langsmith_tracer tag “dp” 추가\n   • result.complexity, cache_hit_rate 로그 기록\n\n8. API 엔드포인트 추가(routes/tax_optimize.py)\n   POST /optimize-tax  {scenario:string}\n   → JSONResponse(result)\n\n9. 문서화(README.md)\n   사용 예제 cURL 및 응답 샘플 포함",
        "testStrategy": "1. 단위 테스트(PyTest)\n   a. test_parser_edge_cases: 불완전 입력 → TaxScenario 필드 자동 채움 확인\n   b. test_dp_engine_simple: 소득세 단일 구간 예시, 수동 계산 값과 동일한 optimized_tax 검증\n   c. test_dp_multi_tax: 소득세+부가가치세 복합 시나리오, 결과 구조·복수 세금 합계 검증\n\n2. 통합 테스트\n   • FastAPI TestClient 로 POST /optimize-tax\n   • 시나리오: \"연봉 95,000,000원, 개인사업자 경비율 40%\" →\n     - 응답 코드 200\n     - optimized_tax 키 존재 및 int 타입\n     - citations 리스트 길이 > 0, 각 원문에 law_name 존재\n     - steps 리스트가 상태·액션·비용 필드 포함\n\n3. 회귀 테스트\n   • 이미 존재하는 /chat SSE 경로에 동일 시나리오 입력 시, stream 최종 덩어리에서 \"optimized_tax\" 포함 확인\n\n4. 성능 테스트\n   • 100개 랜덤 시나리오 batch → 평균 응답 시간 < 3s, 메모리 ≤ 500 MB\n\n5. 문서 인덱싱 검증\n   • scripts/index_tax_rules.py 실행 후 vectordb.count() > 10,000, 메타데이터 필드 누락 없음",
        "status": "deferred",
        "dependencies": [],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 18,
        "title": "RAG 시스템 기반 인프라 아키텍처 설계 및 구축",
        "description": "RAG 시스템의 안정적 운영을 위한 클라우드 기반 인프라(컴퓨팅, 스토리지, 네트워크, 벡터DB, LLM 엔드포인트 등)를 설계하고 IaC(Infrastructure as Code)로 자동화 구축한다.",
        "details": "1. 요구사항 분석 및 인프라 준비도 평가: 현행 시스템의 하드웨어, 네트워크, 보안, 확장성 요구사항을 분석한다. AWS, Azure, GCP 등 주요 클라우드 서비스의 RAG 아키텍처 사례를 참고하여 최적의 플랫폼을 선정한다.\n\n2. 핵심 구성요소 설계:\n- 컴퓨팅: LLM 추론 및 임베딩 처리를 위한 GPU 인스턴스(AWS SageMaker, Bedrock, Azure ML 등)와 서버리스 컴퓨팅(AWS Lambda 등) 활용 방안 설계\n- 스토리지: 대용량 문서 저장용 오브젝트 스토리지(S3 등) 및 메타데이터 관리\n- 벡터 데이터베이스: Amazon OpenSearch, Pinecone, Qdrant 등 클라우드 벡터DB 서비스 도입 및 네트워크/보안 정책 설계\n- LLM/임베딩 엔드포인트: SageMaker Endpoint, Bedrock, Azure OpenAI 등 완전관리형 서비스 활용\n\n3. IaC(Infrastructure as Code) 자동화:\n- Terraform, AWS CDK, Azure Bicep 등 IaC 도구로 전체 인프라 리소스(네트워크, IAM, 컴퓨팅, 스토리지, DB, 엔드포인트 등) 정의 및 배포 자동화\n- 환경별(개발/운영) 분리, 재현성 확보, 코드 리뷰 및 GitOps 적용\n\n4. 모니터링 및 장애 대응:\n- CloudWatch, Azure Monitor 등으로 리소스 상태, 비용, 성능 모니터링 대시보드 구축\n- 장애 알림 및 자동 복구(오토스케일, 헬스체크, 롤백 등) 정책 수립\n\n5. 보안 및 컴플라이언스:\n- IAM 정책, 네트워크 ACL, 데이터 암호화, 접근제어 등 보안 설계\n- 로그 및 감사 추적, 개인정보 보호 등 컴플라이언스 준수 방안 포함\n\n6. 문서화:\n- 전체 인프라 아키텍처 다이어그램, IaC 코드 주석, 운영 가이드, 장애 대응 매뉴얼 작성\n\n최신 RAG 인프라 구축 사례(AWS SageMaker, Bedrock, OpenSearch, Lambda, 완전관리형 LLM/임베딩 엔드포인트 등)와 IaC 기반 자동화, 보안/모니터링/확장성 중심의 설계가 필수적임[1][2][3].",
        "testStrategy": "1. IaC 코드 리뷰 및 배포 테스트: 개발/운영 환경에 IaC로 인프라를 배포하고, 리소스 생성·구성·삭제가 정상 동작하는지 검증한다.\n2. 네트워크 및 보안 테스트: 각 서비스 간 통신, IAM 권한, 방화벽/네트워크 ACL, 데이터 암호화 설정을 점검한다.\n3. 성능 및 확장성 테스트: LLM/임베딩 엔드포인트, 벡터DB, 스토리지에 부하 테스트를 실시하고, 오토스케일 및 장애 복구 시나리오를 검증한다.\n4. 모니터링 및 알림 테스트: 리소스 상태 변화, 장애 발생 시 알림 및 자동 복구 동작을 확인한다.\n5. 문서화 검증: 아키텍처 다이어그램, IaC 코드, 운영 가이드, 장애 대응 매뉴얼이 최신 상태로 작성되어 있는지 리뷰한다.",
        "status": "deferred",
        "dependencies": [],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "요구사항 분석 및 클라우드 플랫폼 선정",
            "description": "RAG 시스템의 비즈니스 도메인, 하드웨어, 네트워크, 보안, 확장성 등 요구사항을 분석하고, AWS, Azure, GCP 등 주요 클라우드 서비스의 RAG 아키텍처 사례를 참고하여 최적의 플랫폼을 선정한다.",
            "dependencies": [],
            "details": "비즈니스 도메인 정의, 현행 시스템 분석, 클라우드별 RAG 지원 기능 및 제약사항 비교, 플랫폼 선정 근거 문서화.\n<info added on 2025-07-21T21:41:45.686Z>\nDocker Compose 기반 로컬 개발 스택\n\n• 파일 구조\n  ├─ docker-compose.yml\n  ├─ .env.example (환경변수 템플릿)\n  └─ compose/\n      ├─ es/\n      │   └─ elasticsearch.yml\n      └─ chroma/\n          └─ config.yaml\n\n• docker-compose.yml 주요 정의\n  services:\n    api:\n      build: .\n      container_name: rag_api\n      env_file:\n        - .env\n      depends_on: [redis, elasticsearch, chroma]\n      networks: [rag-net]\n      ports:\n        - \"8000:8000\"\n      command: uvicorn main:app --reload --host 0.0.0.0 --port 8000\n\n    redis:\n      image: redis:7-alpine\n      container_name: rag_redis\n      command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru\n      volumes:\n        - redis-data:/data\n      networks: [rag-net]\n\n    elasticsearch:\n      image: docker.elastic.co/elasticsearch/elasticsearch:8.11.3\n      container_name: rag_es\n      environment:\n        - discovery.type=single-node\n        - xpack.security.enabled=false\n        - \"ES_JAVA_OPTS=-Xms1g -Xmx1g\"\n      volumes:\n        - es-data:/usr/share/elasticsearch/data\n        - ./compose/es/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml\n      ports:\n        - \"9200:9200\"\n      networks: [rag-net]\n\n    chroma:\n      image: chromadb/chroma:0.5\n      container_name: rag_chroma\n      volumes:\n        - chroma-data:/chroma\n        - ./compose/chroma/config.yaml:/chroma/.chroma/chroma.yaml\n      ports:\n        - \"8001:8000\"\n      networks: [rag-net]\n\n  volumes:\n    redis-data:\n    es-data:\n    chroma-data:\n\n  networks:\n    rag-net:\n      driver: bridge\n\n• 개발자 편의 스크립트\n  make up          # docker compose up ‑d\n  make down        # docker compose down ‑v\n  make logs        # 실시간 로그 스트림\n  make rebuild     # 이미지 재빌드 후 재기동\n\n• 애플 실리콘(M1/M2) 대응\n  elasticsearch 이미지 → platform: linux/arm64\n  빌드명령: DOCKER_DEFAULT_PLATFORM=linux/arm64 make up\n\n• FastAPI, LangChain 코드 변경 사항\n  settings.py: REDIS_URL, ES_HOSTS, CHROMA_HOST, CHROMA_PORT를 .env에서 읽어오도록 수정\n  tests/conftest.py: docker_compose_file fixture 추가해 통합 테스트 컨테이너 재사용\n\n• 문서화\n  docs/local_dev.md에 “Docker Compose로 RAG 스택 띄우기” 절 신설\n  – 최초 실행 전 .env 복사 및 필수 값 기입 안내\n  – 각 서비스별 포트/URL/관리 콘솔 접근 방법 표 정리\n\n• 클라우드 배포(테라폼 · 쿠버네티스 등)는 별도 태스크(18.3 “운영 환경 배포 설계”)로 분리\n</info added on 2025-07-21T21:41:45.686Z>",
            "status": "pending",
            "testStrategy": "요구사항 명세서 및 플랫폼 선정 보고서 작성, 이해관계자 리뷰를 통해 적합성 검증."
          },
          {
            "id": 2,
            "title": "핵심 인프라 구성요소 설계",
            "description": "컴퓨팅(GPU/서버리스), 스토리지(오브젝트 스토리지), 벡터 데이터베이스, LLM/임베딩 엔드포인트 등 RAG 시스템의 핵심 인프라 구성요소를 설계한다.",
            "dependencies": [
              "18.1"
            ],
            "details": "각 구성요소별 서비스(AWS SageMaker, Bedrock, OpenSearch, Lambda 등) 선정 및 아키텍처 다이어그램 작성, 네트워크/보안 정책 설계.",
            "status": "pending",
            "testStrategy": "아키텍처 설계서 및 구성요소별 서비스 매핑표 작성, 설계 리뷰 진행."
          },
          {
            "id": 3,
            "title": "IaC(Infrastructure as Code) 자동화 구축",
            "description": "Terraform, AWS CDK, Azure Bicep 등 IaC 도구를 활용하여 전체 인프라 리소스(네트워크, IAM, 컴퓨팅, 스토리지, DB, 엔드포인트 등)를 코드로 정의하고 자동화 배포한다.",
            "dependencies": [
              "18.2"
            ],
            "details": "환경별(개발/운영) IaC 코드 작성, GitOps 및 코드 리뷰 프로세스 적용, 재현성 및 버전 관리 체계 수립.",
            "status": "pending",
            "testStrategy": "IaC 코드 배포 테스트(리소스 생성/삭제/변경), 코드 리뷰 및 CI/CD 파이프라인 검증."
          },
          {
            "id": 4,
            "title": "모니터링 및 장애 대응 체계 구축",
            "description": "CloudWatch, Azure Monitor 등 클라우드 네이티브 도구로 리소스 상태, 비용, 성능 모니터링 대시보드를 구축하고, 장애 알림 및 자동 복구 정책을 수립한다.",
            "dependencies": [
              "18.3"
            ],
            "details": "모니터링 지표 정의, 알림/오토스케일/헬스체크/롤백 등 장애 대응 시나리오 설계 및 구현.",
            "status": "pending",
            "testStrategy": "모니터링 대시보드 및 알림 테스트, 장애 복구 시나리오(오토스케일, 롤백 등) 실습 검증."
          },
          {
            "id": 5,
            "title": "보안 및 컴플라이언스 설계 및 문서화",
            "description": "IAM 정책, 네트워크 ACL, 데이터 암호화, 접근제어 등 보안 설계와 로그/감사 추적, 개인정보 보호 등 컴플라이언스 준수 방안을 마련하고, 전체 인프라 아키텍처 다이어그램, IaC 코드 주석, 운영 가이드, 장애 대응 매뉴얼 등 문서를 작성한다.",
            "dependencies": [
              "18.4"
            ],
            "details": "보안 정책 및 컴플라이언스 체크리스트 작성, 운영/장애 대응 문서화, 아키텍처 다이어그램 최신화.",
            "status": "pending",
            "testStrategy": "보안 설정 점검(침투 테스트, 권한 검토), 문서 리뷰 및 운영 시나리오 기반 실습 검증."
          }
        ]
      },
      {
        "id": 19,
        "title": "Elasticsearch BM25 + 벡터 앙상블 검색 기능 구현",
        "description": "RAG 시스템의 검색 성능 향상을 위해 Elasticsearch의 BM25 알고리즘과 벡터 임베딩 검색을 결합한 앙상블 검색 기능을 구현하고 최적화한다.",
        "details": "## 구현 세부사항\n\n1. **Elasticsearch 설정 및 인덱스 구성**\n   - Elasticsearch 클라이언트 설정 (`rag/search/elasticsearch_client.py`)\n     ```python\n     from elasticsearch import Elasticsearch\n     from config import settings\n     \n     def get_elasticsearch_client():\n         return Elasticsearch(\n             hosts=settings.ELASTICSEARCH_HOSTS,\n             basic_auth=(settings.ELASTICSEARCH_USERNAME, settings.ELASTICSEARCH_PASSWORD),\n             verify_certs=settings.ELASTICSEARCH_VERIFY_CERTS\n         )\n     ```\n   - 하이브리드 검색을 위한 인덱스 매핑 설정\n     ```python\n     def create_hybrid_index(index_name):\n         client = get_elasticsearch_client()\n         mapping = {\n             \"mappings\": {\n                 \"properties\": {\n                     \"content\": {\n                         \"type\": \"text\",\n                         \"analyzer\": \"korean\"  # 한국어 분석기 사용\n                     },\n                     \"vector_embedding\": {\n                         \"type\": \"dense_vector\",\n                         \"dims\": 1536,  # OpenAI 임베딩 차원 수\n                         \"index\": True,\n                         \"similarity\": \"cosine\"\n                     },\n                     \"metadata\": {\n                         \"type\": \"object\",\n                         \"properties\": {\n                             \"source\": {\"type\": \"keyword\"},\n                             \"doc_id\": {\"type\": \"keyword\"},\n                             \"chunk_id\": {\"type\": \"keyword\"}\n                         }\n                     }\n                 }\n             },\n             \"settings\": {\n                 \"analysis\": {\n                     \"analyzer\": {\n                         \"korean\": {\n                             \"type\": \"nori\",\n                             \"decompound_mode\": \"mixed\"\n                         }\n                     }\n                 }\n             }\n         }\n         client.indices.create(index=index_name, body=mapping)\n     ```\n\n2. **문서 인덱싱 모듈 (`rag/indexer/elasticsearch_indexer.py`)**\n   - 기존 벡터 DB 인덱싱 로직을 확장하여 Elasticsearch에도 동일 문서 저장\n   - 청크 단위로 텍스트와 벡터 임베딩을 함께 저장\n   ```python\n   async def index_document_to_elasticsearch(chunks, embeddings, doc_id, index_name=\"tax_documents\"):\n       client = get_elasticsearch_client()\n       bulk_data = []\n       \n       for i, (chunk, embedding) in enumerate(zip(chunks, embeddings)):\n           chunk_id = f\"{doc_id}_{i}\"\n           doc = {\n               \"content\": chunk.page_content,\n               \"vector_embedding\": embedding,\n               \"metadata\": {\n                   \"source\": chunk.metadata.get(\"source\", \"\"),\n                   \"doc_id\": doc_id,\n                   \"chunk_id\": chunk_id\n               }\n           }\n           \n           # Bulk 인덱싱을 위한 데이터 준비\n           bulk_data.append({\"index\": {\"_index\": index_name, \"_id\": chunk_id}})\n           bulk_data.append(doc)\n       \n       if bulk_data:\n           response = client.bulk(body=bulk_data, refresh=True)\n           return {\"indexed\": len(chunks), \"errors\": response.get(\"errors\", False)}\n   ```\n\n3. **하이브리드 검색 구현 (`rag/search/hybrid_search.py`)**\n   - BM25와 벡터 검색을 결합한 하이브리드 검색 함수\n   ```python\n   async def hybrid_search(query, top_k=5, alpha=0.3):\n       \"\"\"\n       하이브리드 검색 실행: BM25(키워드) + 벡터 검색 결합\n       alpha: 벡터 검색 가중치 (0~1 사이 값, 0은 BM25만, 1은 벡터 검색만)\n       \"\"\"\n       client = get_elasticsearch_client()\n       embedding_model = get_embedding_model()\n       query_embedding = await embedding_model.aembed_query(query)\n       \n       # 하이브리드 검색 쿼리 구성\n       search_query = {\n           \"size\": top_k,\n           \"query\": {\n               \"script_score\": {\n                   \"query\": {\n                       \"bool\": {\n                           \"must\": [\n                               {\"match\": {\"content\": query}}  # BM25 검색\n                           ]\n                       }\n                   },\n                   \"script\": {\n                       # BM25 스코어와 벡터 유사도 결합\n                       \"source\": f\"(1-{alpha}) * _score + {alpha} * cosineSimilarity(params.query_vector, 'vector_embedding')\",\n                       \"params\": {\n                           \"query_vector\": query_embedding\n                       }\n                   }\n               }\n           }\n       }\n       \n       response = client.search(index=\"tax_documents\", body=search_query)\n       \n       # 검색 결과 변환\n       results = []\n       for hit in response[\"hits\"][\"hits\"]:\n           results.append({\n               \"content\": hit[\"_source\"][\"content\"],\n               \"metadata\": hit[\"_source\"][\"metadata\"],\n               \"score\": hit[\"_score\"]\n           })\n       \n       return results\n   ```\n\n4. **검색 파라미터 최적화 모듈 (`rag/search/optimizer.py`)**\n   - 쿼리 유형에 따른 최적 가중치(alpha) 자동 조정\n   ```python\n   def optimize_search_params(query):\n       \"\"\"쿼리 특성에 따라 최적의 검색 파라미터 결정\"\"\"\n       # 전문 용어/법률 용어 비율 계산\n       legal_terms = [\"세금\", \"공제\", \"소득세\", \"부가가치세\", \"원천징수\", \"세액\", \"과세\", \"면세\"]\n       term_count = sum(1 for term in legal_terms if term in query)\n       \n       # 쿼리 길이 기반 최적화\n       query_length = len(query)\n       \n       if query_length < 10:  # 짧은 키워드 쿼리\n           return {\"alpha\": 0.2, \"top_k\": 7}  # BM25 가중치 높게\n       elif term_count >= 2:  # 전문 용어가 많은 쿼리\n           return {\"alpha\": 0.3, \"top_k\": 5}  # 균형적 접근\n       else:  # 일반 자연어 쿼리\n           return {\"alpha\": 0.7, \"top_k\": 5}  # 벡터 검색 가중치 높게\n   ```\n\n5. **API 엔드포인트 구현 (`api/rag/search.py`)**\n   - 하이브리드 검색 API 엔드포인트 추가\n   ```python\n   @router.post(\"/hybrid-search\")\n   async def hybrid_search_endpoint(\n       query: str = Body(..., embed=True),\n       top_k: int = Body(5, embed=True),\n       alpha: Optional[float] = Body(None, embed=True)\n   ):\n       \"\"\"하이브리드 검색 엔드포인트\"\"\"\n       # 검색 파라미터 최적화 (alpha가 지정되지 않은 경우)\n       if alpha is None:\n           params = optimize_search_params(query)\n           alpha = params[\"alpha\"]\n           top_k = params.get(\"top_k\", top_k)\n       \n       results = await hybrid_search(query, top_k=top_k, alpha=alpha)\n       return {\"results\": results, \"params\": {\"alpha\": alpha, \"top_k\": top_k}}\n   ```\n\n6. **성능 모니터링 및 로깅 (`rag/monitoring/search_metrics.py`)**\n   - 검색 성능 지표 수집 및 로깅\n   ```python\n   async def log_search_metrics(query, results, search_type, params, execution_time):\n       \"\"\"검색 성능 지표 로깅\"\"\"\n       metrics = {\n           \"timestamp\": datetime.now().isoformat(),\n           \"query\": query,\n           \"search_type\": search_type,\n           \"params\": params,\n           \"result_count\": len(results),\n           \"execution_time_ms\": execution_time,\n       }\n       \n       # 로그 저장 (파일 또는 DB)\n       async with aiofiles.open(\"logs/search_metrics.jsonl\", \"a\") as f:\n           await f.write(json.dumps(metrics) + \"\\n\")\n   ```\n\n7. **설정 파일 업데이트 (`config.py`)**\n   - Elasticsearch 관련 설정 추가\n   ```python\n   # Elasticsearch 설정\n   ELASTICSEARCH_HOSTS = os.getenv(\"ELASTICSEARCH_HOSTS\", \"http://localhost:9200\").split(\",\")\n   ELASTICSEARCH_USERNAME = os.getenv(\"ELASTICSEARCH_USERNAME\", \"\")\n   ELASTICSEARCH_PASSWORD = os.getenv(\"ELASTICSEARCH_PASSWORD\", \"\")\n   ELASTICSEARCH_VERIFY_CERTS = os.getenv(\"ELASTICSEARCH_VERIFY_CERTS\", \"false\").lower() == \"true\"\n   ```\n\n8. **기존 RAG 파이프라인과 통합**\n   - `rag/pipeline.py` 수정하여 하이브리드 검색 통합\n   ```python\n   async def retrieve_documents(query, search_type=\"hybrid\", **kwargs):\n       \"\"\"문서 검색 통합 함수\"\"\"\n       if search_type == \"hybrid\":\n           # 하이브리드 검색 사용\n           params = optimize_search_params(query)\n           alpha = kwargs.get(\"alpha\", params[\"alpha\"])\n           top_k = kwargs.get(\"top_k\", params[\"top_k\"])\n           \n           start_time = time.time()\n           results = await hybrid_search(query, top_k=top_k, alpha=alpha)\n           execution_time = (time.time() - start_time) * 1000\n           \n           # 성능 지표 로깅\n           await log_search_metrics(\n               query, results, \"hybrid\", \n               {\"alpha\": alpha, \"top_k\": top_k}, \n               execution_time\n           )\n           \n           return results\n       elif search_type == \"vector\":\n           # 기존 벡터 검색 사용\n           return await vector_search(query, **kwargs)\n       else:\n           raise ValueError(f\"Unsupported search type: {search_type}\")\n   ```",
        "testStrategy": "## 테스트 전략\n\n1. **단위 테스트 (pytest)**\n   - Elasticsearch 클라이언트 및 인덱스 생성 테스트\n   ```python\n   def test_elasticsearch_client_connection():\n       client = get_elasticsearch_client()\n       assert client.ping(), \"Elasticsearch 연결 실패\"\n   \n   def test_create_hybrid_index():\n       test_index = \"test_hybrid_index\"\n       create_hybrid_index(test_index)\n       client = get_elasticsearch_client()\n       assert client.indices.exists(index=test_index), \"인덱스 생성 실패\"\n       client.indices.delete(index=test_index)  # 테스트 후 정리\n   ```\n   \n   - 인덱싱 기능 테스트\n   ```python\n   @pytest.mark.asyncio\n   async def test_document_indexing():\n       # 테스트용 문서 청크 및 임베딩 생성\n       chunks = [Document(page_content=\"테스트 문서 내용\", metadata={\"source\": \"test.pdf\"})]\n       embeddings = [[0.1] * 1536]  # 테스트용 임베딩\n       \n       result = await index_document_to_elasticsearch(chunks, embeddings, \"test_doc\", \"test_index\")\n       assert not result.get(\"errors\"), \"인덱싱 중 오류 발생\"\n       assert result.get(\"indexed\") == 1, \"인덱싱된 문서 수 불일치\"\n   ```\n   \n   - 하이브리드 검색 기능 테스트\n   ```python\n   @pytest.mark.asyncio\n   async def test_hybrid_search():\n       # 테스트 데이터 인덱싱\n       await setup_test_data()\n       \n       # 다양한 알파 값으로 검색 테스트\n       for alpha in [0.0, 0.3, 0.7, 1.0]:\n           results = await hybrid_search(\"소득세 공제\", top_k=3, alpha=alpha)\n           assert len(results) <= 3, f\"alpha={alpha}일 때 결과 수 초과\"\n           assert all(\"content\" in r for r in results), f\"alpha={alpha}일 때 결과 형식 오류\"\n   ```\n   \n   - 파라미터 최적화 테스트\n   ```python\n   def test_search_param_optimization():\n       # 다양한 쿼리 유형에 대한 최적화 테스트\n       short_query = \"세금\"\n       legal_query = \"소득세 원천징수 공제\"\n       long_query = \"회사에서 받은 연봉에 대한 세금 계산은 어떻게 하나요?\"\n       \n       short_params = optimize_search_params(short_query)\n       legal_params = optimize_search_params(legal_query)\n       long_params = optimize_search_params(long_query)\n       \n       # 쿼리 유형별로 다른 파라미터가 반환되는지 확인\n       assert short_params[\"alpha\"] < long_params[\"alpha\"], \"짧은 쿼리와 긴 쿼리의 알파 값 최적화 실패\"\n       assert legal_params[\"top_k\"] > 0, \"법률 쿼리의 top_k 값 최적화 실패\"\n   ```\n\n2. **통합 테스트**\n   - API 엔드포인트 테스트 (FastAPI TestClient 사용)\n   ```python\n   def test_hybrid_search_endpoint():\n       client = TestClient(app)\n       response = client.post(\"/api/rag/hybrid-search\", json={\"query\": \"소득세 공제 방법\"})\n       \n       assert response.status_code == 200, \"API 응답 오류\"\n       data = response.json()\n       assert \"results\" in data, \"결과 필드 누락\"\n       assert \"params\" in data, \"파라미터 필드 누락\"\n       assert len(data[\"results\"]) > 0, \"검색 결과 없음\"\n   ```\n   \n   - 파라미터 커스터마이징 테스트\n   ```python\n   def test_hybrid_search_with_custom_params():\n       client = TestClient(app)\n       response = client.post(\n           \"/api/rag/hybrid-search\", \n           json={\"query\": \"세금 공제\", \"top_k\": 10, \"alpha\": 0.8}\n       )\n       \n       assert response.status_code == 200\n       data = response.json()\n       assert data[\"params\"][\"alpha\"] == 0.8, \"커스텀 알파 값이 적용되지 않음\"\n       assert data[\"params\"][\"top_k\"] == 10, \"커스텀 top_k 값이 적용되지 않음\"\n   ```\n\n3. **성능 테스트**\n   - 검색 속도 및 정확도 벤치마크\n   ```python\n   @pytest.mark.benchmark\n   def test_search_performance():\n       # 테스트 쿼리 세트\n       test_queries = [\n           \"소득세 공제 방법\",\n           \"부가가치세 신고 기한\",\n           \"사업자 세금 계산\",\n           \"연말정산 공제 항목\"\n       ]\n       \n       # 검색 유형별 성능 측정\n       for search_type in [\"hybrid\", \"vector\"]:\n           total_time = 0\n           for query in test_queries:\n               start_time = time.time()\n               if search_type == \"hybrid\":\n                   results = hybrid_search(query)\n               else:\n                   results = vector_search(query)\n               query_time = time.time() - start_time\n               total_time += query_time\n               \n               # 결과 수 확인\n               assert len(results) > 0, f\"{search_type} 검색 결과 없음: {query}\"\n           \n           avg_time = total_time / len(test_queries)\n           print(f\"{search_type} 검색 평균 시간: {avg_time:.4f}초\")\n   ```\n   \n   - 메모리 사용량 모니터링\n   ```python\n   def test_memory_usage():\n       import tracemalloc\n       \n       tracemalloc.start()\n       # 대량의 검색 요청 시뮬레이션\n       for i in range(100):\n           hybrid_search(f\"테스트 쿼리 {i % 10}\")\n       \n       current, peak = tracemalloc.get_traced_memory()\n       tracemalloc.stop()\n       \n       print(f\"현재 메모리 사용량: {current / 10**6:.2f}MB\")\n       print(f\"최대 메모리 사용량: {peak / 10**6:.2f}MB\")\n       \n       # 메모리 사용량 제한 확인\n       assert peak < 500 * 10**6, \"메모리 사용량이 500MB를 초과함\"\n   ```\n\n4. **A/B 테스트**\n   - 검색 품질 비교 테스트\n   ```python\n   def test_search_quality_comparison():\n       # 테스트 쿼리 및 예상 결과\n       test_cases = [\n           {\n               \"query\": \"소득세 공제 한도\",\n               \"expected_keywords\": [\"소득세\", \"공제\", \"한도\"]\n           },\n           {\n               \"query\": \"부가가치세 신고 방법\",\n               \"expected_keywords\": [\"부가가치세\", \"신고\", \"방법\"]\n           }\n       ]\n       \n       for case in test_cases:\n           # 벡터 검색 결과\n           vector_results = vector_search(case[\"query\"])\n           \n           # 하이브리드 검색 결과\n           hybrid_results = hybrid_search(case[\"query\"])\n           \n           # 키워드 포함 여부 확인\n           vector_match = count_keyword_matches(vector_results, case[\"expected_keywords\"])\n           hybrid_match = count_keyword_matches(hybrid_results, case[\"expected_keywords\"])\n           \n           print(f\"쿼리: {case['query']}\")\n           print(f\"벡터 검색 키워드 매치: {vector_match}\")\n           print(f\"하이브리드 검색 키워드 매치: {hybrid_match}\")\n           \n           # 하이브리드 검색이 더 많은 키워드를 포함해야 함\n           assert hybrid_match >= vector_match, \"하이브리드 검색 품질이 벡터 검색보다 낮음\"\n   ```\n\n5. **로깅 및 모니터링 테스트**\n   ```python\n   @pytest.mark.asyncio\n   async def test_search_metrics_logging():\n       # 로그 파일 초기화\n       if os.path.exists(\"logs/search_metrics.jsonl\"):\n           os.remove(\"logs/search_metrics.jsonl\")\n       \n       # 검색 실행 및 로깅\n       query = \"테스트 쿼리\"\n       results = [{\"content\": \"테스트 결과\"}]\n       await log_search_metrics(query, results, \"hybrid\", {\"alpha\": 0.5}, 100.5)\n       \n       # 로그 파일 확인\n       assert os.path.exists(\"logs/search_metrics.jsonl\"), \"로그 파일이 생성되지 않음\"\n       \n       # 로그 내용 확인\n       async with aiofiles.open(\"logs/search_metrics.jsonl\", \"r\") as f:\n           log_content = await f.read()\n           log_data = json.loads(log_content.strip())\n           \n           assert log_data[\"query\"] == query, \"로그에 쿼리가 기록되지 않음\"\n           assert log_data[\"execution_time_ms\"] == 100.5, \"실행 시간이 기록되지 않음\"\n   ```",
        "status": "in-progress",
        "dependencies": [],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Elasticsearch 클라이언트 설정 및 인덱스 구성",
            "description": "Elasticsearch 클라이언트를 설정하고 하이브리드 검색을 위한 인덱스를 구성합니다.",
            "dependencies": [],
            "details": "Elasticsearch 클라이언트 설정 및 인덱스 매핑을 통해 한국어 분석기를 사용하는 인덱스를 생성합니다.\n<info added on 2025-07-21T21:42:17.216Z>\n• Elasticsearch Python 클라이언트 설정  \n  ```python\n  from elasticsearch import Elasticsearch\n\n  def get_elasticsearch_client() -> Elasticsearch:\n      return Elasticsearch(\n          hosts=settings.ELASTICSEARCH_HOSTS,\n          basic_auth=(\n              settings.ELASTICSEARCH_USERNAME,\n              settings.ELASTICSEARCH_PASSWORD,\n          ),\n          verify_certs=settings.ELASTICSEARCH_VERIFY_CERTS,\n          request_timeout=30,\n          max_retries=3,\n          retry_on_timeout=True,\n      )\n  ```\n\n• 하이브리드 인덱스 매핑 및 nori 형태소 분석기 적용 예시  \n  ```python\n  def create_hybrid_index(index_name: str, dims: int = 768) -> None:\n      client = get_elasticsearch_client()\n\n      mapping_body = {\n          \"settings\": {\n              \"number_of_shards\": 1,\n              \"number_of_replicas\": 1,\n              \"analysis\": {\n                  \"analyzer\": {\n                      \"nori_analyzer\": {\n                          \"type\": \"custom\",\n                          \"tokenizer\": \"nori_tokenizer\",\n                          \"filter\": [\"lowercase\", \"nori_readingform\"]\n                      }\n                  }\n              }\n          },\n          \"mappings\": {\n              \"properties\": {\n                  \"content\": {           # BM25 검색용\n                      \"type\": \"text\",\n                      \"analyzer\": \"nori_analyzer\"\n                  },\n                  \"embedding\": {         # 벡터 검색용\n                      \"type\": \"dense_vector\",\n                      \"dims\": dims,\n                      \"index\": True,\n                      \"similarity\": \"cosine\"\n                  },\n                  \"doc_id\": { \"type\": \"keyword\" },\n                  \"created_at\": { \"type\": \"date\" }\n              }\n          }\n      }\n\n      if client.indices.exists(index=index_name):\n          client.indices.delete(index=index_name)\n      client.indices.create(index=index_name, body=mapping_body)\n  ```\n\n• 적용 결과  \n  1. `content` 필드는 nori 기반 분석으로 BM25 텍스트 검색을 수행.  \n  2. `embedding` 필드는 cosine 유사도로 벡터 인덱싱되어 ANN 검색 엔진과 동일한 결과를 제공.  \n  3. 단일 인덱스에서 두 필드를 조합하여 BM25 점수와 벡터 점수를 앙상블하여 최종 랭킹을 계산할 수 있도록 foundation 구축.\n</info added on 2025-07-21T21:42:17.216Z>",
            "status": "in-progress",
            "testStrategy": "Elasticsearch 클라이언트 연결 및 인덱스 생성 테스트"
          },
          {
            "id": 2,
            "title": "문서 인덱싱 모듈 구현",
            "description": "기존 벡터 DB 인덱싱 로직을 확장하여 Elasticsearch에도 문서를 저장합니다.",
            "dependencies": [
              "19.1"
            ],
            "details": "청크 단위로 텍스트와 벡터 임베딩을 함께 저장하는 모듈을 구현합니다.",
            "status": "pending",
            "testStrategy": "문서 인덱싱 기능 테스트"
          },
          {
            "id": 3,
            "title": "하이브리드 검색 기능 구현",
            "description": "BM25와 벡터 검색을 결합한 하이브리드 검색 함수를 구현합니다.",
            "dependencies": [
              "19.1",
              "19.2"
            ],
            "details": "BM25와 벡터 임베딩의 스코어를 결합하여 하이브리드 검색을 수행합니다.\n<info added on 2025-07-21T21:42:44.672Z>\n구현 세부사항 추가\n• 위치: rag/search/hybrid_search.py\n• 함수 시그니처\n    def hybrid_rrf_search(\n        query: str,\n        *,\n        alpha: float = 0.5,\n        top_k: int = 10,\n        rrf_k: int = 60,\n        es_index: str = \"tax_docs\",\n        client: Elasticsearch | None = None,\n    ) -> list[dict]:\n        \"\"\"\n        BM25 + 벡터 검색 결과를 Reciprocal Rank Fusion(RRF)으로 결합하여 상위 top_k 문서를 반환\n\n        Args:\n            query: 사용자 검색어\n            alpha: BM25(α)와 벡터(1-α) 가중치\n            top_k: 최종 반환 문서 개수\n            rrf_k: RRF 분모 보정값(일반적으로 60)\n            es_index: 검색 대상 인덱스\n            client: 주입 가능한 Elasticsearch 인스턴스\n        \"\"\"\n\n• 알고리즘\n  1. BM25 검색 → bm25_results = [(doc_id, rank)]\n     - ES `search` + `multi_match`(query, fields=[\"title^2\",\"content\"])\n  2. 벡터 KNN 검색 → vector_results = [(doc_id, rank)]\n     - ES `knn_search` + `field=\"embedding\"`\n  3. RRF 스코어 계산\n     - rrf_score(rank) = 1 / (rrf_k + rank)\n  4. 두 랭킹의 RRF 스코어 가중 합산\n     - fusion_score[doc_id] = α * rrf_bm25 + (1-α) * rrf_vector\n  5. fusion_score 내림차순 정렬 후 top_k 반환\n\n• 예외 처리\n  - alpha ∉ [0,1] 입력 시 ValueError\n  - ES 연결 실패 시 ConnectionError\n\n• 테스트 전략 (pytest)\n  - fixture 로 BM25/벡터 모의 결과 생성, hybrid_rrf_search 실행 후\n    ▪ alpha=1 → BM25 순서와 동일\n    ▪ alpha=0 → 벡터 순서와 동일\n    ▪ alpha=0.5 → 결합 스코어 수학적 기대치 검증\n  - rrf_k 값 변화에 따른 스코어 단조성 확인\n  - top_k 초과 문서 요청 시 결과 길이 == top_k 검증\n</info added on 2025-07-21T21:42:44.672Z>",
            "status": "pending",
            "testStrategy": "하이브리드 검색 기능 테스트"
          },
          {
            "id": 4,
            "title": "검색 파라미터 최적화 모듈 구현",
            "description": "쿼리 유형에 따른 최적 가중치를 자동으로 조정하는 모듈을 구현합니다.",
            "dependencies": [
              "19.3"
            ],
            "details": "쿼리 특성에 따라 BM25와 벡터 검색의 가중치를 최적화합니다.",
            "status": "pending",
            "testStrategy": "검색 파라미터 최적화 테스트"
          },
          {
            "id": 5,
            "title": "API 엔드포인트 및 성능 모니터링 구현",
            "description": "하이브리드 검색 API 엔드포인트를 추가하고 성능 지표를 수집합니다.",
            "dependencies": [
              "19.3",
              "19.4"
            ],
            "details": "하이브리드 검색을 위한 API 엔드포인트를 구현하고 성능 지표를 로깅합니다.",
            "status": "pending",
            "testStrategy": "API 엔드포인트 테스트 및 성능 지표 로깅 테스트"
          }
        ]
      },
      {
        "id": 20,
        "title": "LangGraph 기반 고급 RAG 파이프라인 구현",
        "description": "LangGraph를 활용하여 Reranking, 문서 컨텍스트 확장, 멀티쿼리, Self Query 등 고급 RAG 기능을 구현하고 기존 시스템에 통합한다.",
        "details": "## 구현 세부사항\n\n1. **LangGraph 기반 RAG 파이프라인 설계 (`rag/pipelines/langgraph_rag.py`)**\n   - LangGraph 상태 관리 및 노드 구성\n   ```python\n   from langgraph.graph import StateGraph\n   from pydantic import BaseModel, Field\n   \n   class RAGState(BaseModel):\n       query: str\n       retrieved_documents: list = Field(default_factory=list)\n       reranked_documents: list = Field(default_factory=list)\n       expanded_context: str = \"\"\n       generated_queries: list = Field(default_factory=list)\n       final_answer: str = \"\"\n       feedback: dict = Field(default_factory=dict)\n   \n   def create_rag_graph(llm, retriever, reranker):\n       workflow = StateGraph(RAGState)\n       \n       # 노드 정의\n       workflow.add_node(\"query_analysis\", query_analysis)\n       workflow.add_node(\"query_generation\", generate_multiple_queries)\n       workflow.add_node(\"retrieval\", retrieve_documents)\n       workflow.add_node(\"reranking\", rerank_documents)\n       workflow.add_node(\"context_expansion\", expand_document_context)\n       workflow.add_node(\"answer_generation\", generate_answer)\n       \n       # 엣지 정의\n       workflow.add_edge(\"query_analysis\", \"query_generation\")\n       workflow.add_edge(\"query_generation\", \"retrieval\")\n       workflow.add_edge(\"retrieval\", \"reranking\")\n       workflow.add_edge(\"reranking\", \"context_expansion\")\n       workflow.add_edge(\"context_expansion\", \"answer_generation\")\n       \n       # 조건부 엣지 (피드백 루프)\n       workflow.add_conditional_edges(\n           \"answer_generation\",\n           should_continue,\n           {\n               True: \"query_generation\",  # 불충분한 답변 시 쿼리 재생성\n               False: END\n           }\n       )\n       \n       return workflow.compile()\n   ```\n\n2. **멀티쿼리 생성 모듈 (`rag/components/multi_query.py`)**\n   - 원본 쿼리에서 다양한 관점의 하위 쿼리 생성\n   ```python\n   def generate_multiple_queries(state: RAGState, llm) -> RAGState:\n       \"\"\"원본 쿼리에서 다양한 관점의 하위 쿼리 생성\"\"\"\n       prompt = PromptTemplate.from_template(\n           \"\"\"원본 질문: {query}\n           \n           이 질문에 대한 정보를 검색하기 위해 서로 다른 관점에서 3-5개의 검색 쿼리를 생성하세요.\n           각 쿼리는 원본 질문의 다른 측면이나 관점을 다루어야 합니다.\n           \n           생성된 쿼리:\"\"\"\n       )\n       \n       response = llm.invoke(prompt.format(query=state.query))\n       queries = [q.strip() for q in response.split(\"\\n\") if q.strip()]\n       \n       return RAGState(\n           query=state.query,\n           generated_queries=queries\n       )\n   ```\n\n3. **Self Query 구현 (`rag/components/self_query.py`)**\n   - 쿼리 자체 분석 및 메타데이터 필터링 로직\n   ```python\n   def parse_self_query(state: RAGState, llm) -> dict:\n       \"\"\"쿼리를 분석하여 메타데이터 필터 추출\"\"\"\n       prompt = PromptTemplate.from_template(\n           \"\"\"질문: {query}\n           \n           이 질문에서 다음 메타데이터 필드에 대한 필터 조건을 추출하세요:\n           - 문서 유형 (법률, 판례, 세무 가이드 등)\n           - 날짜 범위 (예: 2020년 이후)\n           - 관련 법률 분야 (소득세법, 법인세법 등)\n           \n           JSON 형식으로 응답하세요:\"\"\"\n       )\n       \n       response = llm.invoke(prompt.format(query=state.query))\n       try:\n           filters = json.loads(response)\n           return filters\n       except:\n           return {}\n   ```\n\n4. **Reranking 모듈 (`rag/components/reranker.py`)**\n   - 검색된 문서 재순위화 로직\n   ```python\n   from sentence_transformers import CrossEncoder\n   \n   class CrossEncoderReranker:\n       def __init__(self, model_name=\"cross-encoder/ms-marco-MiniLM-L-6-v2\"):\n           self.model = CrossEncoder(model_name)\n           \n       def rerank(self, query: str, documents: list) -> list:\n           \"\"\"검색된 문서를 쿼리 관련성에 따라 재순위화\"\"\"\n           pairs = [[query, doc.page_content] for doc in documents]\n           scores = self.model.predict(pairs)\n           \n           # 점수와 문서를 결합하고 정렬\n           scored_docs = list(zip(scores, documents))\n           scored_docs.sort(key=lambda x: x[0], reverse=True)\n           \n           # 정렬된 문서 반환\n           return [doc for _, doc in scored_docs]\n   ```\n\n5. **문서 컨텍스트 확장 (`rag/components/context_expansion.py`)**\n   - 검색된 문서의 컨텍스트 확장 로직\n   ```python\n   def expand_document_context(state: RAGState, llm, retriever) -> RAGState:\n       \"\"\"검색된 문서의 컨텍스트를 확장\"\"\"\n       expanded_docs = []\n       \n       for doc in state.reranked_documents[:3]:  # 상위 3개 문서만 처리\n           # 문서에서 키워드 추출\n           keywords_prompt = PromptTemplate.from_template(\n               \"\"\"다음 텍스트에서 중요한 키워드 5개를 추출하세요:\n               {text}\n               \n               키워드:\"\"\"\n           )\n           keywords_text = llm.invoke(keywords_prompt.format(text=doc.page_content))\n           keywords = [k.strip() for k in keywords_text.split(\",\")]\n           \n           # 키워드로 추가 문서 검색\n           additional_docs = []\n           for keyword in keywords:\n               results = retriever.get_relevant_documents(keyword)\n               additional_docs.extend(results)\n           \n           # 중복 제거 및 원본 문서와 병합\n           unique_additional = [d for d in additional_docs if d.page_content != doc.page_content]\n           expanded_context = doc.page_content + \"\\n\\n관련 컨텍스트:\\n\" + \"\\n\\n\".join([d.page_content for d in unique_additional[:2]])\n           \n           # 메타데이터 유지하면서 확장된 컨텍스트로 문서 업데이트\n           expanded_doc = Document(page_content=expanded_context, metadata=doc.metadata)\n           expanded_docs.append(expanded_doc)\n       \n       return RAGState(\n           query=state.query,\n           retrieved_documents=state.retrieved_documents,\n           reranked_documents=expanded_docs,\n           expanded_context=\"\\n\\n\".join([d.page_content for d in expanded_docs])\n       )\n   ```\n\n6. **통합 API 엔드포인트 (`api/routes/advanced_rag.py`)**\n   - FastAPI 라우터에 고급 RAG 엔드포인트 추가\n   ```python\n   from fastapi import APIRouter, Depends\n   from pydantic import BaseModel\n   from rag.pipelines.langgraph_rag import create_rag_graph\n   \n   router = APIRouter(prefix=\"/api/advanced-rag\", tags=[\"Advanced RAG\"])\n   \n   class AdvancedRAGRequest(BaseModel):\n       query: str\n       use_multi_query: bool = True\n       use_reranking: bool = True\n       use_context_expansion: bool = True\n       use_self_query: bool = True\n   \n   class AdvancedRAGResponse(BaseModel):\n       answer: str\n       sources: list\n       reasoning_trace: list\n   \n   @router.post(\"/query\", response_model=AdvancedRAGResponse)\n   async def advanced_rag_query(request: AdvancedRAGRequest):\n       # 컴포넌트 초기화\n       llm = get_llm()\n       retriever = get_retriever()\n       reranker = CrossEncoderReranker()\n       \n       # 그래프 생성\n       rag_graph = create_rag_graph(llm, retriever, reranker)\n       \n       # 초기 상태 설정\n       initial_state = RAGState(query=request.query)\n       \n       # 그래프 실행\n       result = rag_graph.invoke(initial_state)\n       \n       return AdvancedRAGResponse(\n           answer=result.final_answer,\n           sources=[{\n               \"content\": doc.page_content[:200] + \"...\",\n               \"metadata\": doc.metadata\n           } for doc in result.reranked_documents],\n           reasoning_trace=result.feedback.get(\"reasoning_trace\", [])\n       )\n   ```\n\n7. **성능 평가 및 모니터링 (`rag/evaluation/advanced_metrics.py`)**\n   - 고급 RAG 파이프라인 성능 측정\n   ```python\n   def evaluate_advanced_rag(test_queries, ground_truth, rag_pipeline):\n       \"\"\"고급 RAG 파이프라인 성능 평가\"\"\"\n       metrics = {\n           \"accuracy\": 0,\n           \"retrieval_precision\": 0,\n           \"answer_relevance\": 0,\n           \"context_quality\": 0\n       }\n       \n       for query, truth in zip(test_queries, ground_truth):\n           result = rag_pipeline.invoke({\"query\": query})\n           \n           # 정확도 평가\n           accuracy = calculate_answer_accuracy(result.final_answer, truth[\"answer\"])\n           \n           # 검색 정밀도 평가\n           retrieval_precision = calculate_retrieval_precision(\n               result.retrieved_documents, \n               truth[\"relevant_docs\"]\n           )\n           \n           # 답변 관련성 평가\n           answer_relevance = calculate_answer_relevance(\n               query, \n               result.final_answer\n           )\n           \n           # 컨텍스트 품질 평가\n           context_quality = calculate_context_quality(\n               result.expanded_context,\n               truth[\"ideal_context\"]\n           )\n           \n           metrics[\"accuracy\"] += accuracy\n           metrics[\"retrieval_precision\"] += retrieval_precision\n           metrics[\"answer_relevance\"] += answer_relevance\n           metrics[\"context_quality\"] += context_quality\n       \n       # 평균 계산\n       for key in metrics:\n           metrics[key] /= len(test_queries)\n           \n       return metrics\n   ```\n\n8. **기존 시스템과의 통합**\n   - 기존 RAG 시스템에 고급 기능 통합\n   - 설정 기반 기능 활성화/비활성화 옵션 제공\n   ```python\n   # config.py에 설정 추가\n   ADVANCED_RAG_CONFIG = {\n       \"use_langgraph\": True,\n       \"use_multi_query\": True,\n       \"use_reranking\": True,\n       \"use_context_expansion\": True,\n       \"use_self_query\": True\n   }\n   ```\n\n9. **성능 최적화 및 캐싱**\n   - 멀티쿼리 결과 및 재순위화 결과 캐싱\n   - 비동기 처리를 통한 병렬 검색 최적화\n   ```python\n   async def retrieve_from_multiple_queries(queries: list, retriever) -> list:\n       \"\"\"여러 쿼리에서 병렬로 문서 검색\"\"\"\n       tasks = [retrieve_documents(query, retriever) for query in queries]\n       results = await asyncio.gather(*tasks)\n       \n       # 결과 병합 및 중복 제거\n       all_docs = []\n       seen_contents = set()\n       \n       for docs in results:\n           for doc in docs:\n               if doc.page_content not in seen_contents:\n                   seen_contents.add(doc.page_content)\n                   all_docs.append(doc)\n       \n       return all_docs\n   ```",
        "testStrategy": "## 테스트 전략\n\n1. **단위 테스트 (pytest)**\n   - 각 LangGraph 노드 기능 테스트\n   ```python\n   def test_multi_query_generation():\n       \"\"\"멀티쿼리 생성 기능 테스트\"\"\"\n       state = RAGState(query=\"세금 공제 방법에 대해 알려주세요\")\n       llm = MockLLM(responses=[\"1. 소득세 공제 방법\\n2. 사업자 세금 공제\\n3. 부가가치세 공제 절차\"])\n       \n       result = generate_multiple_queries(state, llm)\n       \n       assert len(result.generated_queries) >= 3\n       assert \"소득세\" in result.generated_queries[0]\n       assert \"사업자\" in result.generated_queries[1]\n   \n   def test_reranker():\n       \"\"\"재순위화 모듈 테스트\"\"\"\n       reranker = CrossEncoderReranker()\n       query = \"법인세 신고 기한\"\n       docs = [\n           Document(page_content=\"법인세 신고는 사업연도 종료일로부터 3개월 이내에 해야 합니다.\", metadata={\"source\": \"tax_law_1\"}),\n           Document(page_content=\"소득세 신고 기한은 매년 5월입니다.\", metadata={\"source\": \"tax_law_2\"}),\n           Document(page_content=\"법인세란 법인의 소득에 부과되는 세금입니다.\", metadata={\"source\": \"tax_law_3\"})\n       ]\n       \n       reranked = reranker.rerank(query, docs)\n       \n       assert reranked[0].metadata[\"source\"] == \"tax_law_1\"  # 가장 관련성 높은 문서가 첫번째\n   \n   def test_context_expansion():\n       \"\"\"컨텍스트 확장 기능 테스트\"\"\"\n       state = RAGState(\n           query=\"법인세 계산 방법\",\n           reranked_documents=[\n               Document(page_content=\"법인세는 과세표준에 세율을 곱하여 계산합니다.\", metadata={\"source\": \"tax_doc\"})\n           ]\n       )\n       \n       llm = MockLLM(responses=[\"법인세, 과세표준, 세율, 계산, 공제\"])\n       retriever = MockRetriever(docs=[\n           Document(page_content=\"과세표준이란 총수입금액에서 필요경비를 차감한 금액입니다.\", metadata={\"source\": \"tax_terms\"}),\n           Document(page_content=\"법인세 세율은 과세표준에 따라 10~25%입니다.\", metadata={\"source\": \"tax_rates\"})\n       ])\n       \n       result = expand_document_context(state, llm, retriever)\n       \n       assert \"과세표준\" in result.expanded_context\n       assert \"세율\" in result.expanded_context\n       assert len(result.reranked_documents) > 0\n   ```\n\n2. **통합 테스트**\n   - 전체 LangGraph 파이프라인 테스트\n   ```python\n   def test_langgraph_rag_pipeline():\n       \"\"\"LangGraph RAG 파이프라인 통합 테스트\"\"\"\n       llm = get_test_llm()\n       retriever = get_test_retriever()\n       reranker = CrossEncoderReranker()\n       \n       rag_graph = create_rag_graph(llm, retriever, reranker)\n       \n       test_query = \"2023년 개정된 소득세법에 따른 종합소득세 계산 방법을 알려주세요\"\n       initial_state = RAGState(query=test_query)\n       \n       result = rag_graph.invoke(initial_state)\n       \n       assert result.final_answer != \"\"\n       assert len(result.retrieved_documents) > 0\n       assert len(result.reranked_documents) > 0\n       assert \"소득세\" in result.final_answer\n   ```\n\n3. **API 엔드포인트 테스트**\n   - FastAPI TestClient를 사용한 엔드포인트 테스트\n   ```python\n   def test_advanced_rag_endpoint():\n       \"\"\"고급 RAG API 엔드포인트 테스트\"\"\"\n       from fastapi.testclient import TestClient\n       from main import app\n       \n       client = TestClient(app)\n       \n       response = client.post(\n           \"/api/advanced-rag/query\",\n           json={\n               \"query\": \"법인세 신고시 필요한 서류는 무엇인가요?\",\n               \"use_multi_query\": True,\n               \"use_reranking\": True,\n               \"use_context_expansion\": True\n           }\n       )\n       \n       assert response.status_code == 200\n       data = response.json()\n       assert \"answer\" in data\n       assert \"sources\" in data\n       assert len(data[\"sources\"]) > 0\n   ```\n\n4. **성능 평가 테스트**\n   - 기존 RAG와 고급 RAG 성능 비교 테스트\n   ```python\n   def test_advanced_rag_performance():\n       \"\"\"고급 RAG와 기본 RAG 성능 비교\"\"\"\n       test_queries = [\n           \"부가가치세 신고 기한은 언제인가요?\",\n           \"개인사업자가 받을 수 있는 세금 혜택은?\",\n           \"법인 설립 시 납부해야 하는 세금은?\"\n       ]\n       \n       # 기본 RAG 성능 측정\n       basic_rag = get_basic_rag_pipeline()\n       basic_metrics = evaluate_rag(test_queries, basic_rag)\n       \n       # 고급 RAG 성능 측정\n       advanced_rag = get_advanced_rag_pipeline()\n       advanced_metrics = evaluate_advanced_rag(test_queries, advanced_rag)\n       \n       # 성능 비교\n       assert advanced_metrics[\"accuracy\"] > basic_metrics[\"accuracy\"]\n       assert advanced_metrics[\"retrieval_precision\"] > basic_metrics[\"retrieval_precision\"]\n       \n       print(f\"기본 RAG 정확도: {basic_metrics['accuracy']:.2f}\")\n       print(f\"고급 RAG 정확도: {advanced_metrics['accuracy']:.2f}\")\n       print(f\"성능 향상: {(advanced_metrics['accuracy'] - basic_metrics['accuracy']) * 100:.1f}%\")\n   ```\n\n5. **부하 테스트**\n   - 고급 RAG 파이프라인의 성능 및 확장성 테스트\n   ```python\n   def test_advanced_rag_load():\n       \"\"\"고급 RAG 파이프라인 부하 테스트\"\"\"\n       import time\n       from concurrent.futures import ThreadPoolExecutor\n       \n       rag_pipeline = get_advanced_rag_pipeline()\n       test_queries = generate_test_queries(50)  # 50개 테스트 쿼리 생성\n       \n       # 단일 쿼리 처리 시간 측정\n       start_time = time.time()\n       rag_pipeline.invoke({\"query\": test_queries[0]})\n       single_query_time = time.time() - start_time\n       \n       # 병렬 처리 성능 측정\n       start_time = time.time()\n       with ThreadPoolExecutor(max_workers=5) as executor:\n           results = list(executor.map(\n               lambda q: rag_pipeline.invoke({\"query\": q}),\n               test_queries[:10]\n           ))\n       parallel_time = time.time() - start_time\n       \n       # 결과 분석\n       avg_parallel_time = parallel_time / 10\n       print(f\"단일 쿼리 처리 시간: {single_query_time:.2f}초\")\n       print(f\"병렬 처리 평균 시간: {avg_parallel_time:.2f}초\")\n       print(f\"처리량: {10 / parallel_time:.2f} 쿼리/초\")\n   ```",
        "status": "pending",
        "dependencies": [],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "LangGraph 기반 고급 RAG 파이프라인 설계 및 그래프 구조 정의",
            "description": "LangGraph의 상태 관리, 노드, 엣지, 조건부 흐름을 활용하여 고급 RAG 파이프라인의 전체 구조를 설계하고, 각 단계별 노드(쿼리 분석, 멀티쿼리 생성, 검색, 재순위화, 컨텍스트 확장, 답변 생성 등)와 상태(State) 모델을 정의한다.",
            "dependencies": [],
            "details": "LangGraph의 그래프 구조와 상태(State) 관리 방식을 적용해 각 고급 RAG 기능을 노드로 분리하고, 순환 처리 및 조건부 분기(Conditional Edge) 등 복잡한 워크플로우를 설계한다. 각 노드별 입력/출력 상태를 명확히 정의한다.\n<info added on 2025-07-21T21:43:19.831Z>\nState 및 노드 세부 정의, 조건부 엣지, Streamlit 설정 스키마\n\n1. RAGState 모델 (pydantic)\nclass RAGState(BaseModel):\n    query: str\n    parsed_query: str | None = None\n    multi_queries: list[str] = Field(default_factory=list)\n    retrieved_docs: list[Document] = Field(default_factory=list)\n    reranked_docs: list[Document] = Field(default_factory=list)\n    expanded_context: str = \"\"\n    answer: str | None = None\n    metadata: dict = Field(default_factory=dict)\n\n2. 노드 매핑\nquery_analyzer       : 쿼리 의도·엔티티 분석 → parsed_query\nmulti_query_generator: parsed_query 기반 파생 쿼리 N개 생성 → multi_queries\nretriever            : (query 또는 multi_queries) 로 벡터 DB 검색 → retrieved_docs\nreranker             : cross-encoder로 재정렬 → reranked_docs\ncontext_expander     : 인접 문단, 요약, citation 삽입 → expanded_context\nanswer_generator     : expanded_context + query 로 최종 답변 → answer\n\n3. 조건부 엣지 규칙(python 의사코드)\ncfg = RAGConfig(...)\ng = StateGraph(RAGState)\n...\ng.add_conditional_edges(\n    source=\"query_analyzer\",\n    condition=lambda s: cfg.enable_multi_query,\n    true_edge=\"multi_query_generator\",\n    false_edge=\"retriever\",\n)\ng.add_edge(\"multi_query_generator\", \"retriever\")\ng.add_conditional_edges(\n    source=\"retriever\",\n    condition=lambda s: cfg.enable_reranker,\n    true_edge=\"reranker\",\n    false_edge=\"context_expander\",\n)\ng.add_edge(\"reranker\", \"context_expander\")\ng.add_conditional_edges(\n    source=\"context_expander\",\n    condition=lambda s: cfg.enable_context_expander,\n    true_edge=\"answer_generator\",\n    false_edge=\"answer_generator\",  # off 일 때도 바로 answer_generator 로 이동\n)\ng.set_entry_point(\"query_analyzer\")\ng.set_terminal_nodes([\"answer_generator\"])\n\n4. Streamlit UI 연동용 설정 스키마\nclass RAGConfig(BaseModel):\n    enable_multi_query: bool = True\n    enable_reranker: bool = True\n    enable_context_expander: bool = True\n    top_k_search: int = 4\n    top_k_multi_query: int = 3\n    temperature: float = 0.3\n\n5. Streamlit 예시\nwith st.sidebar:\n    cfg = RAGConfig(\n        enable_multi_query = st.checkbox(\"멀티쿼리 생성\", value=True),\n        enable_reranker = st.checkbox(\"Reranker 사용\", value=True),\n        enable_context_expander = st.checkbox(\"컨텍스트 확장\", value=True),\n        top_k_search = st.slider(\"검색 top-k\",1,10,4),\n        top_k_multi_query = st.slider(\"멀티쿼리 k\",1,10,3),\n        temperature = st.slider(\"LLM 온도\",0.0,1.0,0.3,0.05),\n    )\n...\nexecutor = graph.compile()\nresult_state = executor.invoke({\"state\": RAGState(query=user_query), \"config\": cfg})\n</info added on 2025-07-21T21:43:19.831Z>",
            "status": "pending",
            "testStrategy": "각 노드별 단위 테스트 및 그래프 전체 실행 시 상태 전이와 흐름이 의도대로 동작하는지 검증한다."
          },
          {
            "id": 2,
            "title": "멀티쿼리 생성 및 Self Query 분석 모듈 구현",
            "description": "원본 쿼리로부터 다양한 관점의 하위 쿼리를 생성하는 멀티쿼리 모듈과, 쿼리 내 메타데이터 필터 조건을 추출하는 Self Query 분석 모듈을 개발한다.",
            "dependencies": [
              "20.1"
            ],
            "details": "LLM 기반 프롬프트를 활용해 멀티쿼리 생성 및 Self Query 분석 로직을 구현하고, 생성된 쿼리와 필터 정보를 상태에 반영한다.",
            "status": "pending",
            "testStrategy": "예시 쿼리 입력 시 다양한 하위 쿼리와 올바른 메타데이터 필터가 추출되는지 단위 테스트로 검증한다."
          },
          {
            "id": 3,
            "title": "검색, Reranking, 문서 컨텍스트 확장 모듈 개발",
            "description": "생성된 쿼리 및 필터를 이용해 문서를 검색하고, CrossEncoder 등으로 재순위화하며, 상위 문서의 컨텍스트를 키워드 기반으로 확장하는 모듈을 구현한다.",
            "dependencies": [
              "20.2"
            ],
            "details": "검색 결과에 대해 재순위화 및 컨텍스트 확장 로직을 적용하고, 확장된 문서 정보를 상태에 반영한다.\n<info added on 2025-07-21T21:43:49.184Z>\n• 구현 범위 확대  \n  1. CrossEncoder 기반 Reranking 노드(`rag/nodes/rerank.py`)  \n     – sentence-transformers[`CrossEncoder`](https://www.sbert.net) 활용, 모델명은 ENV `CROSS_ENCODER_MODEL`(기본값 *cross-encoder/ms-marco-MiniLM-L-6-v2*).  \n     – 입력: `state.retrieved_documents`(List[Document])  \n       출력: `state.reranked_documents`(score 속성 추가 후 상위 k=15 리스트)  \n     – 독립 테스트: `tests/nodes/test_rerank.py :: test_rerank_top_order`  \n       ‑ Faker 문서 10개와 쿼리 “양도소득세”에 대해 score 내림차순 정렬 여부 검증.\n\n  2. PDF 부모 문서 컨텍스트 확장 노드(`rag/nodes/expand_parent.py`)  \n     – 각 child chunk의 metadata(`pdf_path`, `page_num`)를 사용해 PyPDF로 해당 페이지±δ(기본 δ=2) 전체 텍스트를 로드하여 `parent_context` 필드로 합산.  \n     – 중복 제거(BM25 기반 85 % 이상 유사 문장 skip) 후 `state.expanded_context` 업데이트.  \n     – 독립 테스트: `tests/nodes/test_expand_parent.py :: test_page_window_merge`  \n       ‑ fixture PDF(5 p)에서 2페이지 chunk 입력 시 1-3페이지 텍스트가 포함되는지 확인.\n\n  3. 멀티쿼리 결과 병합 노드(`rag/nodes/merge_multiquery.py`)  \n     – 입력: `state.multiquery_results`(List[List[Document]])  \n     – 전략: (a) 문서 ID+page 해시를 키로 dedup, (b) 동일 문서 다중 hit 시 rerank score 가중 평균, (c) 최종 상위 N=30 선택 → `state.retrieved_documents` 갱신.  \n     – 독립 테스트: `tests/nodes/test_merge_multiquery.py :: test_dedup_and_score`  \n       ‑ 두 쿼리에서 동일 문서가 겹칠 때 하나로 합쳐지고 score 평균이 계산되는지 검증.\n\n• LangGraph 통합  \n  – `rag/pipelines/langgraph_rag.py` 에서 위 세 노드를 `StateGraph` 에 추가하고 의존 흐름 정의:  \n    GenerateQueries → Search → MergeMultiQuery → Rerank → ExpandParent → AnswerGeneration.\n\n• 상태 모델 확장  \n  ```python\n  class RAGState(BaseModel):\n      ...\n      multiquery_results: list = Field(default_factory=list)\n      parent_context: str = \"\"\n  ```\n\n• CI 반영  \n  – `pyproject.toml` 에 `sentence-transformers`, `pypdf`, `rank_bm25` 추가.  \n  – `pytest -m \"nodes\"` 태그로 노드 단위 테스트만 실행 가능하도록 마커 분리.\n</info added on 2025-07-21T21:43:49.184Z>",
            "status": "pending",
            "testStrategy": "검색-재순위화-컨텍스트 확장 각 단계별로 입력/출력의 품질과 일관성을 단위 테스트로 검증한다."
          },
          {
            "id": 4,
            "title": "고급 RAG 파이프라인 API 엔드포인트 및 시스템 통합",
            "description": "FastAPI 기반의 고급 RAG API 엔드포인트를 구현하고, 기존 시스템과의 통합 및 설정 기반 기능 활성화/비활성화 옵션을 제공한다.",
            "dependencies": [
              "20.3"
            ],
            "details": "API 요청에 따라 LangGraph 기반 파이프라인을 실행하고, 결과(답변, 소스, reasoning trace 등)를 표준화된 응답으로 반환한다. 기존 RAG 시스템과의 통합 및 설정 관리도 포함한다.\n<info added on 2025-07-21T21:44:14.446Z>\n• FastAPI 라우트 정의: `routes/rag.py`  \n  ```python\n  @router.post(\"/api/rag/advanced\", response_model=RAGResponse)\n  async def advanced_rag(req: RAGRequest, rag_service: RagService = Depends(get_rag_service)):\n      result = await rag_service.run(\n          query=req.query,\n          enable_rerank=req.options.rerank,\n          enable_context_expand=req.options.context_expand,\n          enable_multi_query=req.options.multi_query,\n          return_trace=req.options.trace,\n      )\n      return result\n  ```\n\n• 공통 RAG 서비스 레이어: `services/rag_service.py`  \n  - FastAPI/Streamlit 양쪽에서 `RagService.run()` 비동기 호출 가능하도록 설계  \n  - LangGraph `StateGraph` 인스턴스를 내부에서 캐싱, 옵션별 노드 추가/제거로 동적 그래프 구성  \n  - trace 모드 시 `graph.compile(debug=True)`로 reasoning path 포함 응답\n\n• Pydantic 스키마:  \n  ```python\n  class RAGOptions(BaseModel):\n      rerank: bool = True\n      context_expand: bool = True\n      multi_query: bool = False\n      trace: bool = False\n\n  class RAGRequest(BaseModel):\n      query: str\n      options: RAGOptions = RAGOptions()\n\n  class RAGResponse(BaseModel):\n      answer: str\n      sources: list[str]\n      trace: dict | None = None\n  ```\n\n• Streamlit 통합 예시:  \n  ```python\n  rag_service = RagService()\n  query = st.text_input(\"질문 입력\")\n  if st.button(\"검색\"):\n      res = asyncio.run(\n          rag_service.run(query, enable_rerank=st.checkbox(\"Rerank\"), ...)\n      )\n      st.write(res.answer)\n      if res.trace:\n          st.json(res.trace)\n  ```\n\n• 설정 관리  \n  - `config/rag.yaml`에 기본 옵션 저장, 요청 본문이 우선  \n  - DI 컨테이너에 `RagService` 싱글톤 바인딩, 테스트 시 `MockRagService` 대체 가능\n\n• 테스트  \n  - `tests/test_rag_route.py`에서 `TestClient`로 POST `/api/rag/advanced` → 200 검증  \n  - 피쳐 플래그 조합별 파라미터라이즈 테스트로 그래프 노드 존재 여부 확인\n</info added on 2025-07-21T21:44:14.446Z>",
            "status": "pending",
            "testStrategy": "API 엔드포인트에 대한 통합 테스트 및 기존 시스템과의 연동 테스트를 수행한다."
          },
          {
            "id": 5,
            "title": "성능 평가, 모니터링 및 최적화",
            "description": "고급 RAG 파이프라인의 성능(정확도, 검색 정밀도, 답변 관련성, 컨텍스트 품질 등)을 평가하고, 멀티쿼리/재순위화 결과 캐싱 및 비동기 병렬 검색 등 최적화 방안을 적용한다.",
            "dependencies": [
              "20.4"
            ],
            "details": "평가 지표 산출, 캐싱 및 비동기 처리 적용, 모니터링 로직 구현 등으로 파이프라인의 효율성과 품질을 지속적으로 개선한다.",
            "status": "pending",
            "testStrategy": "성능 평가 스크립트로 주요 지표를 측정하고, 캐싱/비동기 처리의 효과를 비교 테스트한다."
          }
        ]
      },
      {
        "id": 21,
        "title": "최신 정보 가중치 탐색 기능 구현",
        "description": "RAG 시스템에서 최신 정보에 가중치를 부여하는 탐색 기능을 구현하여 시간적 관련성이 높은 문서를 우선적으로 검색 결과에 반영한다.",
        "details": "## 구현 세부사항\n\n1. **시간 가중치 모델 설계 (`rag/models/time_weight.py`)**\n   - 문서 생성/수정 시간 기반 가중치 계산 함수 구현\n   ```python\n   from datetime import datetime\n   import math\n   \n   def calculate_time_weight(doc_timestamp, base_weight=1.0, decay_factor=0.1, max_boost=2.0):\n       \"\"\"\n       문서의 시간적 신선도에 따른 가중치 계산\n       \n       Args:\n           doc_timestamp (datetime): 문서 생성/수정 시간\n           base_weight (float): 기본 가중치\n           decay_factor (float): 시간 경과에 따른 감소 계수\n           max_boost (float): 최대 가중치 증폭값\n           \n       Returns:\n           float: 계산된 시간 가중치\n       \"\"\"\n       now = datetime.now()\n       days_diff = (now - doc_timestamp).days\n       \n       # 지수 감소 함수 적용 (최신 문서일수록 높은 가중치)\n       time_weight = base_weight * math.exp(-decay_factor * days_diff)\n       \n       # 최대 가중치 제한\n       return min(time_weight, max_boost)\n   ```\n\n2. **Elasticsearch 시간 가중치 검색 구현 (`rag/search/time_weighted_search.py`)**\n   - BM25 + 벡터 검색에 시간 가중치를 결합한 함수 구현\n   ```python\n   from rag.search.elasticsearch_client import get_elasticsearch_client\n   from rag.models.time_weight import calculate_time_weight\n   \n   def time_weighted_search(query, index_name, vector_field, text_field, timestamp_field, \n                           top_k=10, vector=None, time_weight_factor=0.3):\n       \"\"\"\n       시간 가중치를 적용한 하이브리드 검색 수행\n       \n       Args:\n           query (str): 검색 쿼리\n           index_name (str): 검색할 인덱스 이름\n           vector_field (str): 벡터 필드 이름\n           text_field (str): 텍스트 필드 이름\n           timestamp_field (str): 타임스탬프 필드 이름\n           top_k (int): 반환할 결과 수\n           vector (list): 쿼리 벡터\n           time_weight_factor (float): 시간 가중치 영향력 계수\n           \n       Returns:\n           list: 검색 결과 목록\n       \"\"\"\n       client = get_elasticsearch_client()\n       \n       # 기본 하이브리드 검색 수행\n       search_results = client.search(\n           index=index_name,\n           body={\n               \"query\": {\n                   \"bool\": {\n                       \"should\": [\n                           {\"match\": {text_field: query}},  # BM25\n                           {\"knn\": {vector_field: {\"vector\": vector, \"k\": top_k}}}  # 벡터 검색\n                       ]\n                   }\n               },\n               \"_source\": [\"*\", timestamp_field],\n               \"size\": top_k * 2  # 가중치 재조정을 위해 더 많은 결과 가져오기\n           }\n       )\n       \n       # 시간 가중치 적용하여 결과 재정렬\n       weighted_results = []\n       for hit in search_results[\"hits\"][\"hits\"]:\n           base_score = hit[\"_score\"]\n           timestamp = datetime.fromisoformat(hit[\"_source\"][timestamp_field])\n           time_weight = calculate_time_weight(timestamp)\n           \n           # 최종 점수 = 기본 점수 + (시간 가중치 * 시간 가중치 영향력 계수)\n           final_score = base_score + (time_weight * time_weight_factor * base_score)\n           \n           weighted_results.append({\n               \"document\": hit[\"_source\"],\n               \"original_score\": base_score,\n               \"time_weight\": time_weight,\n               \"final_score\": final_score\n           })\n       \n       # 최종 점수로 정렬하고 상위 k개 반환\n       weighted_results.sort(key=lambda x: x[\"final_score\"], reverse=True)\n       return weighted_results[:top_k]\n   ```\n\n3. **시간 가중치 설정 관리 (`rag/config/time_weight_config.py`)**\n   - 시간 가중치 파라미터 설정 및 관리 클래스 구현\n   ```python\n   from pydantic import BaseModel, Field\n   \n   class TimeWeightConfig(BaseModel):\n       \"\"\"시간 가중치 설정 모델\"\"\"\n       base_weight: float = Field(default=1.0, ge=0.1, le=10.0)\n       decay_factor: float = Field(default=0.1, ge=0.01, le=1.0)\n       max_boost: float = Field(default=2.0, ge=1.0, le=5.0)\n       time_weight_factor: float = Field(default=0.3, ge=0.0, le=1.0)\n       \n       def to_dict(self):\n           return self.dict()\n       \n       @classmethod\n       def from_dict(cls, data):\n           return cls(**data)\n   ```\n\n4. **FastAPI 엔드포인트 확장 (`rag/api/search_routes.py`)**\n   - 시간 가중치 검색 API 엔드포인트 추가\n   ```python\n   from fastapi import APIRouter, Depends, Query\n   from rag.search.time_weighted_search import time_weighted_search\n   from rag.config.time_weight_config import TimeWeightConfig\n   from rag.models.embedding import get_embedding\n   \n   router = APIRouter()\n   \n   @router.post(\"/search/time-weighted\")\n   async def time_weighted_search_endpoint(\n       query: str,\n       index_name: str = Query(\"documents\"),\n       top_k: int = Query(10, ge=1, le=50),\n       time_weight_config: TimeWeightConfig = None\n   ):\n       \"\"\"시간 가중치를 적용한 검색 수행\"\"\"\n       # 기본 설정 사용\n       if time_weight_config is None:\n           time_weight_config = TimeWeightConfig()\n       \n       # 쿼리 임베딩 생성\n       query_vector = get_embedding(query)\n       \n       # 시간 가중치 검색 수행\n       results = time_weighted_search(\n           query=query,\n           index_name=index_name,\n           vector_field=\"embedding\",\n           text_field=\"content\",\n           timestamp_field=\"created_at\",\n           top_k=top_k,\n           vector=query_vector,\n           time_weight_factor=time_weight_config.time_weight_factor\n       )\n       \n       return {\n           \"query\": query,\n           \"results\": results,\n           \"time_weight_config\": time_weight_config.to_dict()\n       }\n   ```\n\n5. **LangGraph 파이프라인 통합 (`rag/pipelines/time_weighted_rag.py`)**\n   - 기존 LangGraph 파이프라인에 시간 가중치 검색 노드 추가\n   ```python\n   from langgraph.graph import StateGraph\n   from rag.search.time_weighted_search import time_weighted_search\n   from rag.models.embedding import get_embedding\n   \n   def retrieve_with_time_weight(state):\n       \"\"\"시간 가중치를 적용한 문서 검색 노드\"\"\"\n       query = state[\"query\"]\n       query_vector = get_embedding(query)\n       \n       # 시간 가중치 검색 수행\n       results = time_weighted_search(\n           query=query,\n           index_name=\"documents\",\n           vector_field=\"embedding\",\n           text_field=\"content\",\n           timestamp_field=\"created_at\",\n           top_k=5,\n           vector=query_vector\n       )\n       \n       # 결과에서 문서 추출\n       documents = [item[\"document\"] for item in results]\n       \n       # 상태 업데이트\n       return {\n           **state,\n           \"retrieved_documents\": documents,\n           \"search_metadata\": {\n               \"time_weighted_scores\": [\n                   {\"id\": item[\"document\"][\"id\"], \n                    \"original_score\": item[\"original_score\"],\n                    \"time_weight\": item[\"time_weight\"],\n                    \"final_score\": item[\"final_score\"]}\n                   for item in results\n               ]\n           }\n       }\n   \n   # LangGraph 파이프라인에 노드 추가\n   def build_time_weighted_rag_graph():\n       workflow = StateGraph()\n       \n       # 노드 추가\n       workflow.add_node(\"retrieve_with_time_weight\", retrieve_with_time_weight)\n       # 기존 노드들 추가...\n       \n       # 엣지 연결\n       workflow.add_edge(\"start\", \"retrieve_with_time_weight\")\n       # 나머지 엣지 연결...\n       \n       return workflow.compile()\n   ```\n\n6. **시간 가중치 파라미터 최적화 도구 (`rag/tools/time_weight_optimizer.py`)**\n   - 다양한 쿼리에 대한 시간 가중치 파라미터 최적화 기능\n   ```python\n   import numpy as np\n   from sklearn.model_selection import ParameterGrid\n   from rag.search.time_weighted_search import time_weighted_search\n   from rag.models.embedding import get_embedding\n   \n   def optimize_time_weights(test_queries, relevant_docs, index_name):\n       \"\"\"\n       시간 가중치 파라미터 최적화\n       \n       Args:\n           test_queries (list): 테스트 쿼리 목록\n           relevant_docs (dict): 쿼리별 관련 문서 ID 목록\n           index_name (str): 검색할 인덱스 이름\n           \n       Returns:\n           dict: 최적화된 시간 가중치 파라미터\n       \"\"\"\n       # 파라미터 그리드 정의\n       param_grid = {\n           'base_weight': [0.5, 1.0, 1.5],\n           'decay_factor': [0.05, 0.1, 0.2],\n           'max_boost': [1.5, 2.0, 2.5],\n           'time_weight_factor': [0.1, 0.3, 0.5]\n       }\n       \n       grid = ParameterGrid(param_grid)\n       best_score = 0\n       best_params = None\n       \n       # 각 파라미터 조합에 대해 평가\n       for params in grid:\n           total_score = 0\n           \n           for query in test_queries:\n               query_vector = get_embedding(query)\n               \n               results = time_weighted_search(\n                   query=query,\n                   index_name=index_name,\n                   vector_field=\"embedding\",\n                   text_field=\"content\",\n                   timestamp_field=\"created_at\",\n                   top_k=10,\n                   vector=query_vector,\n                   time_weight_factor=params['time_weight_factor']\n               )\n               \n               # 검색 결과에서 문서 ID 추출\n               result_ids = [item[\"document\"][\"id\"] for item in results]\n               \n               # 관련 문서가 상위에 랭크되었는지 평가 (NDCG 등 메트릭 사용)\n               # 여기서는 간단한 예시로 관련 문서의 순위 기반 점수 계산\n               query_score = 0\n               for i, doc_id in enumerate(result_ids):\n                   if doc_id in relevant_docs.get(query, []):\n                       # 순위가 높을수록 더 높은 점수 부여\n                       query_score += 1.0 / (i + 1)\n               \n               total_score += query_score\n           \n           # 더 좋은 파라미터 조합 발견 시 업데이트\n           if total_score > best_score:\n               best_score = total_score\n               best_params = params\n       \n       return best_params\n   ```\n\n7. **시간 가중치 시각화 도구 (`rag/tools/time_weight_visualizer.py`)**\n   - 시간 가중치 영향 시각화 및 분석 도구\n   ```python\n   import matplotlib.pyplot as plt\n   import pandas as pd\n   from datetime import datetime, timedelta\n   from rag.models.time_weight import calculate_time_weight\n   \n   def visualize_time_weights(base_weight=1.0, decay_factor=0.1, max_boost=2.0):\n       \"\"\"시간 경과에 따른 가중치 변화 시각화\"\"\"\n       now = datetime.now()\n       days = list(range(0, 366, 30))  # 1년 동안 30일 간격\n       \n       weights = []\n       for day in days:\n           doc_date = now - timedelta(days=day)\n           weight = calculate_time_weight(\n               doc_date, base_weight, decay_factor, max_boost\n           )\n           weights.append(weight)\n       \n       plt.figure(figsize=(10, 6))\n       plt.plot(days, weights, marker='o')\n       plt.title('시간 경과에 따른 문서 가중치 변화')\n       plt.xlabel('문서 생성 후 경과일')\n       plt.ylabel('가중치')\n       plt.grid(True)\n       plt.savefig('time_weight_curve.png')\n       \n       return {\n           'days': days,\n           'weights': weights,\n           'params': {\n               'base_weight': base_weight,\n               'decay_factor': decay_factor,\n               'max_boost': max_boost\n           }\n       }\n   \n   def compare_search_results(query, with_time_weight=True, top_k=5):\n       \"\"\"시간 가중치 적용 전후 검색 결과 비교\"\"\"\n       # 구현 생략\n       pass\n   ```\n\n## 통합 및 배포 고려사항\n\n1. **데이터베이스 스키마 업데이트**\n   - 문서 메타데이터에 타임스탬프 필드 추가 및 인덱싱\n   - 기존 문서의 타임스탬프 정보 마이그레이션\n\n2. **성능 최적화**\n   - 대량 문서 처리 시 시간 가중치 계산 최적화\n   - 캐싱 전략 적용 (자주 사용되는 시간 가중치 계산 결과 캐싱)\n\n3. **사용자 인터페이스 확장**\n   - 시간 가중치 파라미터 조정 UI 추가\n   - 검색 결과에 시간 정보 및 가중치 영향 표시\n\n4. **모니터링 및 로깅**\n   - 시간 가중치 적용 전후 검색 성능 비교 메트릭 수집\n   - 사용자 피드백 기반 파라미터 자동 조정 메커니즘",
        "testStrategy": "## 테스트 전략\n\n1. **단위 테스트 (pytest)**\n   - 시간 가중치 계산 함수 테스트\n   ```python\n   def test_time_weight_calculation():\n       \"\"\"시간 가중치 계산 함수 테스트\"\"\"\n       now = datetime.now()\n       yesterday = now - timedelta(days=1)\n       last_month = now - timedelta(days=30)\n       last_year = now - timedelta(days=365)\n       \n       # 최신 문서는 높은 가중치를 가져야 함\n       assert calculate_time_weight(now) > calculate_time_weight(yesterday)\n       assert calculate_time_weight(yesterday) > calculate_time_weight(last_month)\n       assert calculate_time_weight(last_month) > calculate_time_weight(last_year)\n       \n       # 최대 가중치 제한 테스트\n       assert calculate_time_weight(now, max_boost=1.5) <= 1.5\n   \n   def test_time_weighted_search():\n       \"\"\"시간 가중치 검색 함수 테스트\"\"\"\n       # 모의 Elasticsearch 클라이언트 설정\n       mock_client = MagicMock()\n       mock_client.search.return_value = {\n           \"hits\": {\n               \"hits\": [\n                   {\n                       \"_score\": 0.8,\n                       \"_source\": {\n                           \"id\": \"doc1\",\n                           \"content\": \"최신 세금 정책\",\n                           \"created_at\": datetime.now().isoformat()\n                       }\n                   },\n                   {\n                       \"_score\": 0.9,\n                       \"_source\": {\n                           \"id\": \"doc2\",\n                           \"content\": \"오래된 세금 정책\",\n                           \"created_at\": (datetime.now() - timedelta(days=365)).isoformat()\n                       }\n                   }\n               ]\n           }\n       }\n       \n       with patch('rag.search.time_weighted_search.get_elasticsearch_client', return_value=mock_client):\n           results = time_weighted_search(\n               query=\"세금 정책\",\n               index_name=\"test_index\",\n               vector_field=\"embedding\",\n               text_field=\"content\",\n               timestamp_field=\"created_at\",\n               vector=[0.1] * 384  # 가상 벡터\n           )\n           \n           # 시간 가중치 적용 후 최신 문서가 더 높은 점수를 가져야 함\n           assert results[0][\"document\"][\"id\"] == \"doc1\"\n           assert results[0][\"final_score\"] > results[1][\"final_score\"]\n   ```\n\n2. **통합 테스트**\n   - LangGraph 파이프라인 통합 테스트\n   ```python\n   def test_time_weighted_rag_pipeline():\n       \"\"\"시간 가중치 RAG 파이프라인 통합 테스트\"\"\"\n       # 테스트용 상태 초기화\n       initial_state = {\n           \"query\": \"최근 세금 정책 변경사항은 무엇인가요?\"\n       }\n       \n       # 파이프라인 실행\n       graph = build_time_weighted_rag_graph()\n       final_state = graph.invoke(initial_state)\n       \n       # 결과 검증\n       assert \"retrieved_documents\" in final_state\n       assert \"search_metadata\" in final_state\n       assert \"time_weighted_scores\" in final_state[\"search_metadata\"]\n       \n       # 최신 문서가 상위에 랭크되었는지 확인\n       docs = final_state[\"retrieved_documents\"]\n       if len(docs) >= 2:\n           doc1_date = datetime.fromisoformat(docs[0][\"created_at\"])\n           doc2_date = datetime.fromisoformat(docs[1][\"created_at\"])\n           assert doc1_date >= doc2_date\n   ```\n\n3. **API 엔드포인트 테스트**\n   - FastAPI 테스트 클라이언트를 사용한 엔드포인트 테스트\n   ```python\n   def test_time_weighted_search_endpoint():\n       \"\"\"시간 가중치 검색 API 엔드포인트 테스트\"\"\"\n       from fastapi.testclient import TestClient\n       from rag.api.main import app\n       \n       client = TestClient(app)\n       \n       response = client.post(\n           \"/search/time-weighted\",\n           json={\n               \"query\": \"최근 세금 정책\",\n               \"time_weight_config\": {\n                   \"base_weight\": 1.0,\n                   \"decay_factor\": 0.1,\n                   \"max_boost\": 2.0,\n                   \"time_weight_factor\": 0.3\n               }\n           }\n       )\n       \n       assert response.status_code == 200\n       data = response.json()\n       assert \"results\" in data\n       assert \"time_weight_config\" in data\n   ```\n\n4. **파라미터 최적화 테스트**\n   - 시간 가중치 파라미터 최적화 도구 테스트\n   ```python\n   def test_time_weight_optimizer():\n       \"\"\"시간 가중치 파라미터 최적화 도구 테스트\"\"\"\n       # 테스트 쿼리 및 관련 문서 정의\n       test_queries = [\"세금 공제 방법\", \"최근 세법 개정\"]\n       relevant_docs = {\n           \"세금 공제 방법\": [\"doc1\", \"doc3\"],\n           \"최근 세법 개정\": [\"doc2\", \"doc5\"]\n       }\n       \n       # 모의 검색 결과 설정\n       with patch('rag.tools.time_weight_optimizer.time_weighted_search') as mock_search:\n           mock_search.side_effect = lambda **kwargs: [\n               {\"document\": {\"id\": f\"doc{i}\"}} for i in range(1, 6)\n           ]\n           \n           with patch('rag.tools.time_weight_optimizer.get_embedding', return_value=[0.1] * 384):\n               best_params = optimize_time_weights(\n                   test_queries=test_queries,\n                   relevant_docs=relevant_docs,\n                   index_name=\"test_index\"\n               )\n               \n               assert isinstance(best_params, dict)\n               assert \"base_weight\" in best_params\n               assert \"decay_factor\" in best_params\n               assert \"max_boost\" in best_params\n               assert \"time_weight_factor\" in best_params\n   ```\n\n5. **성능 테스트**\n   - 대량 문서에 대한 시간 가중치 검색 성능 테스트\n   ```python\n   def test_time_weighted_search_performance():\n       \"\"\"시간 가중치 검색 성능 테스트\"\"\"\n       import time\n       \n       # 대량의 테스트 문서 생성\n       num_docs = 10000\n       mock_hits = []\n       now = datetime.now()\n       \n       for i in range(num_docs):\n           # 무작위 날짜 생성 (최대 2년 전)\n           days_ago = random.randint(0, 730)\n           doc_date = now - timedelta(days=days_ago)\n           \n           mock_hits.append({\n               \"_score\": random.uniform(0.5, 1.0),\n               \"_source\": {\n                   \"id\": f\"doc{i}\",\n                   \"content\": f\"테스트 문서 {i}\",\n                   \"created_at\": doc_date.isoformat()\n               }\n           })\n       \n       mock_response = {\"hits\": {\"hits\": mock_hits}}\n       \n       with patch('rag.search.time_weighted_search.get_elasticsearch_client') as mock_client:\n           mock_instance = MagicMock()\n           mock_instance.search.return_value = mock_response\n           mock_client.return_value = mock_instance\n           \n           start_time = time.time()\n           results = time_weighted_search(\n               query=\"테스트 쿼리\",\n               index_name=\"test_index\",\n               vector_field=\"embedding\",\n               text_field=\"content\",\n               timestamp_field=\"created_at\",\n               vector=[0.1] * 384\n           )\n           end_time = time.time()\n           \n           # 처리 시간이 합리적인지 확인 (예: 1초 미만)\n           assert end_time - start_time < 1.0\n           assert len(results) == 10  # top_k 기본값\n   ```\n\n6. **시각화 도구 테스트**\n   - 시간 가중치 시각화 도구 테스트\n   ```python\n   def test_time_weight_visualizer():\n       \"\"\"시간 가중치 시각화 도구 테스트\"\"\"\n       with patch('rag.tools.time_weight_visualizer.plt') as mock_plt:\n           result = visualize_time_weights(\n               base_weight=1.0,\n               decay_factor=0.1,\n               max_boost=2.0\n           )\n           \n           # plt.figure가 호출되었는지 확인\n           mock_plt.figure.assert_called_once()\n           # plt.savefig가 호출되었는지 확인\n           mock_plt.savefig.assert_called_once()\n           \n           assert \"days\" in result\n           assert \"weights\" in result\n           assert \"params\" in result\n           assert len(result[\"days\"]) == len(result[\"weights\"])\n   ```\n\n7. **사용자 시나리오 테스트**\n   - 실제 사용자 시나리오를 시뮬레이션하는 E2E 테스트\n   ```python\n   def test_user_scenario():\n       \"\"\"사용자 시나리오 E2E 테스트\"\"\"\n       # 1. 최신 세금 정책 검색\n       # 2. 시간 가중치 파라미터 조정\n       # 3. 결과 비교 및 검증\n       # (구현 생략)\n       pass\n   ```",
        "status": "pending",
        "dependencies": [],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "시간 가중치 모델 설계 및 구현",
            "description": "문서의 생성/수정 시간에 따라 가중치를 계산하는 함수와 로직을 설계하고 구현한다.",
            "dependencies": [],
            "details": "문서의 타임스탬프를 입력받아, 최신 문서일수록 높은 가중치를 반환하는 지수 감소 기반 함수(calculate_time_weight)를 개발한다. 파라미터로 base_weight, decay_factor, max_boost를 지원한다.",
            "status": "pending",
            "testStrategy": "단위 테스트를 통해 다양한 날짜 입력에 대해 가중치가 올바르게 계산되는지 검증한다."
          },
          {
            "id": 2,
            "title": "Elasticsearch 시간 가중치 하이브리드 검색 구현",
            "description": "BM25와 벡터 검색 결과에 시간 가중치를 결합하여 최종 점수를 산출하고, 이를 기반으로 검색 결과를 재정렬하는 기능을 구현한다.",
            "dependencies": [
              "21.1"
            ],
            "details": "Elasticsearch에서 BM25 및 벡터 검색 결과를 받아온 뒤, 각 문서의 타임스탬프에 대해 시간 가중치를 계산하고, 기본 점수와 조합하여 최종 점수를 산출한다. 상위 k개의 결과를 반환한다.\n<info added on 2025-07-21T21:44:44.133Z>\n• Elasticsearch function_score 쿼리를 활용하여 BM25·벡터·시간 가중치를 3중 앙상블로 통합  \n  - created_at 필드에 exponential decay 함수(exp) 적용  \n  - score_mode=\"sum\", boost_mode=\"multiply\" 로 BM25/벡터 기본 점수에 시간 가중치를 곱해 최종 점수 산출\n\n• 인덱스 매핑 예시  \n  ```\n  PUT tax_docs\n  {\n    \"mappings\": {\n      \"properties\": {\n        \"content\": { \"type\": \"text\" },\n        \"embedding\": { \"type\": \"dense_vector\", \"dims\": 1536, \"index\": true, \"similarity\": \"dot_product\" },\n        \"created_at\": { \"type\": \"date\", \"format\": \"strict_date_optional_time||epoch_millis\" }\n      }\n    }\n  }\n  ```\n\n• 검색 요청 예시 (Python elasticsearch-py)  \n  ```python\n  def hybrid_time_search(client, index, query, query_vector, k=10,\n                         scale=\"30d\", decay=0.5):\n      es_query = {\n          \"size\": k,\n          \"knn\": {\n              \"field\": \"embedding\",\n              \"query_vector\": query_vector,\n              \"k\": k * 5,\n              \"num_candidates\": k * 20\n          },\n          \"query\": {\n              \"function_score\": {\n                  \"query\": {\n                      \"match\": { \"content\": { \"query\": query, \"operator\": \"and\" } }\n                  },\n                  \"functions\": [\n                      {\n                          \"exp\": {\n                              \"created_at\": {\n                                  \"origin\": \"now\",\n                                  \"scale\": scale,\n                                  \"decay\": decay\n                              }\n                          }\n                      }\n                  ],\n                  \"score_mode\": \"sum\",\n                  \"boost_mode\": \"multiply\"\n              }\n          }\n      }\n      return client.search(index=index, body=es_query)\n  ```\n\n• 설정값  \n  - TIME_DECAY_SCALE(\"30d\"), TIME_DECAY_FACTOR(0.5)을 settings.py 에서 관리  \n  - scale, decay 값은 A/B 테스트로 최적화 가능\n\n• 테스트 전략  \n  1. 동일 BM25·벡터 점수를 가진 신규/구문서 준비 → 최근 문서가 상위에 노출되는지 확인  \n  2. created_at 누락 문서는 decay 함수 미적용(기본 1.0) 여부 검증  \n  3. k=10 호출 시 반환 문서 수, 정렬 순서가 기대와 일치하는지 확인\n\n• 예외 처리  \n  - created_at 파싱 실패 시 로그 경고 후 time weight=1.0 적용  \n  - Elasticsearch 8.11 이상에서만 dense_vector + knn + function_score 동시 사용 가능 버전 체크\n</info added on 2025-07-21T21:44:44.133Z>",
            "status": "pending",
            "testStrategy": "검색 쿼리별로 시간 가중치 적용 전후의 결과 순위 변화를 검증한다."
          },
          {
            "id": 3,
            "title": "시간 가중치 파라미터 설정 및 관리 기능 개발",
            "description": "시간 가중치 계산에 사용되는 파라미터(base_weight, decay_factor, max_boost, time_weight_factor)를 설정하고 관리할 수 있는 클래스를 구현한다.",
            "dependencies": [
              "21.1"
            ],
            "details": "Pydantic 기반 설정 모델을 작성하여 파라미터의 유효성 검증, 직렬화/역직렬화, 기본값 제공 기능을 포함한다.",
            "status": "pending",
            "testStrategy": "파라미터 값 변경 및 직렬화/역직렬화 동작을 단위 테스트로 검증한다."
          },
          {
            "id": 4,
            "title": "시간 가중치 검색 API 엔드포인트 및 파이프라인 통합",
            "description": "FastAPI 엔드포인트를 추가하여 시간 가중치 검색 기능을 외부에서 사용할 수 있도록 하고, LangGraph 파이프라인에 해당 노드를 통합한다.",
            "dependencies": [
              "21.2",
              "21.3"
            ],
            "details": "API에서 쿼리, 인덱스명, top_k, 파라미터를 입력받아 시간 가중치 검색을 수행하고 결과를 반환한다. LangGraph 파이프라인에 시간 가중치 검색 노드를 추가하여 end-to-end 흐름에 통합한다.",
            "status": "pending",
            "testStrategy": "API 호출 시 시간 가중치가 적용된 결과가 반환되는지, 파이프라인에서 정상적으로 동작하는지 통합 테스트를 수행한다."
          },
          {
            "id": 5,
            "title": "시간 가중치 파라미터 최적화 및 시각화 도구 개발",
            "description": "다양한 쿼리와 관련 문서 집합을 기반으로 시간 가중치 파라미터를 자동으로 최적화하고, 시간 가중치 영향도를 시각화하는 도구를 개발한다.",
            "dependencies": [
              "21.1",
              "21.2",
              "21.3"
            ],
            "details": "파라미터 그리드 탐색을 통해 최적의 시간 가중치 조합을 찾고, 시간 경과에 따른 가중치 변화를 그래프로 시각화하는 기능을 구현한다.\n<info added on 2025-07-21T21:45:14.559Z>\n• Streamlit 대시보드(`tools/streamlit_time_weight.py`) 추가  \n  - sidebar 슬라이더: `decay_factor`, `base_weight`, `max_boost`, `cutoff_days` 등 실시간 조정  \n  - 변경 이벤트마다 `/search/time_weight` API 호출 → 최신 쿼리 결과를 재계산하여 화면 갱신  \n  - st.tabs(\"문서 분포\",\"가중치 곡선\",\"검색 결과\") 구성  \n    • 문서 분포: plotly.express.histogram 으로 시간축 히스토그램 및 커널 밀도 표시  \n    • 가중치 곡선: matplotlib 또는 plotly.graph_objects.line 로 현재 파라미터에 따른 weight(t) 곡선 렌더링  \n    • 검색 결과: top-k 리스트, 점수 heatmap, nDCG/MAP 그래프를 동적으로 표시  \n\n• A/B 테스트 모듈  \n  - sidebar 에 “Variation A/B 저장” 버튼 → 파라미터 스냅샷을 redis hash(`time_weight:ab:{user}`) 에 저장  \n  - “A vs B 비교” 선택 시 두 변형에 대해 동일 쿼리 세트 실행, 성능 지표(nDCG@10, Recall@20, 평균 시간 가중 점수) 계산  \n  - plotly bar + table 로 지표를 나란히 시각화, 통계적 유의성(bootstrap p-value) 표시  \n\n• 패키지 의존성: `poetry add streamlit==1.33 plotly==5.20 matplotlib==3.9 pandas==2.2`  \n\n• E2E 테스트(`tests/test_streamlit_ab.py`)  \n  1) FastAPI 검색 서버를 test client 로 기동 후 selenium 으로 Streamlit 앱 접속  \n  2) 슬라이더 조정 → 곡선·결과 영역이 websocket 메시지 수신 뒤 1 s 내 업데이트 되는지 assert  \n  3) A/B 저장 후 비교 클릭 → 두 변형의 nDCG 차이가 UI 에 표시되는지 확인 (스크린샷 픽셀 hash 비교)\n</info added on 2025-07-21T21:45:14.559Z>",
            "status": "pending",
            "testStrategy": "최적화 도구가 실제로 검색 성능(NDCG 등)을 개선하는지, 시각화 결과가 올바르게 출력되는지 검증한다."
          }
        ]
      }
    ],
    "metadata": {
      "created": "2025-07-15T09:33:41.655Z",
      "updated": "2025-07-21T23:27:03.811Z",
      "description": "Tasks for master context"
    }
  }
}