{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ”„ ChromaDB ë™ê¸°í™” ì‹œìŠ¤í…œ\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ `raw_data` í´ë”ì™€ ChromaDBë¥¼ ìë™ìœ¼ë¡œ ë™ê¸°í™”í•˜ëŠ” ì „ìš© ì‹œìŠ¤í…œì…ë‹ˆë‹¤.\n",
    "\n",
    "## ğŸ“‹ ì£¼ìš” ê¸°ëŠ¥\n",
    "1. **Raw Data í´ë” ìŠ¤ìº”**: .txt, .pdf íŒŒì¼ ìë™ ê°ì§€\n",
    "2. **ìŠ¤ë§ˆíŠ¸ ë™ê¸°í™”**: ìƒˆ íŒŒì¼ë§Œ ì„ ë³„í•˜ì—¬ DB ì¶”ê°€\n",
    "3. **ìƒíƒœ ëª¨ë‹ˆí„°ë§**: ìƒì„¸í•œ ë™ê¸°í™” ë¦¬í¬íŠ¸\n",
    "4. **ê³ ì•„ íŒŒì¼ ê°ì§€**: DBì—ë§Œ ìˆëŠ” íŒŒì¼ ì‹ë³„\n",
    "5. **ê²€ìƒ‰ í…ŒìŠ¤íŠ¸**: ë™ê¸°í™” í›„ ê²€ìƒ‰ ê¸°ëŠ¥ í™•ì¸\n",
    "\n",
    "## âš ï¸ ì‚¬ìš© ì „ ì¤€ë¹„ì‚¬í•­\n",
    "- `.env` íŒŒì¼ì— `OPENAI_API_KEY` ì„¤ì • í•„ìš”\n",
    "- `raw_data` í´ë”ì— ë™ê¸°í™”í•  ë¬¸ì„œ íŒŒì¼ ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° ì„í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜ (ì²˜ìŒ ì‹¤í–‰ ì‹œì—ë§Œ)\n",
    "# !pip install chromadb langchain-openai langchain-community langchain-chroma python-dotenv pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„±ê³µì ìœ¼ë¡œ ì„í¬íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "ğŸ”‘ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# Langchain imports\n",
    "from langchain_community.document_loaders import TextLoader, PyPDFLoader\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "print(\"âœ… ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„±ê³µì ìœ¼ë¡œ ì„í¬íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# API í‚¤ í™•ì¸\n",
    "if os.getenv('OPENAI_API_KEY'):\n",
    "    print(\"ğŸ”‘ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\")\n",
    "else:\n",
    "    print(\"âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ› ï¸ ChromaDB ê´€ë¦¬ í´ë˜ìŠ¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ChromaDBManager í´ë˜ìŠ¤ê°€ ì •ì˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "class ChromaDBManager:\n",
    "    \"\"\"ChromaDB ê´€ë¦¬ë¥¼ ìœ„í•œ í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    def __init__(self, db_path: str = \"./chroma_db\", embedding_model: str = \"text-embedding-3-large\"):\n",
    "        self.db_path = db_path\n",
    "        self.embedding_model = embedding_model\n",
    "        self.embeddings = OpenAIEmbeddings(model=embedding_model)\n",
    "        self.db = None\n",
    "        \n",
    "        print(f\"ğŸ“ DB ê²½ë¡œ: {self.db_path}\")\n",
    "        print(f\"ğŸ”¤ ì„ë² ë”© ëª¨ë¸: {self.embedding_model}\")\n",
    "    \n",
    "    def check_db_exists(self) -> bool:\n",
    "        \"\"\"DB ì¡´ì¬ ì—¬ë¶€ í™•ì¸\"\"\"\n",
    "        return os.path.exists(self.db_path) and os.path.isdir(self.db_path) and len(os.listdir(self.db_path)) > 0\n",
    "    \n",
    "    def create_new_db(self, documents: list, force_recreate: bool = False) -> bool:\n",
    "        \"\"\"ìƒˆë¡œìš´ ChromaDB ìƒì„±\"\"\"\n",
    "        try:\n",
    "            if force_recreate and self.check_db_exists():\n",
    "                print(\"ğŸ—‘ï¸ ê¸°ì¡´ DBë¥¼ ì‚­ì œí•˜ê³  ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤...\")\n",
    "                self.delete_db()\n",
    "            \n",
    "            print(f\"ğŸ”¨ ìƒˆë¡œìš´ ChromaDBë¥¼ ìƒì„±í•˜ê³  {len(documents)}ê°œ ë¬¸ì„œë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤...\")\n",
    "            \n",
    "            self.db = Chroma.from_documents(\n",
    "                documents=documents,\n",
    "                embedding=self.embeddings,\n",
    "                collection_name=\"rag_collection\",\n",
    "                persist_directory=self.db_path\n",
    "            )\n",
    "            \n",
    "            print(f\"âœ… ChromaDBê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤! ({len(documents)}ê°œ ë¬¸ì„œ)\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ DB ìƒì„± ì‹¤íŒ¨: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def load_existing_db(self) -> bool:\n",
    "        \"\"\"ê¸°ì¡´ ChromaDB ë¡œë“œ\"\"\"\n",
    "        try:\n",
    "            if not self.check_db_exists():\n",
    "                print(\"âŒ ë¡œë“œí•  DBê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "                return False\n",
    "            \n",
    "            print(\"ğŸ“¥ ê¸°ì¡´ ChromaDBë¥¼ ë¡œë“œí•©ë‹ˆë‹¤...\")\n",
    "            \n",
    "            self.db = Chroma(\n",
    "                persist_directory=self.db_path,\n",
    "                embedding_function=self.embeddings,\n",
    "                collection_name=\"rag_collection\"\n",
    "            )\n",
    "            \n",
    "            count = self.get_document_count()\n",
    "            print(f\"âœ… ChromaDBê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤! ({count}ê°œ ë¬¸ì„œ)\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ DB ë¡œë“œ ì‹¤íŒ¨: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def add_documents(self, documents: list) -> bool:\n",
    "        \"\"\"ê¸°ì¡´ DBì— ë¬¸ì„œ ì¶”ê°€\"\"\"\n",
    "        try:\n",
    "            if self.db is None:\n",
    "                if not self.load_existing_db():\n",
    "                    print(\"âŒ DBë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ì–´ ë¬¸ì„œ ì¶”ê°€ë¥¼ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\")\n",
    "                    return False\n",
    "            \n",
    "            old_count = self.get_document_count()\n",
    "            print(f\"ğŸ“ ê¸°ì¡´ DBì— {len(documents)}ê°œ ë¬¸ì„œë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤...\")\n",
    "            \n",
    "            self.db.add_documents(documents)\n",
    "            \n",
    "            new_count = self.get_document_count()\n",
    "            print(f\"âœ… ë¬¸ì„œ ì¶”ê°€ ì™„ë£Œ! ({old_count} â†’ {new_count}ê°œ)\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ë¬¸ì„œ ì¶”ê°€ ì‹¤íŒ¨: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def get_document_count(self) -> int:\n",
    "        \"\"\"ì €ì¥ëœ ë¬¸ì„œ ê°œìˆ˜ ë°˜í™˜\"\"\"\n",
    "        try:\n",
    "            if self.db is None:\n",
    "                return 0\n",
    "            return self.db._collection.count()\n",
    "        except:\n",
    "            return 0\n",
    "    \n",
    "    def get_files_in_db(self) -> List[str]:\n",
    "        \"\"\"DBì— ì €ì¥ëœ íŒŒì¼ëª… ëª©ë¡ ë°˜í™˜\"\"\"\n",
    "        try:\n",
    "            if self.db is None:\n",
    "                return []\n",
    "            \n",
    "            collection = self.db._collection\n",
    "            results = collection.get(include=['metadatas'])\n",
    "            \n",
    "            files_in_db = set()\n",
    "            for metadata in results['metadatas']:\n",
    "                if metadata and 'source' in metadata:\n",
    "                    source = metadata['source']\n",
    "                    filename = os.path.basename(source)\n",
    "                    files_in_db.add(filename)\n",
    "            \n",
    "            return list(files_in_db)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ DB íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}\")\n",
    "            return []\n",
    "    \n",
    "    def delete_db(self) -> bool:\n",
    "        \"\"\"ChromaDB ì™„ì „ ì‚­ì œ\"\"\"\n",
    "        try:\n",
    "            self.db = None\n",
    "            import gc\n",
    "            gc.collect()\n",
    "            \n",
    "            if os.path.exists(self.db_path):\n",
    "                shutil.rmtree(self.db_path)\n",
    "                print(f\"ğŸ—‘ï¸ ChromaDBê°€ ì™„ì „íˆ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤: {self.db_path}\")\n",
    "            else:\n",
    "                print(\"â„¹ï¸ ì‚­ì œí•  DBê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ DB ì‚­ì œ ì‹¤íŒ¨: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def get_status(self) -> Dict[str, Any]:\n",
    "        \"\"\"DB ìƒíƒœ ì •ë³´ ë°˜í™˜\"\"\"\n",
    "        exists = self.check_db_exists()\n",
    "        loaded = self.db is not None\n",
    "        count = self.get_document_count() if loaded else 0\n",
    "        \n",
    "        return {\n",
    "            'db_exists': exists,\n",
    "            'db_loaded': loaded,\n",
    "            'document_count': count,\n",
    "            'db_path': self.db_path,\n",
    "            'embedding_model': self.embedding_model\n",
    "        }\n",
    "\n",
    "print(\"âœ… ChromaDBManager í´ë˜ìŠ¤ê°€ ì •ì˜ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“„ ë¬¸ì„œ ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë¬¸ì„œ ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ê°€ ì •ì˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "def load_and_split_document(file_path: str, chunk_size: int = 500, chunk_overlap: int = 100) -> list:\n",
    "    \"\"\"íŒŒì¼ì„ ë¡œë“œí•˜ê³  ì²­í¬ë¡œ ë¶„í• \"\"\"\n",
    "    try:\n",
    "        file_extension = Path(file_path).suffix.lower()\n",
    "        \n",
    "        # íŒŒì¼ íƒ€ì…ì— ë”°ë¥¸ ë¡œë” ì„ íƒ\n",
    "        if file_extension == '.txt':\n",
    "            loader = TextLoader(file_path, encoding='utf-8')\n",
    "        elif file_extension == '.pdf':\n",
    "            loader = PyPDFLoader(file_path)\n",
    "        else:\n",
    "            raise ValueError(f\"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_extension}\")\n",
    "        \n",
    "        # í…ìŠ¤íŠ¸ ë¶„í• ê¸° ì„¤ì •\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap\n",
    "        )\n",
    "        \n",
    "        # ë¬¸ì„œ ë¡œë“œ ë° ë¶„í• \n",
    "        documents = loader.load_and_split(text_splitter)\n",
    "        \n",
    "        print(f\"ğŸ“„ íŒŒì¼ ë¡œë“œ ì„±ê³µ: {os.path.basename(file_path)}\")\n",
    "        print(f\"ğŸ“Š ìƒì„±ëœ ì²­í¬ ìˆ˜: {len(documents)}\")\n",
    "        \n",
    "        return documents\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ ({os.path.basename(file_path)}): {str(e)}\")\n",
    "        return []\n",
    "\n",
    "print(\"âœ… ë¬¸ì„œ ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ê°€ ì •ì˜ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ—‚ï¸ Raw Data ë™ê¸°í™” ê´€ë¦¬ í´ë˜ìŠ¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RawDataSyncManager í´ë˜ìŠ¤ê°€ ì •ì˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "class RawDataSyncManager:\n",
    "    \"\"\"Raw Data í´ë”ì™€ ChromaDB ë™ê¸°í™” ê´€ë¦¬ í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    def __init__(self, raw_data_path: str = \"./raw_data\"):\n",
    "        self.raw_data_path = raw_data_path\n",
    "        self.supported_extensions = ['.txt', '.pdf']\n",
    "        \n",
    "        # raw_data í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±\n",
    "        if not os.path.exists(self.raw_data_path):\n",
    "            os.makedirs(self.raw_data_path)\n",
    "            print(f\"ğŸ“ raw_data í´ë”ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤: {self.raw_data_path}\")\n",
    "        else:\n",
    "            print(f\"ğŸ“ raw_data í´ë” ê²½ë¡œ: {self.raw_data_path}\")\n",
    "    \n",
    "    def scan_raw_data_folder(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"raw_data í´ë”ì˜ ëª¨ë“  ì§€ì› íŒŒì¼ ìŠ¤ìº”\"\"\"\n",
    "        files_info = []\n",
    "        \n",
    "        try:\n",
    "            if not os.path.exists(self.raw_data_path):\n",
    "                print(f\"âŒ raw_data í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {self.raw_data_path}\")\n",
    "                return files_info\n",
    "            \n",
    "            for root, dirs, files in os.walk(self.raw_data_path):\n",
    "                for file in files:\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    file_extension = Path(file).suffix.lower()\n",
    "                    \n",
    "                    if file_extension in self.supported_extensions:\n",
    "                        file_stat = os.stat(file_path)\n",
    "                        \n",
    "                        file_info = {\n",
    "                            'filename': file,\n",
    "                            'full_path': file_path,\n",
    "                            'relative_path': os.path.relpath(file_path, self.raw_data_path),\n",
    "                            'extension': file_extension,\n",
    "                            'size_bytes': file_stat.st_size,\n",
    "                            'size_mb': round(file_stat.st_size / (1024 * 1024), 2),\n",
    "                            'modified_time': file_stat.st_mtime,\n",
    "                            'modified_date': pd.to_datetime(file_stat.st_mtime, unit='s').strftime('%Y-%m-%d %H:%M:%S')\n",
    "                        }\n",
    "                        files_info.append(file_info)\n",
    "            \n",
    "            return files_info\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ raw_data í´ë” ìŠ¤ìº” ì‹¤íŒ¨: {str(e)}\")\n",
    "            return []\n",
    "    \n",
    "    def compare_with_db(self, db_manager: ChromaDBManager) -> Dict[str, List[str]]:\n",
    "        \"\"\"raw_data í´ë”ì˜ íŒŒì¼ë“¤ê³¼ DBì— ì €ì¥ëœ íŒŒì¼ë“¤ì„ ë¹„êµ\"\"\"\n",
    "        # raw_data í´ë” íŒŒì¼ ëª©ë¡\n",
    "        raw_files_info = self.scan_raw_data_folder()\n",
    "        raw_files = [info['filename'] for info in raw_files_info]\n",
    "        \n",
    "        # DBì— ì €ì¥ëœ íŒŒì¼ ëª©ë¡\n",
    "        db_files = db_manager.get_files_in_db()\n",
    "        \n",
    "        # ë¹„êµ ê²°ê³¼\n",
    "        sync_status = {\n",
    "            'new_files': [],      # DBì— ì—†ëŠ” ìƒˆ íŒŒì¼ë“¤\n",
    "            'existing_files': [], # DBì— ì´ë¯¸ ìˆëŠ” íŒŒì¼ë“¤\n",
    "            'orphaned_files': [], # raw_dataì—ëŠ” ì—†ì§€ë§Œ DBì— ìˆëŠ” íŒŒì¼ë“¤\n",
    "            'all_raw_files': raw_files,\n",
    "            'all_db_files': db_files\n",
    "        }\n",
    "        \n",
    "        # ìƒˆ íŒŒì¼ê³¼ ê¸°ì¡´ íŒŒì¼ ë¶„ë¥˜\n",
    "        for filename in raw_files:\n",
    "            if filename in db_files:\n",
    "                sync_status['existing_files'].append(filename)\n",
    "            else:\n",
    "                sync_status['new_files'].append(filename)\n",
    "        \n",
    "        # ê³ ì•„ íŒŒì¼ ì°¾ê¸° (DBì—ë§Œ ìˆê³  raw_dataì—ëŠ” ì—†ëŠ” íŒŒì¼)\n",
    "        for filename in db_files:\n",
    "            if filename not in raw_files:\n",
    "                sync_status['orphaned_files'].append(filename)\n",
    "        \n",
    "        return sync_status\n",
    "    \n",
    "    def sync_with_db(self, db_manager: ChromaDBManager, chunk_size: int = 500, chunk_overlap: int = 100) -> bool:\n",
    "        \"\"\"raw_data í´ë”ì˜ ìƒˆ íŒŒì¼ë“¤ì„ DBì— ë™ê¸°í™”\"\"\"\n",
    "        try:\n",
    "            # ë™ê¸°í™” ìƒíƒœ í™•ì¸\n",
    "            sync_status = self.compare_with_db(db_manager)\n",
    "            new_files = sync_status['new_files']\n",
    "            \n",
    "            if not new_files:\n",
    "                print(\"âœ… ë™ê¸°í™”í•  ìƒˆ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ëª¨ë“  íŒŒì¼ì´ ì´ë¯¸ DBì— ì €ì¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\")\n",
    "                return True\n",
    "            \n",
    "            print(f\"ğŸ“ {len(new_files)}ê°œì˜ ìƒˆ íŒŒì¼ì„ DBì— ì¶”ê°€í•©ë‹ˆë‹¤...\")\n",
    "            \n",
    "            # DBê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ë‹¤ë©´ ë¡œë“œ ì‹œë„\n",
    "            if db_manager.db is None:\n",
    "                if db_manager.check_db_exists():\n",
    "                    if not db_manager.load_existing_db():\n",
    "                        print(\"âŒ ê¸°ì¡´ DB ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\")\n",
    "                        return False\n",
    "                else:\n",
    "                    print(\"â„¹ï¸ ê¸°ì¡´ DBê°€ ì—†ìŠµë‹ˆë‹¤. ì²« ë²ˆì§¸ íŒŒì¼ë¡œ ìƒˆ DBë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\")\n",
    "            \n",
    "            # ê° ìƒˆ íŒŒì¼ ì²˜ë¦¬\n",
    "            total_added_docs = 0\n",
    "            for filename in new_files:\n",
    "                file_path = os.path.join(self.raw_data_path, filename)\n",
    "                \n",
    "                print(f\"\\nğŸ”„ ì²˜ë¦¬ ì¤‘: {filename}\")\n",
    "                \n",
    "                # íŒŒì¼ ë¡œë“œ ë° ë¶„í• \n",
    "                documents = load_and_split_document(file_path, chunk_size, chunk_overlap)\n",
    "                \n",
    "                if documents:\n",
    "                    # DBê°€ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ íŒŒì¼ë¡œ ìƒì„±, ìˆìœ¼ë©´ ì¶”ê°€\n",
    "                    if not db_manager.check_db_exists():\n",
    "                        success = db_manager.create_new_db(documents)\n",
    "                    else:\n",
    "                        success = db_manager.add_documents(documents)\n",
    "                    \n",
    "                    if success:\n",
    "                        total_added_docs += len(documents)\n",
    "                        print(f\"   âœ… {filename}: {len(documents)}ê°œ ì²­í¬ ì¶”ê°€ë¨\")\n",
    "                    else:\n",
    "                        print(f\"   âŒ {filename}: ì¶”ê°€ ì‹¤íŒ¨\")\n",
    "                        return False\n",
    "                else:\n",
    "                    print(f\"   âš ï¸ {filename}: íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨\")\n",
    "            \n",
    "            print(f\"\\nğŸ‰ ë™ê¸°í™” ì™„ë£Œ! ì´ {total_added_docs}ê°œ ì²­í¬ê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ë™ê¸°í™” ì‹¤íŒ¨: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def print_sync_report(self, db_manager: ChromaDBManager):\n",
    "        \"\"\"ë™ê¸°í™” ìƒíƒœ ë¦¬í¬íŠ¸ ì¶œë ¥\"\"\"\n",
    "        print(\"\\nğŸ“Š Raw Data ë™ê¸°í™” ìƒíƒœ ë¦¬í¬íŠ¸\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # raw_data í´ë” ìŠ¤ìº”\n",
    "        raw_files_info = self.scan_raw_data_folder()\n",
    "        sync_status = self.compare_with_db(db_manager)\n",
    "        \n",
    "        # raw_data í´ë” ì •ë³´\n",
    "        print(f\"\\nğŸ“ Raw Data í´ë”: {self.raw_data_path}\")\n",
    "        print(f\"   ì´ íŒŒì¼ ìˆ˜: {len(raw_files_info)}ê°œ\")\n",
    "        \n",
    "        if raw_files_info:\n",
    "            total_size_mb = sum(info['size_mb'] for info in raw_files_info)\n",
    "            print(f\"   ì´ íŒŒì¼ í¬ê¸°: {total_size_mb:.2f} MB\")\n",
    "            \n",
    "            # íŒŒì¼ ëª©ë¡ í…Œì´ë¸”\n",
    "            df_raw = pd.DataFrame(raw_files_info)\n",
    "            print(\"\\nğŸ“‹ Raw Data íŒŒì¼ ëª©ë¡:\")\n",
    "            display_cols = ['filename', 'extension', 'size_mb', 'modified_date']\n",
    "            print(df_raw[display_cols].to_string(index=False))\n",
    "        \n",
    "        # DB ìƒíƒœ\n",
    "        db_status = db_manager.get_status()\n",
    "        print(f\"\\nğŸ—„ï¸ ChromaDB ìƒíƒœ:\")\n",
    "        print(f\"   DB ì¡´ì¬: {'âœ…' if db_status['db_exists'] else 'âŒ'}\")\n",
    "        print(f\"   ì´ ë¬¸ì„œ ìˆ˜: {db_status['document_count']}ê°œ\")\n",
    "        print(f\"   ì €ì¥ëœ íŒŒì¼ ìˆ˜: {len(sync_status['all_db_files'])}ê°œ\")\n",
    "        \n",
    "        # ë™ê¸°í™” ìƒíƒœ\n",
    "        print(f\"\\nğŸ”„ ë™ê¸°í™” ìƒíƒœ:\")\n",
    "        print(f\"   ìƒˆ íŒŒì¼ (ì¶”ê°€ í•„ìš”): {len(sync_status['new_files'])}ê°œ\")\n",
    "        print(f\"   ê¸°ì¡´ íŒŒì¼ (ë™ê¸°í™”ë¨): {len(sync_status['existing_files'])}ê°œ\")\n",
    "        print(f\"   ê³ ì•„ íŒŒì¼ (DBì—ë§Œ ì¡´ì¬): {len(sync_status['orphaned_files'])}ê°œ\")\n",
    "        \n",
    "        # ìƒì„¸ ì •ë³´\n",
    "        if sync_status['new_files']:\n",
    "            print(f\"\\nğŸ“¥ ì¶”ê°€í•  ìƒˆ íŒŒì¼ë“¤:\")\n",
    "            for filename in sync_status['new_files']:\n",
    "                print(f\"   - {filename}\")\n",
    "        \n",
    "        if sync_status['orphaned_files']:\n",
    "            print(f\"\\nğŸ‘» ê³ ì•„ íŒŒì¼ë“¤ (raw_dataì— ì—†ìŒ):\")\n",
    "            for filename in sync_status['orphaned_files']:\n",
    "                print(f\"   - {filename}\")\n",
    "        \n",
    "        # ê¶Œì¥ ì‚¬í•­\n",
    "        print(f\"\\nğŸ’¡ ê¶Œì¥ ì‚¬í•­:\")\n",
    "        if sync_status['new_files']:\n",
    "            print(f\"   ğŸ”„ sync_manager.sync_with_db(db_manager)ë¥¼ ì‹¤í–‰í•˜ì—¬ ìƒˆ íŒŒì¼ë“¤ì„ ì¶”ê°€í•˜ì„¸ìš”\")\n",
    "        if sync_status['orphaned_files']:\n",
    "            print(f\"   ğŸ§¹ ê³ ì•„ íŒŒì¼ë“¤ì„ DBì—ì„œ ì œê±°í•˜ê±°ë‚˜ ì›ë³¸ íŒŒì¼ì„ raw_dataì— ë³µì›í•˜ëŠ” ê²ƒì„ ê³ ë ¤í•˜ì„¸ìš”\")\n",
    "        if not sync_status['new_files'] and not sync_status['orphaned_files']:\n",
    "            print(f\"   âœ… ëª¨ë“  íŒŒì¼ì´ ì™„ë²½í•˜ê²Œ ë™ê¸°í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤!\")\n",
    "\n",
    "print(\"âœ… RawDataSyncManager í´ë˜ìŠ¤ê°€ ì •ì˜ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ ë™ê¸°í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™” ë° ì‹¤í–‰\n",
    "\n",
    "ì´ì œ ì‹¤ì œë¡œ ë™ê¸°í™”ë¥¼ ì‹¤í–‰í•´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ ê´€ë¦¬ì ì´ˆê¸°í™”\n",
      "ğŸ“ DB ê²½ë¡œ: ./chroma_db\n",
      "ğŸ”¤ ì„ë² ë”© ëª¨ë¸: text-embedding-3-large\n",
      "ğŸ“ raw_data í´ë” ê²½ë¡œ: ./raw_data\n",
      "\n",
      "âœ… ê´€ë¦¬ì ì´ˆê¸°í™” ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# 1. ê´€ë¦¬ì ì´ˆê¸°í™”\n",
    "print(\"ğŸ”§ ê´€ë¦¬ì ì´ˆê¸°í™”\")\n",
    "\n",
    "# ChromaDB ë§¤ë‹ˆì € (ì‹¤ì œ ì‚¬ìš©í•  DB ê²½ë¡œ)\n",
    "db_manager = ChromaDBManager(\n",
    "    db_path=\"./chroma_db\",  # ì‹¤ì œ DB ê²½ë¡œ\n",
    "    embedding_model=\"text-embedding-3-large\"\n",
    ")\n",
    "\n",
    "# Raw Data ë™ê¸°í™” ë§¤ë‹ˆì €\n",
    "sync_manager = RawDataSyncManager(\n",
    "    raw_data_path=\"./raw_data\"\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… ê´€ë¦¬ì ì´ˆê¸°í™” ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š í˜„ì¬ ë™ê¸°í™” ìƒíƒœ í™•ì¸\n",
      "\n",
      "ğŸ“Š Raw Data ë™ê¸°í™” ìƒíƒœ ë¦¬í¬íŠ¸\n",
      "==================================================\n",
      "\n",
      "ğŸ“ Raw Data í´ë”: ./raw_data\n",
      "   ì´ íŒŒì¼ ìˆ˜: 2ê°œ\n",
      "   ì´ íŒŒì¼ í¬ê¸°: 9.60 MB\n",
      "\n",
      "ğŸ“‹ Raw Data íŒŒì¼ ëª©ë¡:\n",
      "                       filename extension  size_mb       modified_date\n",
      "       2025ë…„ ê°œì •ì„¸ë²• í•´ì„¤ ë‚´ì§€-12êµ.pdf      .pdf     8.86 2025-07-15 07:53:04\n",
      "ì†Œë“ì„¸ë²•(ë²•ë¥ )(ì œ20615í˜¸)(20250701).pdf      .pdf     0.74 2025-07-15 04:28:14\n",
      "\n",
      "ğŸ—„ï¸ ChromaDB ìƒíƒœ:\n",
      "   DB ì¡´ì¬: âœ…\n",
      "   ì´ ë¬¸ì„œ ìˆ˜: 1704ê°œ\n",
      "   ì €ì¥ëœ íŒŒì¼ ìˆ˜: 2ê°œ\n",
      "\n",
      "ğŸ”„ ë™ê¸°í™” ìƒíƒœ:\n",
      "   ìƒˆ íŒŒì¼ (ì¶”ê°€ í•„ìš”): 0ê°œ\n",
      "   ê¸°ì¡´ íŒŒì¼ (ë™ê¸°í™”ë¨): 2ê°œ\n",
      "   ê³ ì•„ íŒŒì¼ (DBì—ë§Œ ì¡´ì¬): 0ê°œ\n",
      "\n",
      "ğŸ’¡ ê¶Œì¥ ì‚¬í•­:\n",
      "   âœ… ëª¨ë“  íŒŒì¼ì´ ì™„ë²½í•˜ê²Œ ë™ê¸°í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "# 2. í˜„ì¬ ë™ê¸°í™” ìƒíƒœ í™•ì¸\n",
    "print(\"ğŸ“Š í˜„ì¬ ë™ê¸°í™” ìƒíƒœ í™•ì¸\")\n",
    "sync_manager.print_sync_report(db_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ ìë™ ë™ê¸°í™” ì‹œì‘\n",
      "ğŸ“ 2ê°œì˜ ìƒˆ íŒŒì¼ì„ DBì— ì¶”ê°€í•©ë‹ˆë‹¤...\n",
      "ğŸ“¥ ê¸°ì¡´ ChromaDBë¥¼ ë¡œë“œí•©ë‹ˆë‹¤...\n",
      "âœ… ChromaDBê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤! (852ê°œ ë¬¸ì„œ)\n",
      "\n",
      "ğŸ”„ ì²˜ë¦¬ ì¤‘: 2025ë…„ ê°œì •ì„¸ë²• í•´ì„¤ ë‚´ì§€-12êµ.pdf\n",
      "ğŸ“„ íŒŒì¼ ë¡œë“œ ì„±ê³µ: 2025ë…„ ê°œì •ì„¸ë²• í•´ì„¤ ë‚´ì§€-12êµ.pdf\n",
      "ğŸ“Š ìƒì„±ëœ ì²­í¬ ìˆ˜: 497\n",
      "ğŸ“ ê¸°ì¡´ DBì— 497ê°œ ë¬¸ì„œë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤...\n",
      "âœ… ë¬¸ì„œ ì¶”ê°€ ì™„ë£Œ! (852 â†’ 1349ê°œ)\n",
      "   âœ… 2025ë…„ ê°œì •ì„¸ë²• í•´ì„¤ ë‚´ì§€-12êµ.pdf: 497ê°œ ì²­í¬ ì¶”ê°€ë¨\n",
      "\n",
      "ğŸ”„ ì²˜ë¦¬ ì¤‘: ì†Œë“ì„¸ë²•(ë²•ë¥ )(ì œ20615í˜¸)(20250701).pdf\n",
      "ğŸ“„ íŒŒì¼ ë¡œë“œ ì„±ê³µ: ì†Œë“ì„¸ë²•(ë²•ë¥ )(ì œ20615í˜¸)(20250701).pdf\n",
      "ğŸ“Š ìƒì„±ëœ ì²­í¬ ìˆ˜: 355\n",
      "ğŸ“ ê¸°ì¡´ DBì— 355ê°œ ë¬¸ì„œë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤...\n",
      "âœ… ë¬¸ì„œ ì¶”ê°€ ì™„ë£Œ! (1349 â†’ 1704ê°œ)\n",
      "   âœ… ì†Œë“ì„¸ë²•(ë²•ë¥ )(ì œ20615í˜¸)(20250701).pdf: 355ê°œ ì²­í¬ ì¶”ê°€ë¨\n",
      "\n",
      "ğŸ‰ ë™ê¸°í™” ì™„ë£Œ! ì´ 852ê°œ ì²­í¬ê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ğŸ‰ ë™ê¸°í™”ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "# 3. ìë™ ë™ê¸°í™” ì‹¤í–‰\n",
    "print(\"ğŸ”„ ìë™ ë™ê¸°í™” ì‹œì‘\")\n",
    "\n",
    "# ì²­í¬ ì„¤ì • (í•„ìš”ì— ë”°ë¼ ì¡°ì •)\n",
    "CHUNK_SIZE = 1000      # ì²­í¬ í¬ê¸°\n",
    "CHUNK_OVERLAP = 200    # ì²­í¬ ê²¹ì¹¨\n",
    "\n",
    "# ë™ê¸°í™” ì‹¤í–‰\n",
    "success = sync_manager.sync_with_db(\n",
    "    db_manager=db_manager,\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP\n",
    ")\n",
    "\n",
    "if success:\n",
    "    print(\"\\nğŸ‰ ë™ê¸°í™”ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "else:\n",
    "    print(\"\\nâŒ ë™ê¸°í™” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š ë™ê¸°í™” í›„ ìµœì¢… ìƒíƒœ\n",
      "\n",
      "ğŸ“Š Raw Data ë™ê¸°í™” ìƒíƒœ ë¦¬í¬íŠ¸\n",
      "==================================================\n",
      "\n",
      "ğŸ“ Raw Data í´ë”: ./raw_data\n",
      "   ì´ íŒŒì¼ ìˆ˜: 2ê°œ\n",
      "   ì´ íŒŒì¼ í¬ê¸°: 9.60 MB\n",
      "\n",
      "ğŸ“‹ Raw Data íŒŒì¼ ëª©ë¡:\n",
      "                       filename extension  size_mb       modified_date\n",
      "       2025ë…„ ê°œì •ì„¸ë²• í•´ì„¤ ë‚´ì§€-12êµ.pdf      .pdf     8.86 2025-07-15 07:53:04\n",
      "ì†Œë“ì„¸ë²•(ë²•ë¥ )(ì œ20615í˜¸)(20250701).pdf      .pdf     0.74 2025-07-15 04:28:14\n",
      "\n",
      "ğŸ—„ï¸ ChromaDB ìƒíƒœ:\n",
      "   DB ì¡´ì¬: âœ…\n",
      "   ì´ ë¬¸ì„œ ìˆ˜: 1704ê°œ\n",
      "   ì €ì¥ëœ íŒŒì¼ ìˆ˜: 2ê°œ\n",
      "\n",
      "ğŸ”„ ë™ê¸°í™” ìƒíƒœ:\n",
      "   ìƒˆ íŒŒì¼ (ì¶”ê°€ í•„ìš”): 0ê°œ\n",
      "   ê¸°ì¡´ íŒŒì¼ (ë™ê¸°í™”ë¨): 2ê°œ\n",
      "   ê³ ì•„ íŒŒì¼ (DBì—ë§Œ ì¡´ì¬): 0ê°œ\n",
      "\n",
      "ğŸ’¡ ê¶Œì¥ ì‚¬í•­:\n",
      "   âœ… ëª¨ë“  íŒŒì¼ì´ ì™„ë²½í•˜ê²Œ ë™ê¸°í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤!\n",
      "\n",
      "ğŸ“ˆ ìµœì¢… DB ìƒíƒœ ìš”ì•½:\n",
      "   ì´ ë¬¸ì„œ ì²­í¬ ìˆ˜: 1,704ê°œ\n",
      "   DB ê²½ë¡œ: ./chroma_db\n",
      "   ì„ë² ë”© ëª¨ë¸: text-embedding-3-large\n"
     ]
    }
   ],
   "source": [
    "# 4. ë™ê¸°í™” í›„ ìƒíƒœ ì¬í™•ì¸\n",
    "print(\"\\nğŸ“Š ë™ê¸°í™” í›„ ìµœì¢… ìƒíƒœ\")\n",
    "sync_manager.print_sync_report(db_manager)\n",
    "\n",
    "# DB ìƒíƒœ ìš”ì•½\n",
    "status = db_manager.get_status()\n",
    "print(f\"\\nğŸ“ˆ ìµœì¢… DB ìƒíƒœ ìš”ì•½:\")\n",
    "print(f\"   ì´ ë¬¸ì„œ ì²­í¬ ìˆ˜: {status['document_count']:,}ê°œ\")\n",
    "print(f\"   DB ê²½ë¡œ: {status['db_path']}\")\n",
    "print(f\"   ì„ë² ë”© ëª¨ë¸: {status['embedding_model']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” ë™ê¸°í™”ëœ ë¬¸ì„œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
    "\n",
    "ë™ê¸°í™”ê°€ ì™„ë£Œëœ í›„ ì‹¤ì œë¡œ ê²€ìƒ‰ì´ ì˜ ì‘ë™í•˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸í•´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” ë™ê¸°í™”ëœ ë¬¸ì„œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
      "\n",
      "ğŸ” ê²€ìƒ‰ì–´: 'ì†Œë“ì„¸'\n",
      "   ê²°ê³¼ 1: 2025ë…„ ê°œì •ì„¸ë²• í•´ì„¤ ë‚´ì§€-12êµ.pdf (í˜ì´ì§€ 34)\n",
      "   ë‚´ìš©: ì†Œë“ì„¸ë²•(ì¢…í•©ì†Œë“ì„¸ ë¶„ì•¼) ï¿­ 27\n",
      "ì†Œë“ì„¸ë²•(ì¢…í•©ì†Œë“ì„¸ ë¶„ì•¼)\n",
      "\n",
      "   ê²°ê³¼ 2: 2025ë…„ ê°œì •ì„¸ë²• í•´ì„¤ ë‚´ì§€-12êµ.pdf (í˜ì´ì§€ 34)\n",
      "   ë‚´ìš©: ì†Œë“ì„¸ë²•(ì¢…í•©ì†Œë“ì„¸ ë¶„ì•¼) ï¿­ 27\n",
      "ì†Œë“ì„¸ë²•(ì¢…í•©ì†Œë“ì„¸ ë¶„ì•¼)\n",
      "\n",
      "   ê²°ê³¼ 3: ì†Œë“ì„¸ë²•(ë²•ë¥ )(ì œ20615í˜¸)(20250701).pdf (í˜ì´ì§€ 0)\n",
      "   ë‚´ìš©: ë²•ì œì²˜                                                            1                                                       êµ­ê°€ë²•ë ¹ì •ë³´ì„¼í„°\n",
      "ì†Œë“ì„¸ë²•\n",
      " \n",
      "ì†Œë“ì„¸ë²•\n",
      "[ì‹œí–‰ 2025. ...\n",
      "\n",
      "\n",
      "ğŸ” ê²€ìƒ‰ì–´: 'ê°œì •ì„¸ë²•'\n",
      "   ê²°ê³¼ 1: 2025ë…„ ê°œì •ì„¸ë²• í•´ì„¤ ë‚´ì§€-12êµ.pdf (í˜ì´ì§€ 87)\n",
      "   ë‚´ìš©: 80 ï¿­ 2025ë…„ ê°œì •ì„¸ë²• í•´ì„¤\n",
      "\n",
      "   ê²°ê³¼ 2: 2025ë…„ ê°œì •ì„¸ë²• í•´ì„¤ ë‚´ì§€-12êµ.pdf (í˜ì´ì§€ 87)\n",
      "   ë‚´ìš©: 80 ï¿­ 2025ë…„ ê°œì •ì„¸ë²• í•´ì„¤\n",
      "\n",
      "   ê²°ê³¼ 3: 2025ë…„ ê°œì •ì„¸ë²• í•´ì„¤ ë‚´ì§€-12êµ.pdf (í˜ì´ì§€ 33)\n",
      "   ë‚´ìš©: 26 ï¿­ 2025ë…„ ê°œì •ì„¸ë²• í•´ì„¤\n",
      "\n",
      "\n",
      "ğŸ” ê²€ìƒ‰ì–´: 'ì„¸ë²• ê°œì •'\n",
      "   ê²°ê³¼ 1: 2025ë…„ ê°œì •ì„¸ë²• í•´ì„¤ ë‚´ì§€-12êµ.pdf (í˜ì´ì§€ 121)\n",
      "   ë‚´ìš©: 114 ï¿­ 2025ë…„ ê°œì •ì„¸ë²• í•´ì„¤\n",
      "\n",
      "   ê²°ê³¼ 2: 2025ë…„ ê°œì •ì„¸ë²• í•´ì„¤ ë‚´ì§€-12êµ.pdf (í˜ì´ì§€ 121)\n",
      "   ë‚´ìš©: 114 ï¿­ 2025ë…„ ê°œì •ì„¸ë²• í•´ì„¤\n",
      "\n",
      "   ê²°ê³¼ 3: 2025ë…„ ê°œì •ì„¸ë²• í•´ì„¤ ë‚´ì§€-12êµ.pdf (í˜ì´ì§€ 323)\n",
      "   ë‚´ìš©: 316 ï¿­ 2025ë…„ ê°œì •ì„¸ë²• í•´ì„¤\n",
      "\n",
      "\n",
      "ğŸ” ê²€ìƒ‰ì–´: '2025ë…„'\n",
      "   ê²°ê³¼ 1: 2025ë…„ ê°œì •ì„¸ë²• í•´ì„¤ ë‚´ì§€-12êµ.pdf (í˜ì´ì§€ 0)\n",
      "   ë‚´ìš©: 2025\n",
      "20\n",
      "2\n",
      "5\n",
      "\n",
      "   ê²°ê³¼ 2: 2025ë…„ ê°œì •ì„¸ë²• í•´ì„¤ ë‚´ì§€-12êµ.pdf (í˜ì´ì§€ 0)\n",
      "   ë‚´ìš©: 2025\n",
      "20\n",
      "2\n",
      "5\n",
      "\n",
      "   ê²°ê³¼ 3: 2025ë…„ ê°œì •ì„¸ë²• í•´ì„¤ ë‚´ì§€-12êµ.pdf (í˜ì´ì§€ 189)\n",
      "   ë‚´ìš©: 182 ï¿­ 2025ë…„ ê°œì •ì„¸ë²• í•´ì„¤\n",
      "ì¢…          ì „ ê°œ          ì •<ì‹   ì„¤>       âˆ™5ë…„ì„ íƒ ì·¨ì†Œ í›„ ì¡°ì •ëŒ€ìƒ ì¡°ì„¸ æ—£ì‚°ì… ê¸ˆì•¡ í™˜ì›ì‹œ â†’ í™˜ì›ëœ ì‚¬ì—…ì—°ë„ì˜ ì¡°ì • ëŒ€ìƒì¡°ì„¸ì—ì„œ ì œì™¸ë‹¤. ì ìš©ì‹œê¸° ë° ì ìš©ë¡€  â—‹ 2025.2.28. ì´í›„ ì‹ ê³ í•˜ëŠ” ë¶„ë¶€...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. ë™ê¸°í™”ëœ ë¬¸ì„œë“¤ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
    "print(\"\\nğŸ” ë™ê¸°í™”ëœ ë¬¸ì„œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\")\n",
    "\n",
    "if db_manager.db:\n",
    "    # ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤ (ì‹¤ì œ ë¬¸ì„œì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”)\n",
    "    test_queries = [\n",
    "        \"ì†Œë“ì„¸\",\n",
    "        \"ê°œì •ì„¸ë²•\",\n",
    "        \"ì„¸ë²• ê°œì •\",\n",
    "        \"2025ë…„\"\n",
    "    ]\n",
    "    \n",
    "    for query in test_queries:\n",
    "        print(f\"\\nğŸ” ê²€ìƒ‰ì–´: '{query}'\")\n",
    "        try:\n",
    "            results = db_manager.db.similarity_search(query, k=3)\n",
    "            \n",
    "            if results:\n",
    "                for i, result in enumerate(results, 1):\n",
    "                    filename = os.path.basename(result.metadata.get('source', 'Unknown'))\n",
    "                    page = result.metadata.get('page', 'N/A')\n",
    "                    content_preview = result.page_content[:150] + \"...\" if len(result.page_content) > 150 else result.page_content\n",
    "                    \n",
    "                    print(f\"   ê²°ê³¼ {i}: {filename} (í˜ì´ì§€ {page})\")\n",
    "                    print(f\"   ë‚´ìš©: {content_preview}\")\n",
    "                    print()\n",
    "            else:\n",
    "                print(f\"   ğŸ“­ '{query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}\")\n",
    "else:\n",
    "    print(\"âŒ DBê°€ ë¡œë“œë˜ì§€ ì•Šì•„ ê²€ìƒ‰ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ›ï¸ ì¶”ê°€ ê´€ë¦¬ ê¸°ëŠ¥\n",
    "\n",
    "í•„ìš”ì— ë”°ë¼ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì¶”ê°€ ê´€ë¦¬ ê¸°ëŠ¥ë“¤ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” 'ê²€ìƒ‰í•˜ê³  ì‹¶ì€ í‚¤ì›Œë“œ' ê²€ìƒ‰ ê²°ê³¼:\n",
      "\n",
      "ğŸ“„ ê²°ê³¼ 1: 2025ë…„ ê°œì •ì„¸ë²• í•´ì„¤ ë‚´ì§€-12êµ.pdf (í˜ì´ì§€: 161)\n",
      "ë‚´ìš©: ì°¨ë¡€01. ì •ìƒê°€ê²© ì¡°ì •ì— ë”°ë¥¸ ê²½ì •ì²­êµ¬ í•©ë¦¬í™”Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â·15702. ìƒê³„ê±°ë˜ ì ìš©ëŒ€ìƒ ì¡°ë¬¸ ì •ë¹„Â· Â· Â· Â·...\n",
      "\n",
      "ğŸ“„ ê²°ê³¼ 2: 2025ë…„ ê°œì •ì„¸ë²• í•´ì„¤ ë‚´ì§€-12êµ.pdf (í˜ì´ì§€: 161)\n",
      "ë‚´ìš©: ì°¨ë¡€01. ì •ìƒê°€ê²© ì¡°ì •ì— ë”°ë¥¸ ê²½ì •ì²­êµ¬ í•©ë¦¬í™”Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â·15702. ìƒê³„ê±°ë˜ ì ìš©ëŒ€ìƒ ì¡°ë¬¸ ì •ë¹„Â· Â· Â· Â·...\n",
      "\n",
      "ğŸ“„ ê²°ê³¼ 3: 2025ë…„ ê°œì •ì„¸ë²• í•´ì„¤ ë‚´ì§€-12êµ.pdf (í˜ì´ì§€: 32)\n",
      "ë‚´ìš©: ì†Œë“ì„¸ë²•(ì¢…í•©ì†Œë“ì„¸ ë¶„ì•¼)2025ë…„ ê°œì •ì„¸ë²• í•´ì„¤\n",
      "ì§‘ í•„ ì§„\n",
      "ë¬¸ì˜ì‚¬í•­\n",
      "ì§•ì„¸ë²•ë¬´êµ­ ë²•ê·œê³¼ í–‰ì •ì‚¬ë¬´ê´€  ë…¸ ì˜ ì¸ì§•ì„¸ë²•ë¬´êµ­ ë²•ê·œê³¼ êµ­ì„¸ì¡°ì‚¬ê´€  ì†¡ ì„  ìš©ì§•ì„¸ë²•ë¬´êµ­ ë²•ê·œê³¼ êµ­ì„¸ì¡°ì‚¬ê´€  ê¹€ ì„± í¬ì§•ì„¸ë²•ë¬´êµ­ ë²•ê·œê³¼ êµ­ì„¸ì¡°ì‚¬ê´€  ê¹€ í•œ ê·¼ì§•ì„¸ë²•ë¬´êµ­ ë²•ê·œê³¼ êµ­ì„¸ì¡°ì‚¬ê´€  ë°• ê´‘ ì¶˜\n",
      "(044) 204-3117~21...\n",
      "\n",
      "ğŸ“„ ê²°ê³¼ 4: 2025ë…„ ê°œì •ì„¸ë²• í•´ì„¤ ë‚´ì§€-12êµ.pdf (í˜ì´ì§€: 32)\n",
      "ë‚´ìš©: ì†Œë“ì„¸ë²•(ì¢…í•©ì†Œë“ì„¸ ë¶„ì•¼)2025ë…„ ê°œì •ì„¸ë²• í•´ì„¤\n",
      "ì§‘ í•„ ì§„\n",
      "ë¬¸ì˜ì‚¬í•­\n",
      "ì§•ì„¸ë²•ë¬´êµ­ ë²•ê·œê³¼ í–‰ì •ì‚¬ë¬´ê´€  ë…¸ ì˜ ì¸ì§•ì„¸ë²•ë¬´êµ­ ë²•ê·œê³¼ êµ­ì„¸ì¡°ì‚¬ê´€  ì†¡ ì„  ìš©ì§•ì„¸ë²•ë¬´êµ­ ë²•ê·œê³¼ êµ­ì„¸ì¡°ì‚¬ê´€  ê¹€ ì„± í¬ì§•ì„¸ë²•ë¬´êµ­ ë²•ê·œê³¼ êµ­ì„¸ì¡°ì‚¬ê´€  ê¹€ í•œ ê·¼ì§•ì„¸ë²•ë¬´êµ­ ë²•ê·œê³¼ êµ­ì„¸ì¡°ì‚¬ê´€  ë°• ê´‘ ì¶˜\n",
      "(044) 204-3117~21...\n",
      "\n",
      "ğŸ“„ ê²°ê³¼ 5: 2025ë…„ ê°œì •ì„¸ë²• í•´ì„¤ ë‚´ì§€-12êµ.pdf (í˜ì´ì§€: 155)\n",
      "ë‚´ìš©: Â· Â· Â· Â· Â· Â· Â·106    â‘£ QFI ì¤€ìˆ˜ì‚¬í•­ ì¡°ì •Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â·...\n"
     ]
    }
   ],
   "source": [
    "# íŠ¹ì • í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•˜ê¸° (ì‚¬ìš©ì ì •ì˜)\n",
    "search_query = \"ê²€ìƒ‰í•˜ê³  ì‹¶ì€ í‚¤ì›Œë“œ\"  # ì›í•˜ëŠ” í‚¤ì›Œë“œë¡œ ë³€ê²½\n",
    "\n",
    "if db_manager.db:\n",
    "    print(f\"ğŸ” '{search_query}' ê²€ìƒ‰ ê²°ê³¼:\")\n",
    "    try:\n",
    "        results = db_manager.db.similarity_search(search_query, k=5)\n",
    "        \n",
    "        for i, result in enumerate(results, 1):\n",
    "            filename = os.path.basename(result.metadata.get('source', 'Unknown'))\n",
    "            page = result.metadata.get('page', 'N/A')\n",
    "            score = result.metadata.get('score', 'N/A')  # ìœ ì‚¬ë„ ì ìˆ˜ (ê°€ëŠ¥í•œ ê²½ìš°)\n",
    "            \n",
    "            print(f\"\\nğŸ“„ ê²°ê³¼ {i}: {filename} (í˜ì´ì§€: {page})\")\n",
    "            print(f\"ë‚´ìš©: {result.page_content[:200]}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}\")\n",
    "else:\n",
    "    print(\"âŒ DBê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ChromaDB ìƒì„¸ ì •ë³´\n",
      "==============================\n",
      "DB ê²½ë¡œ: ./chroma_db\n",
      "ì„ë² ë”© ëª¨ë¸: text-embedding-3-large\n",
      "DB ì¡´ì¬ ì—¬ë¶€: âœ…\n",
      "DB ë¡œë“œ ìƒíƒœ: âœ…\n",
      "ì´ ë¬¸ì„œ ì²­í¬ ìˆ˜: 1,704ê°œ\n",
      "ì €ì¥ëœ íŒŒì¼ ìˆ˜: 2ê°œ\n",
      "\n",
      "ğŸ“‹ ì €ì¥ëœ íŒŒì¼ ëª©ë¡:\n",
      "   1. 2025ë…„ ê°œì •ì„¸ë²• í•´ì„¤ ë‚´ì§€-12êµ.pdf\n",
      "   2. ì†Œë“ì„¸ë²•(ë²•ë¥ )(ì œ20615í˜¸)(20250701).pdf\n"
     ]
    }
   ],
   "source": [
    "# DB ìƒì„¸ ì •ë³´ í™•ì¸\n",
    "print(\"ğŸ“Š ChromaDB ìƒì„¸ ì •ë³´\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "status = db_manager.get_status()\n",
    "files_in_db = db_manager.get_files_in_db()\n",
    "\n",
    "print(f\"DB ê²½ë¡œ: {status['db_path']}\")\n",
    "print(f\"ì„ë² ë”© ëª¨ë¸: {status['embedding_model']}\")\n",
    "print(f\"DB ì¡´ì¬ ì—¬ë¶€: {'âœ…' if status['db_exists'] else 'âŒ'}\")\n",
    "print(f\"DB ë¡œë“œ ìƒíƒœ: {'âœ…' if status['db_loaded'] else 'âŒ'}\")\n",
    "print(f\"ì´ ë¬¸ì„œ ì²­í¬ ìˆ˜: {status['document_count']:,}ê°œ\")\n",
    "print(f\"ì €ì¥ëœ íŒŒì¼ ìˆ˜: {len(files_in_db)}ê°œ\")\n",
    "\n",
    "if files_in_db:\n",
    "    print(\"\\nğŸ“‹ ì €ì¥ëœ íŒŒì¼ ëª©ë¡:\")\n",
    "    for i, filename in enumerate(files_in_db, 1):\n",
    "        print(f\"   {i}. {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ—‘ï¸ DB ê´€ë¦¬ ê¸°ëŠ¥ (ì£¼ì˜í•´ì„œ ì‚¬ìš©)\n",
    "\n",
    "âš ï¸ **ì£¼ì˜**: ì•„ë˜ ê¸°ëŠ¥ë“¤ì€ DBë¥¼ ì‚­ì œí•˜ê±°ë‚˜ ì´ˆê¸°í™”í•©ë‹ˆë‹¤. ì‹ ì¤‘í•˜ê²Œ ì‚¬ìš©í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB ì™„ì „ ì‚­ì œ (ì£¼ì˜: ëª¨ë“  ë°ì´í„°ê°€ ì‚­ì œë©ë‹ˆë‹¤)\n",
    "# ì‹¤ì œ ì‚­ì œë¥¼ ì›í•˜ë©´ ì•„ë˜ ì£¼ì„ì„ í•´ì œí•˜ê³  ì‹¤í–‰í•˜ì„¸ìš”\n",
    "\n",
    "# confirm_delete = input(\"ì •ë§ë¡œ DBë¥¼ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (yes/no): \")\n",
    "# if confirm_delete.lower() == 'yes':\n",
    "#     success = db_manager.delete_db()\n",
    "#     if success:\n",
    "#         print(\"âœ… DBê°€ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "#     else:\n",
    "#         print(\"âŒ DB ì‚­ì œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\")\n",
    "# else:\n",
    "#     print(\"âœ‹ DB ì‚­ì œê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "print(\"ğŸ’¡ DB ì‚­ì œ ê¸°ëŠ¥ì€ ì£¼ì„ ì²˜ë¦¬ë˜ì–´ ìˆìŠµë‹ˆë‹¤. í•„ìš”ì‹œ ì£¼ì„ì„ í•´ì œí•˜ì—¬ ì‚¬ìš©í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š ì‚¬ìš© ê°€ì´ë“œ ë° íŒ\n",
    "\n",
    "### ğŸ”„ ì •ê¸°ì ì¸ ë™ê¸°í™” ì›Œí¬í”Œë¡œìš°:\n",
    "1. **ìƒˆ ë¬¸ì„œ ì¶”ê°€**: `raw_data` í´ë”ì— .txt ë˜ëŠ” .pdf íŒŒì¼ ì¶”ê°€\n",
    "2. **ìƒíƒœ í™•ì¸**: `sync_manager.print_sync_report(db_manager)` ì‹¤í–‰\n",
    "3. **ë™ê¸°í™” ì‹¤í–‰**: `sync_manager.sync_with_db(db_manager)` ì‹¤í–‰\n",
    "4. **ê²€ìƒ‰ í…ŒìŠ¤íŠ¸**: ìƒˆë¡œ ì¶”ê°€ëœ ë¬¸ì„œê°€ ê²€ìƒ‰ë˜ëŠ”ì§€ í™•ì¸\n",
    "\n",
    "### âš™ï¸ ì„¤ì • ì¡°ì •:\n",
    "- **ì²­í¬ í¬ê¸°**: ë¬¸ì„œ ìœ í˜•ì— ë”°ë¼ `CHUNK_SIZE` ì¡°ì • (500-2000 ê¶Œì¥)\n",
    "- **ì²­í¬ ê²¹ì¹¨**: ë¬¸ë§¥ ìœ ì§€ë¥¼ ìœ„í•´ `CHUNK_OVERLAP` ì¡°ì • (100-300 ê¶Œì¥)\n",
    "- **ì„ë² ë”© ëª¨ë¸**: ë¹„ìš©ê³¼ ì„±ëŠ¥ì„ ê³ ë ¤í•˜ì—¬ ëª¨ë¸ ì„ íƒ\n",
    "\n",
    "### ğŸš¨ ì£¼ì˜ì‚¬í•­:\n",
    "- OpenAI API ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ í•„ìš”\n",
    "- ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ ì‹œ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŒ\n",
    "- ì¤‘ìš”í•œ DBëŠ” ì •ê¸°ì ìœ¼ë¡œ ë°±ì—… ê¶Œì¥\n",
    "\n",
    "### ğŸ¯ ìµœì í™” íŒ:\n",
    "- íŒŒì¼ëª…ì— ì˜ë¯¸ ìˆëŠ” ì´ë¦„ ì‚¬ìš©\n",
    "- ê´€ë ¨ ë¬¸ì„œë“¤ì„ í•¨ê»˜ ë°°ì¹˜\n",
    "- ì •ê¸°ì ì¸ ê³ ì•„ íŒŒì¼ ì •ë¦¬\n",
    "- ê²€ìƒ‰ í‚¤ì›Œë“œ ìµœì í™”"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
