import streamlit as st
import os
import shutil
from pathlib import Path
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import koreanize_matplotlib
from datasets import Dataset

# Langchain imports
from langchain_community.document_loaders import TextLoader, PyPDFLoader
from langchain_openai.embeddings import OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import ChatOpenAI
from langchain.chains import create_retrieval_chain
from langchain_core.prompts import ChatPromptTemplate

# RAGAS imports
from ragas.metrics import (
    faithfulness,
    answer_relevancy,
    context_precision,
    context_recall
)
from ragas.evaluation import evaluate

# Load environment variables
from dotenv import load_dotenv
import os

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ì˜ .env íŒŒì¼ ê²½ë¡œ ì„¤ì •
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
env_path = os.path.join(project_root, '.env')

load_dotenv(dotenv_path=env_path, override=True)

# LangSmith ì„¤ì • í™•ì¸
print(f"LangSmith API Key loaded: {'Yes' if os.getenv('LANGSMITH_API_KEY') else 'No'}")
print(f"LangSmith Project: {os.getenv('LANGSMITH_PROJECT', 'Not set')}")

# LangSmith ê°•ì œ ì´ˆê¸°í™” (Streamlit í™˜ê²½ì—ì„œ í•„ìš”)
if os.getenv('LANGSMITH_API_KEY'):
    from langsmith import Client
    try:
        langsmith_client = Client()
        print(f"LangSmith client initialized successfully")
    except Exception as e:
        print(f"LangSmith client initialization failed: {e}")

from typing import List, Dict, Any
from modules.auto_rag.mod import (
    ChromaDBManager,
    RawDataSyncManager,
    RAGSystemManager,
    QuestionGenerationManager,
    EvaluationManager,
    ChatInterfaceManager,
    VisualizationUtils,
    WorkflowStatusManager
)
# LangChain ë„¤ì´í‹°ë¸Œ ìë™ ì¶”ì  ì‚¬ìš©

# Matplotlib í•œê¸€ ë° ìŒìˆ˜ ê¹¨ì§ ë°©ì§€ ì„¤ì •
plt.rcParams['axes.unicode_minus'] = False

# Set page config
st.set_page_config(
    page_title="RAG System with RAGAS Evaluation",
    page_icon="ğŸ¤–",
    layout="wide"
)

# Document loading and splitting function
def load_and_split_document(file_path: str, chunk_size: int = 500, chunk_overlap: int = 100) -> list:
    """íŒŒì¼ì„ ë¡œë“œí•˜ê³  ì²­í¬ë¡œ ë¶„í• """
    try:
        file_extension = Path(file_path).suffix.lower()
        
        # íŒŒì¼ íƒ€ì…ì— ë”°ë¥¸ ë¡œë” ì„ íƒ
        if file_extension == '.txt':
            loader = TextLoader(file_path, encoding='utf-8')
        elif file_extension == '.pdf':
            loader = PyPDFLoader(file_path)
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_extension}")
        
        # í…ìŠ¤íŠ¸ ë¶„í• ê¸° ì„¤ì •
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap
        )
        
        # ë¬¸ì„œ ë¡œë“œ ë° ë¶„í• 
        documents = loader.load_and_split(text_splitter)
        
        return documents
        
    except Exception as e:
        st.error(f"íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ ({os.path.basename(file_path)}): {str(e)}")
        return []


# Initialize session state
if 'db' not in st.session_state:
    st.session_state.db = None
if 'documents' not in st.session_state:
    st.session_state.documents = None
if 'evaluation_results' not in st.session_state:
    st.session_state.evaluation_results = None
if 'generated_questions' not in st.session_state:
    st.session_state.generated_questions = []
if 'edited_questions' not in st.session_state:
    st.session_state.edited_questions = []
if 'chat_messages' not in st.session_state:
    st.session_state.chat_messages = []
if 'db_manager' not in st.session_state:
    st.session_state.db_manager = ChromaDBManager()
if 'sync_manager' not in st.session_state:
    st.session_state.sync_manager = RawDataSyncManager()
if 'rag_manager' not in st.session_state:
    st.session_state.rag_manager = RAGSystemManager()
if 'question_manager' not in st.session_state:
    st.session_state.question_manager = QuestionGenerationManager()
if 'evaluation_manager' not in st.session_state:
    st.session_state.evaluation_manager = EvaluationManager()
if 'chat_interface' not in st.session_state:
    st.session_state.chat_interface = ChatInterfaceManager()
if 'workflow_manager' not in st.session_state:
    st.session_state.workflow_manager = WorkflowStatusManager()

st.title("ğŸ¤– RAG ì‹œìŠ¤í…œ ë° RAGAS í‰ê°€")
st.markdown("---")

# íƒ­ ì´ë¦„
tab1, tab2, tab3, tab4 = st.tabs(["ğŸ”„ Raw Data ë™ê¸°í™”", "ğŸ’¬ RAG í…ŒìŠ¤íŠ¸", "ğŸ“ ì§ˆë¬¸ ìƒì„±í•˜ê¸°", "ğŸ” RAG í‰ê°€í•˜ê¸°"])

with tab1:
    st.header("Raw Data ë™ê¸°í™”")
    
    # ë™ê¸°í™” ê´€ë¦¬ì ê°€ì ¸ì˜¤ê¸°
    sync_manager = st.session_state.sync_manager
    db_manager = st.session_state.db_manager
    
    # VectorDB ìƒíƒœ í‘œì‹œ
    db_status = db_manager.get_status()
    
    st.subheader("ğŸ“ VectorDB ìƒíƒœ")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if db_status["db_exists"]:
            st.success("âœ… VectorDB ì¡´ì¬")
            st.metric("ì €ì¥ëœ ë¬¸ì„œ ìˆ˜", db_status["document_count"])
        else:
            st.warning("âŒ VectorDB ì—†ìŒ")
            st.metric("ì €ì¥ëœ ë¬¸ì„œ ìˆ˜", 0)
    
    with col2:
        st.info(f"ğŸ“‚ ì €ì¥ ê²½ë¡œ: {db_status['db_path']}")
        st.info(f"ğŸ”¤ ì„ë² ë”© ëª¨ë¸: {db_status['embedding_model']}")
    
    with col3:
        if db_status["db_exists"]:
            if st.button("ğŸ—‘ï¸ VectorDB ì‚­ì œ", type="secondary"):
                try:
                    with st.spinner("VectorDBë¥¼ ì‚­ì œí•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                        # ì„¸ì…˜ ë°ì´í„° ì´ˆê¸°í™”
                        st.session_state.documents = None
                        st.session_state.generated_questions = []
                        st.session_state.edited_questions = []
                        st.session_state.evaluation_results = None
                        st.session_state.db = None
                        
                        # DB ì‚­ì œ
                        success = db_manager.delete_db()
                        
                        if success:
                            st.success("âœ… VectorDBê°€ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤!")
                        else:
                            st.error("âŒ VectorDB ì‚­ì œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                            
                        st.rerun()
                        
                except Exception as e:
                    st.error(f"VectorDB ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    st.markdown("---")
    
    st.subheader("ğŸ“Š ë™ê¸°í™” ìƒíƒœ")
    
    # ë™ê¸°í™” ìƒíƒœ í™•ì¸
    if st.button("ğŸ”„ ë™ê¸°í™” ìƒíƒœ í™•ì¸"):
        sync_status = sync_manager.compare_with_db(db_manager)
        raw_files_info = sync_manager.scan_raw_data_folder()
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("ğŸ“ **Raw Data í´ë” ìƒíƒœ**")
            st.write(f"- ê²½ë¡œ: {sync_manager.raw_data_path}")
            st.write(f"- ì´ íŒŒì¼ ìˆ˜: {len(raw_files_info)}ê°œ")
            
            if raw_files_info:
                total_size_mb = sum(info['size_mb'] for info in raw_files_info)
                st.write(f"- ì´ íŒŒì¼ í¬ê¸°: {total_size_mb:.2f} MB")
                
                # íŒŒì¼ ëª©ë¡ í‘œì‹œ
                st.write("**íŒŒì¼ ëª©ë¡:**")
                for file_info in raw_files_info:
                    st.write(f"  - {file_info['filename']} ({file_info['size_mb']:.2f} MB)")
        
        with col2:
            st.write("ğŸ—„ï¸ **ChromaDB ìƒíƒœ**")
            db_status = db_manager.get_status()
            st.write(f"- DB ì¡´ì¬: {'âœ…' if db_status['db_exists'] else 'âŒ'}")
            st.write(f"- ì´ ë¬¸ì„œ ìˆ˜: {db_status['document_count']}ê°œ")
            st.write(f"- ì €ì¥ëœ íŒŒì¼ ìˆ˜: {len(sync_status['all_db_files'])}ê°œ")
            
            # ë™ê¸°í™” ìƒíƒœ
            st.write("**ë™ê¸°í™” ìƒíƒœ:**")
            st.write(f"- ìƒˆ íŒŒì¼: {len(sync_status['new_files'])}ê°œ")
            st.write(f"- ë™ê¸°í™”ë¨: {len(sync_status['existing_files'])}ê°œ")
            st.write(f"- ê³ ì•„ íŒŒì¼: {len(sync_status['orphaned_files'])}ê°œ")
            
            # ìƒì„¸ ì •ë³´
            if sync_status['new_files']:
                st.write("**ì¶”ê°€í•  ìƒˆ íŒŒì¼:**")
                for filename in sync_status['new_files']:
                    st.write(f"  - {filename}")
            
            if sync_status['orphaned_files']:
                st.write("**ê³ ì•„ íŒŒì¼ (raw_dataì— ì—†ìŒ):**")
                for filename in sync_status['orphaned_files']:
                    st.write(f"  - {filename}")
    
    st.markdown("---")
    
    # ë™ê¸°í™” ì„¤ì •
    st.subheader("âš™ï¸ ë™ê¸°í™” ì„¤ì •")
    
    col1, col2 = st.columns(2)
    
    with col1:
        sync_chunk_size = st.slider("ì²­í¬ í¬ê¸°", min_value=100, max_value=2000, value=500, step=50, key="sync_chunk_size")
    
    with col2:
        sync_chunk_overlap = st.slider("ì²­í¬ ì¤‘ì²©", min_value=0, max_value=500, value=100, step=25, key="sync_chunk_overlap")
    
    # ë™ê¸°í™” ì‹¤í–‰
    if st.button("ğŸš€ ë™ê¸°í™” ì‹¤í–‰", type="primary"):
        # Update workflow status to in_progress
        workflow_manager = st.session_state.workflow_manager
        workflow_manager.update_step_status("embedding", "in_progress", 0)
        
        with st.spinner("ë™ê¸°í™”ë¥¼ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤..."):
            # Check sync status first
            sync_status = sync_manager.compare_with_db(db_manager)
            new_files_count = len(sync_status['new_files'])
            
            workflow_manager.update_step_status("embedding", "in_progress", 25, {
                "new_files": new_files_count,
                "document_count": db_manager.get_document_count()
            })
            
            success = sync_manager.sync_with_db(
                db_manager=db_manager,
                chunk_size=sync_chunk_size,
                chunk_overlap=sync_chunk_overlap
            )
            
            if success:
                # ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
                st.session_state.db = db_manager.db
                final_doc_count = db_manager.get_document_count()
                
                # Update workflow status to completed
                workflow_manager.update_step_status("embedding", "completed", 100, {
                    "document_count": final_doc_count,
                    "new_files": new_files_count
                })
                
                st.rerun()
            else:
                # Update workflow status to error
                workflow_manager.update_step_status("embedding", "error", 0, error="ë™ê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                st.error("ë™ê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    
    # ì¶”ê°€ ì •ë³´
    st.info("ğŸ’¡ **ì‚¬ìš©ë²•:** raw_data í´ë”ì— .txt ë˜ëŠ” .pdf íŒŒì¼ì„ ì¶”ê°€í•œ í›„ ë™ê¸°í™”ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
    st.info(f"ğŸ“‚ **Raw Data í´ë” ê²½ë¡œ:** {sync_manager.raw_data_path}")
    
    # ê¸°ì¡´ DB ê´€ë¦¬ ê¸°ëŠ¥
    if db_status["db_exists"]:
        st.markdown("---")
        st.subheader("ğŸ“‹ VectorDB ê´€ë¦¬")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if not db_status["db_loaded"]:
                if st.button("ğŸ“¥ ê¸°ì¡´ VectorDB ë¡œë“œ", type="primary"):
                    try:
                        with st.spinner("ê¸°ì¡´ VectorDBë¥¼ ë¡œë“œ ì¤‘ì…ë‹ˆë‹¤..."):
                            success = db_manager.load_existing_db()
                            
                            if success:
                                st.session_state.db = db_manager.db
                                st.success(f"ê¸°ì¡´ VectorDBë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤! (ë¬¸ì„œ ìˆ˜: {db_status['document_count']})")
                                st.rerun()
                            
                    except Exception as e:
                        st.error(f"VectorDB ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        
        with col2:
            if st.button("ğŸ“‹ ì €ì¥ëœ ë¬¸ì„œ ëª©ë¡ ë³´ê¸°"):
                with st.spinner("ë¬¸ì„œ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                    files_in_db = db_manager.get_files_in_db()
                    
                    if files_in_db:
                        st.subheader("ğŸ“š ì €ì¥ëœ íŒŒì¼ ëª©ë¡")
                        st.write(f"ì´ {len(files_in_db)}ê°œì˜ íŒŒì¼ì´ ì €ì¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
                        st.write(f"ì´ ë¬¸ì„œ ì²­í¬ ìˆ˜: {db_status['document_count']}ê°œ")
                        
                        # íŒŒì¼ ëª©ë¡ í‘œì‹œ
                        for i, filename in enumerate(files_in_db, 1):
                            st.write(f"{i}. {filename}")
                    else:
                        st.warning("ì €ì¥ëœ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

with tab2:
    st.header("RAG í…ŒìŠ¤íŠ¸")
    
    if st.session_state.db is None:
        st.warning("ë¨¼ì € 'Raw Data ë™ê¸°í™”' íƒ­ì—ì„œ ë¬¸ì„œë¥¼ ë™ê¸°í™”í•´ ì£¼ì„¸ìš”.")
    else:
        # RAG Configuration
        st.subheader("RAG ì„¤ì •")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            chat_model = st.selectbox(
                "Answer Model",
                ["gpt-3.5-turbo", "gpt-4o-mini", "gpt-4o", "gpt-4-turbo"],
                index=0,
                key="chat_model"
            )
        
        with col2:
            chat_temperature = st.slider("ë‹µë³€ ìƒì„± ì˜¨ë„", min_value=0.0, max_value=1.0, value=0.0, step=0.1, key="chat_temp")
        
        with col3:
            search_k = st.slider("ê²€ìƒ‰í•  ë¬¸ì„œ ê°œìˆ˜", min_value=1, max_value=10, value=3, key="chat_k")
        
        # RAG ë§¤ë‹ˆì € ì„¤ì •
        rag_manager = st.session_state.rag_manager
        rag_manager.set_llm(chat_model, chat_temperature)
        rag_manager.set_retriever(st.session_state.db, "similarity", {"k": search_k})
        
        # ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ ë§¤ë‹ˆì €
        chat_interface = st.session_state.chat_interface
        
        # Clear chat button and LangSmith dashboard
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™”"):
                chat_interface.clear_messages()
                st.rerun()
        
        with col2:
            # LangSmith dashboard link
            langsmith_project = os.getenv("LANGSMITH_PROJECT", "rag_lab_project")
            langsmith_url = f"https://smith.langchain.com/projects/{langsmith_project}"
            st.markdown(f"[ğŸ” LangSmith ëŒ€ì‹œë³´ë“œ ì—´ê¸°]({langsmith_url})", unsafe_allow_html=True)
        
        # Display chat messages
        st.subheader("ì±„íŒ…")
        
        # Chat container
        chat_container = st.container()
        
        with chat_container:
            chat_interface.display_messages()
        
        # Chat input
        user_question = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...")
        
        if user_question:
            # Add user message to chat
            chat_interface.add_message("user", user_question)
            
            try:
                with st.spinner("ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                    # Get answer using RAG manager (LangChain ìë™ ì¶”ì )
                    answer, contexts = rag_manager.get_answer(user_question)
                    
                    # Add assistant message to chat
                    chat_interface.add_message("assistant", answer, contexts)
                    
                    st.rerun()
                    
            except Exception as e:
                st.error(f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                # Add error message to chat
                chat_interface.add_message("assistant", f"ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

with tab3:
    st.header("ì§ˆë¬¸ ìƒì„±í•˜ê¸°")
    
    if st.session_state.db is None:
        st.warning("ë¨¼ì € 'Raw Data ë™ê¸°í™”' íƒ­ì—ì„œ ë¬¸ì„œë¥¼ ë™ê¸°í™”í•´ ì£¼ì„¸ìš”.")
    else:
        # LLM configuration for question generation
        st.subheader("LLM ì„¤ì •")
        
        col1, col2 = st.columns(2)
        
        with col1:
            question_model = st.selectbox(
                "Question Generation Model",
                ["gpt-4o-mini", "gpt-3.5-turbo", "gpt-4o", "gpt-4-turbo"],
                index=0
            )
        
        with col2:
            question_temperature = st.slider("ì§ˆë¬¸ ìƒì„± ì˜¨ë„", min_value=0.0, max_value=1.0, value=0.9, step=0.1)
        
        # Number of questions
        num_questions = st.slider("ìƒì„±í•  ì§ˆë¬¸ ê°œìˆ˜", min_value=1, max_value=10, value=5)
        
        # ì§ˆë¬¸ ìƒì„± ë§¤ë‹ˆì € ì„¤ì •
        question_manager = st.session_state.question_manager
        question_manager.set_llm(question_model, question_temperature)
        
        # Generate questions
        if st.button("ì§ˆë¬¸ ìƒì„±", type="primary"):
            try:
                # Update workflow status to in_progress
                workflow_manager = st.session_state.workflow_manager
                workflow_manager.update_step_status("question_generation", "in_progress", 0)
                
                with st.spinner("ì§ˆë¬¸ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                    if st.session_state.db is None:
                        workflow_manager.update_step_status("question_generation", "error", 0, 
                                                          error="DBê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € ë™ê¸°í™”ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
                        st.error("DBê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € ë™ê¸°í™”ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
                    else:
                        # Update progress
                        workflow_manager.update_step_status("question_generation", "in_progress", 25, {
                            "model_used": question_model,
                            "target_count": num_questions
                        })
                        
                        # Generate questions using manager
                        questions = question_manager.generate_questions(st.session_state.db, num_questions)
                        
                        # Store generated questions
                        st.session_state.generated_questions = questions
                        st.session_state.edited_questions = questions.copy()
                        
                        # Update workflow status to completed
                        workflow_manager.update_step_status("question_generation", "completed", 100, {
                            "question_count": len(questions),
                            "model_used": question_model
                        })
                        
                        st.success(f"{len(questions)}ê°œì˜ ì§ˆë¬¸ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    
            except Exception as e:
                workflow_manager.update_step_status("question_generation", "error", 0, 
                                                  error=str(e))
                st.error(f"ì§ˆë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        
        # Display and edit questions
        if st.session_state.generated_questions:
            st.subheader("ìƒì„±ëœ ì§ˆë¬¸ ìˆ˜ì •")
            st.write("ì•„ë˜ì—ì„œ ì§ˆë¬¸ì„ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:")
            
            # Edit questions
            for i, question in enumerate(st.session_state.generated_questions):
                edited_question = st.text_area(
                    f"ì§ˆë¬¸ {i+1}",
                    value=st.session_state.edited_questions[i] if i < len(st.session_state.edited_questions) else question,
                    key=f"question_{i}"
                )
                
                # Update edited questions in session state
                if len(st.session_state.edited_questions) <= i:
                    st.session_state.edited_questions.append(edited_question)
                else:
                    st.session_state.edited_questions[i] = edited_question
            
            # Add/Remove questions
            col1, col2 = st.columns(2)
            
            with col1:
                if st.button("ì§ˆë¬¸ ì¶”ê°€"):
                    question_manager.add_question("ìƒˆë¡œìš´ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")
                    st.session_state.generated_questions = question_manager.get_questions()
                    st.session_state.edited_questions = question_manager.get_questions()
                    st.rerun()
            
            with col2:
                if st.button("ë§ˆì§€ë§‰ ì§ˆë¬¸ ì‚­ì œ") and len(st.session_state.generated_questions) > 1:
                    question_manager.remove_question(len(question_manager.get_questions()) - 1)
                    st.session_state.generated_questions = question_manager.get_questions()
                    st.session_state.edited_questions = question_manager.get_questions()
                    st.rerun()
            
            # Display final questions
            st.subheader("ìµœì¢… ì§ˆë¬¸ ëª©ë¡")
            for i, question in enumerate(st.session_state.edited_questions):
                st.write(f"{i+1}. {question}")

with tab4:
    st.header("RAG í‰ê°€í•˜ê¸°")
    
    if st.session_state.db is None:
        st.warning("ë¨¼ì € 'Raw Data ë™ê¸°í™”' íƒ­ì—ì„œ ë¬¸ì„œë¥¼ ë™ê¸°í™”í•´ ì£¼ì„¸ìš”.")
    elif not st.session_state.edited_questions:
        st.warning("ë¨¼ì € 'ì§ˆë¬¸ ìƒì„±í•˜ê¸°' íƒ­ì—ì„œ ì§ˆë¬¸ì„ ìƒì„±í•´ ì£¼ì„¸ìš”.")
    else:
        # Retriever configuration
        st.subheader("ê²€ìƒ‰ê¸° ì„¤ì •")
        
        col1, col2 = st.columns(2)
        
        with col1:
            search_type = st.selectbox(
                "Search Type",
                ["mmr", "similarity", "similarity_score_threshold"],
                index=0
            )
        
        with col2:
            k = st.slider("ê²€ìƒ‰í•  ë¬¸ì„œ ê°œìˆ˜ (k)", min_value=1, max_value=20, value=5)
        
        # Additional parameters based on search type
        if search_type == "mmr":
            col1, col2 = st.columns(2)
            with col1:
                lambda_mult = st.slider("ëŒë‹¤ ê°€ì¤‘ì¹˜", min_value=0.0, max_value=1.0, value=0.25, step=0.05)
            with col2:
                fetch_k = st.slider("Fetch K (ê²€ìƒ‰ í›„ë³´ ìˆ˜)", min_value=k, max_value=50, value=10)
            
            search_kwargs = {"k": k, "lambda_mult": lambda_mult, "fetch_k": fetch_k}
        
        elif search_type == "similarity_score_threshold":
            score_threshold = st.slider("ì ìˆ˜ ì„ê³„ê°’", min_value=-1.0, max_value=1.0, value=0.5, step=0.1)
            search_kwargs = {"k": k, "score_threshold": score_threshold}
        
        else:
            search_kwargs = {"k": k}
        
        # LLM configuration
        st.subheader("LLM ì„¤ì •")
        
        answer_model = st.selectbox(
            "Answer Generation Model",
            ["gpt-3.5-turbo", "gpt-4o-mini", "gpt-4o", "gpt-4-turbo"],
            index=0
        )
        answer_temperature = st.slider("ë‹µë³€ ìƒì„± ì˜¨ë„", min_value=0.0, max_value=1.0, value=0.0, step=0.1)
        
        # RAGAS metrics selection
        st.subheader("RAGAS í‰ê°€ ì§€í‘œ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            use_faithfulness = st.checkbox("ì •í™•ì„±(Faithfulness)", value=True)
            use_answer_relevancy = st.checkbox("ë‹µë³€ ê´€ë ¨ì„±(Answer Relevancy)", value=True)
        
        with col2:
            use_context_precision = st.checkbox("ë¬¸ë§¥ ì •ë°€ë„(Context Precision)", value=True)
            use_context_recall = st.checkbox("ë¬¸ë§¥ ì¬í˜„ìœ¨(Context Recall)", value=True)
        
        # Display questions to be evaluated
        st.subheader("í‰ê°€í•  ì§ˆë¬¸ ëª©ë¡")
        for i, question in enumerate(st.session_state.edited_questions):
            st.write(f"{i+1}. {question}")
        
        # í‰ê°€ ë§¤ë‹ˆì € ì„¤ì •
        evaluation_manager = st.session_state.evaluation_manager
        rag_manager = st.session_state.rag_manager
        
        # RAG ë§¤ë‹ˆì € ì„¤ì •
        rag_manager.set_llm(answer_model, answer_temperature)
        rag_manager.set_retriever(st.session_state.db, search_type, search_kwargs)
        
        # Evaluate questions
        if st.button("RAG í‰ê°€ ì‹¤í–‰", type="primary"):
            try:
                # Update workflow status to in_progress
                workflow_manager = st.session_state.workflow_manager
                workflow_manager.update_step_status("evaluation", "in_progress", 0)
                
                with st.spinner("ì§ˆë¬¸ì„ í‰ê°€ ì¤‘ì…ë‹ˆë‹¤..."):
                    st.write("RAGASë¡œ í‰ê°€ ì¤‘...")
                    
                    # Update progress
                    workflow_manager.update_step_status("evaluation", "in_progress", 10, {
                        "total_questions": len(st.session_state.edited_questions),
                        "model_used": answer_model
                    })
                    
                    # í‰ê°€ ë©”íŠ¸ë¦­ ì„¤ì •
                    metrics_config = {
                        'use_faithfulness': use_faithfulness,
                        'use_answer_relevancy': use_answer_relevancy,
                        'use_context_precision': use_context_precision,
                        'use_context_recall': use_context_recall
                    }
                    
                    # Progress update
                    workflow_manager.update_step_status("evaluation", "in_progress", 30)
                    
                    # í‰ê°€ ì‹¤í–‰
                    results_df = evaluation_manager.evaluate_rag_system(
                        st.session_state.edited_questions,
                        st.session_state.db,
                        rag_manager,
                        metrics_config
                    )
                    
                    # Store results
                    st.session_state.evaluation_results = results_df
                    
                    # Get average scores for workflow status
                    avg_scores = evaluation_manager.get_average_scores()
                    
                    # Update workflow status to completed
                    workflow_manager.update_step_status("evaluation", "completed", 100, {
                        "total_questions": len(st.session_state.edited_questions),
                        "model_used": answer_model,
                        "average_scores": avg_scores
                    })
                    
                    st.success("í‰ê°€ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                    
            except Exception as e:
                workflow_manager.update_step_status("evaluation", "error", 0, 
                                                  error=str(e))
                st.error(f"í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        
        # Display results
        if st.session_state.evaluation_results is not None:
            st.subheader("í‰ê°€ ê²°ê³¼")
            
            results_df = st.session_state.evaluation_results
            
            # Display dataframe
            st.dataframe(results_df)
            
            # Calculate and display average scores
            avg_scores = evaluation_manager.get_average_scores()
            
            if avg_scores:
                st.subheader("í‰ê·  ì ìˆ˜")
                col1, col2 = st.columns(2)
                
                avg_scores_items = list(avg_scores.items())
                with col1:
                    for i, (metric, score) in enumerate(avg_scores_items):
                        if i < len(avg_scores_items) // 2 + len(avg_scores_items) % 2:
                            st.metric(metric.replace("_", " ").title(), f"{score:.3f}")
                
                with col2:
                    for i, (metric, score) in enumerate(avg_scores_items):
                        if i >= len(avg_scores_items) // 2 + len(avg_scores_items) % 2:
                            st.metric(metric.replace("_", " ").title(), f"{score:.3f}")
                
                # Visualizations
                st.subheader("Visualizations")
                
                # Bar chart for each metric
                metric_columns = [col for col in results_df.columns if col not in ["question", "answer"]]
                for metric in metric_columns:
                    fig = VisualizationUtils.create_metric_bar_chart(results_df, metric)
                    st.pyplot(fig)
                
                # Radar chart for average scores
                radar_fig = VisualizationUtils.create_radar_chart(avg_scores)
                if radar_fig:
                    st.pyplot(radar_fig)
            
            # Q&A Display
            st.subheader("ì§ˆë¬¸ê³¼ ë‹µë³€")
            for i, row in results_df.iterrows():
                with st.expander(f"Q{i+1}: {row['question']}"):
                    st.write("**ë‹µë³€:**")
                    st.write(row['answer'])
                    
                    if avg_scores:
                        st.write("**ì ìˆ˜:**")
                        for metric in avg_scores.keys():
                            if metric in row:
                                st.write(f"- {metric.replace('_', ' ').title()}: {row[metric]:.3f}")

# Workflow Status Sidebar
def display_workflow_sidebar():
    """Display workflow status in sidebar"""
    workflow_manager = st.session_state.workflow_manager
    
    st.sidebar.title("ğŸ”„ RAG Workflow Status")
    st.sidebar.markdown("---")
    
    # Overall progress
    overall_progress = workflow_manager.get_overall_progress()
    st.sidebar.progress(overall_progress / 100)
    st.sidebar.text(f"Overall Progress: {overall_progress:.1f}%")
    
    # Current status
    workflow_status = workflow_manager.get_workflow_status()
    status_emoji = {"pending": "â³", "in_progress": "ğŸ”„", "completed": "âœ…"}.get(workflow_status, "â“")
    st.sidebar.text(f"Status: {status_emoji} {workflow_status.title()}")
    
    st.sidebar.markdown("---")
    
    # Individual steps
    st.sidebar.subheader("ğŸ“‹ Workflow Steps")
    
    # Step 1: Document Embedding
    embedding_info = workflow_manager.get_step_display_info("embedding")
    with st.sidebar.expander(f"{embedding_info['emoji']} Document Embedding", expanded=True):
        st.text(f"Status: {embedding_info['status'].title()}")
        if embedding_info['progress'] > 0:
            st.progress(embedding_info['progress'] / 100)
        st.text(f"Updated: {embedding_info['last_updated']}")
        
        if embedding_info['details']:
            if 'document_count' in embedding_info['details']:
                st.text(f"Documents: {embedding_info['details']['document_count']}")
            if 'new_files' in embedding_info['details']:
                st.text(f"New files: {embedding_info['details']['new_files']}")
        
        if embedding_info['error']:
            st.error(f"Error: {embedding_info['error']}")
    
    # Step 2: Question Generation
    question_info = workflow_manager.get_step_display_info("question_generation")
    with st.sidebar.expander(f"{question_info['emoji']} Question Generation"):
        st.text(f"Status: {question_info['status'].title()}")
        if question_info['progress'] > 0:
            st.progress(question_info['progress'] / 100)
        st.text(f"Updated: {question_info['last_updated']}")
        
        if question_info['details']:
            if 'question_count' in question_info['details']:
                st.text(f"Questions: {question_info['details']['question_count']}")
            if 'model_used' in question_info['details']:
                st.text(f"Model: {question_info['details']['model_used']}")
        
        if question_info['error']:
            st.error(f"Error: {question_info['error']}")
    
    # Step 3: Question Evaluation
    evaluation_info = workflow_manager.get_step_display_info("evaluation")
    with st.sidebar.expander(f"{evaluation_info['emoji']} Question Evaluation"):
        st.text(f"Status: {evaluation_info['status'].title()}")
        if evaluation_info['progress'] > 0:
            st.progress(evaluation_info['progress'] / 100)
        st.text(f"Updated: {evaluation_info['last_updated']}")
        
        if evaluation_info['details']:
            if 'average_scores' in evaluation_info['details']:
                st.text("Average Scores:")
                for metric, score in evaluation_info['details']['average_scores'].items():
                    st.text(f"  {metric}: {score:.3f}")
        
        if evaluation_info['error']:
            st.error(f"Error: {evaluation_info['error']}")
    
    st.sidebar.markdown("---")
    
    # Quick Actions
    st.sidebar.subheader("ğŸš€ Quick Actions")
    
    # Next step suggestion
    next_step = workflow_manager.get_next_step()
    if next_step:
        step_names = {
            "embedding": "Document Sync",
            "question_generation": "Question Generation", 
            "evaluation": "Evaluation"
        }
        st.sidebar.info(f"Next: {step_names.get(next_step, next_step)}")
    
    # Reset workflow button
    if st.sidebar.button("ğŸ”„ Reset Workflow"):
        workflow_manager.reset_workflow()
        st.rerun()
    
    # Workflow completion celebration
    if workflow_manager.workflow_completed:
        st.sidebar.success("ğŸ‰ Workflow Completed!")
        completion_time = workflow_manager.completion_time
        start_time = workflow_manager.start_time
        if completion_time and start_time:
            duration = completion_time - start_time
            st.sidebar.text(f"Duration: {duration:.1f} seconds")

# Display sidebar
display_workflow_sidebar()