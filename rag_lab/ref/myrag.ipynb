{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 RAG\n",
    "\n",
    "* 인덱싱\n",
    "  데이터 로딩\n",
    "\n",
    "  데이터를 작은 단위의 청크로 나눔\n",
    "\n",
    "  임베딩 > 수치화 > 3차원 배열 속 저장\n",
    "\n",
    "  임베딩 > 벡터 DB\n",
    "\n",
    "* 검색 & 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(dotenv_path='../.env', override=True)\n",
    "\n",
    "api = os.getenv(\"API2\")\n",
    "default_model = os.getenv(\"OPENAI_DEFAULT_MODEL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doucument Loader\n",
    "\n",
    "파일\n",
    "* TextLoader\n",
    "| 일반 텍스트 파일(.txt) 읽기\n",
    "* PDFPlumberLoader / PyPDFLoader\n",
    "| PDF 문서 불러오기\n",
    "* UnstructuredFileLoader\n",
    "| 다양한 파일 포맷 (Word, PPT, PDF 등)을 구조 없이 불러오기\n",
    "* CSVLoader\n",
    "| CSV 파일의 각 행을 문서로 변환\n",
    "* JSONLoader\n",
    "| JSON 파일을 읽고 문서로 구성\n",
    "\n",
    "\n",
    "웹/URL\n",
    "* WebBaseLoader\n",
    "| 일반 웹 페이지 크롤링\n",
    "* SitemapLoader\n",
    "| 사이트맵 기반으로 다수의 웹 페이지 로딩\n",
    "\n",
    "\n",
    "문서 플랫폼\n",
    "* NotionDBLoader\n",
    "| Notion의 DB에서 문서 불러오기 (API 필요)\n",
    "* ConfluenceLoader\n",
    "| Atlassian Confluence 문서 불러오기\n",
    "\n",
    "\n",
    "클라우드 문서\n",
    "* GoogleDriveLoader\n",
    "| 구글 드라이브에서 문서 불러오기\n",
    "* OneDriveLoader\n",
    "| 마이크로소프트 OneDrive에서 불러오기\n",
    "\n",
    "\n",
    "코드/로컬\n",
    "* GitLoader\n",
    "| Git 저장소 내 파일 불러오기\n",
    "* DirectoryLoader\n",
    "| 특정 폴더 내 모든 문서 일괄 불러오기\n",
    "\n",
    "\n",
    "메일\n",
    "* OutlookMessageLoader\n",
    "| Outlook .msg 파일 불러오기\n",
    "* EmailLoader\n",
    "| EML 또는 MIME 형식 이메일 로드\n",
    "\n",
    "\n",
    "이미지/스캔\n",
    "* UnstructuredImageLoader\n",
    "| 이미지에서 텍스트 추출 (OCR 기반)\n",
    "* UnstructuredPDFLoader\n",
    "| PDF 전처리 고급"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//////////////////////////////////\n",
    "#### 텍스트 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': '..\\\\data\\\\data.txt'}, page_content='프랑스의 수도는 파리이다. 파리는 유럽에서 가장 인기 있는 관광 도시 중 하나로, 에펠탑과 루브르 박물관이 유명하다.\\n\\n독일의 수도는 베를린이다. 베를린은 역사적으로 중요한 도시이며, 베를린 장벽으로 유명하다.\\n\\n일본의 수도는 도쿄이다. 도쿄는 기술과 문화의 중심지로, 애니메이션과 음식 문화가 발달해 있다.')]\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import TextLoader, PDFPlumberLoader, WebBaseLoader\n",
    "\n",
    "# 텍스트 파일\n",
    "text_loader = TextLoader(\"..\\\\data\\\\data.txt\", encoding=\"utf-8\")\n",
    "docs_text = text_loader.load()\n",
    "print(docs_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 청크로 나누기\n",
    "\n",
    "청크 사이즈는 RAG의 성능을 결정하는 하이퍼파라미터가 됨 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[Document(metadata={'source': '..\\\\data\\\\data.txt'}, page_content='프랑스의 수도는 파리이다. 파리는 유럽에서 가장 인기 있는 관광 도시 중 하나로, 에펠탑과 루브르 박물관이 유명하다.'), Document(metadata={'source': '..\\\\data\\\\data.txt'}, page_content='독일의 수도는 베를린이다. 베를린은 역사적으로 중요한 도시이며, 베를린 장벽으로 유명하다.'), Document(metadata={'source': '..\\\\data\\\\data.txt'}, page_content='일본의 수도는 도쿄이다. 도쿄는 기술과 문화의 중심지로, 애니메이션과 음식 문화가 발달해 있다.')]\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=5)\n",
    "\n",
    "docs =text_splitter.split_documents(docs_text)\n",
    "print(len(docs))\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 임베딩\n",
    "\n",
    "* openai 임베딩에 사용 가능한 모델\n",
    "\n",
    "  * text-embedding-3-small\n",
    "  * text-embedding-3-large\n",
    "  * text-embedding-ada-002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'api' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAIEmbeddings\n\u001b[1;32m----> 3\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m OpenAIEmbeddings(api_key\u001b[38;5;241m=\u001b[39m\u001b[43mapi\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'api' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(api_key=api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m ex_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m프랑스의 수도는 파리이다. 파리는 유럽에서 가장 인기 있는 관광 도시 중 하나로, 에펠탑과 루브르 박물관이 유명하다.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m vector \u001b[38;5;241m=\u001b[39m \u001b[43membeddings\u001b[49m\u001b[38;5;241m.\u001b[39membed_query(ex_text)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "ex_text = \"프랑스의 수도는 파리이다. 파리는 유럽에서 가장 인기 있는 관광 도시 중 하나로, 에펠탑과 루브르 박물관이 유명하다.\"\n",
    "vector = embeddings.embed_query(ex_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m doc_texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdocs\u001b[49m]\n\u001b[0;32m      3\u001b[0m vectors \u001b[38;5;241m=\u001b[39m embeddings\u001b[38;5;241m.\u001b[39membed_documents(doc_texts)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'docs' is not defined"
     ]
    }
   ],
   "source": [
    "doc_texts = [doc.page_content for doc in docs]\n",
    "\n",
    "vectors = embeddings.embed_documents(doc_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChromaDB 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JS\\AppData\\Local\\Temp\\ipykernel_21856\\503007652.py:8: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectorstore.persist()\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"..\\\\chroma_db\"\n",
    ")\n",
    "vectorstore.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval & LLM 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JS\\AppData\\Local\\Temp\\ipykernel_21856\\22402204.py:5: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(api_key=api,\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "llm = ChatOpenAI(api_key=api,\n",
    "                 model=default_model,\n",
    "                 temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 질문하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "프랑스의 수도는 파리입니다.\n"
     ]
    }
   ],
   "source": [
    "query = \"프랑스의 수도는 무엇인가요?\"\n",
    "result = qa_chain.run(query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 프롬프트를 함께 제공하는 법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JS\\AppData\\Local\\Temp\\ipykernel_21856\\3092354485.py:3: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  ret = retriever.get_relevant_documents(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "죄송하지만, 제공된 정보에는 영국의 수도에 대한 내용이 없습니다.\n"
     ]
    }
   ],
   "source": [
    "query = \"영국의 수도는 무엇인가요?\"\n",
    "\n",
    "ret = retriever.get_relevant_documents(query)\n",
    "\n",
    "if not ret:\n",
    "    print(\"검색 결과가 없습니다.\")\n",
    "else:\n",
    "    result = qa_chain.run(query)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "custom_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"\n",
    "    너는 주어진 context(문서)에서만 답변해야 해. 만약 context가 비어 있거나, \n",
    "    context에 답이 없으면 반드시 \"그런 내용 없습니다.\"라고 답해.\n",
    "    Context: {context} \n",
    "    Question: {question}\n",
    "    답변:\"\"\"\n",
    ")\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, \n",
    "                                       retriever=retriever,\n",
    "                                       chain_type_kwargs={\"prompt\": custom_prompt},\n",
    "                                       return_source_documents=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "그런 내용 없습니다.\n"
     ]
    }
   ],
   "source": [
    "query = \"영국의 수도는 무엇인가요?\"\n",
    "result = qa_chain.run(query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"안녕하세요? 반갑습니다.\"\n",
    "\n",
    "sentence2 = \"안녕하세요? 반갑습니다!\"\n",
    "\n",
    "sentence3 = \"안녕하세요? 만나서 반가워요.\"\n",
    "\n",
    "sentence4 = \"Hi, nice to meet you.\"\n",
    "\n",
    "sentence5 = \"I like to eat apples.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장 쌍별 코사인 유사도:\n",
      "[1] \"안녕하세요? 반갑습니다.\" <-> [2] \"안녕하세요? 반갑습니다!\" : 0.9881\n",
      "[1] \"안녕하세요? 반갑습니다.\" <-> [3] \"안녕하세요? 만나서 반가워요.\" : 0.9463\n",
      "[1] \"안녕하세요? 반갑습니다.\" <-> [4] \"Hi, nice to meet you.\" : 0.8448\n",
      "[1] \"안녕하세요? 반갑습니다.\" <-> [5] \"I like to eat apples.\" : 0.7296\n",
      "[1] \"안녕하세요? 반갑습니다.\" <-> [6] \"아침 못먹었어요\" : 0.8169\n",
      "[1] \"안녕하세요? 반갑습니다.\" <-> [7] \"吃羊肉串的时候, 我超喜欢喝啤酒\" : 0.7213\n",
      "[1] \"안녕하세요? 반갑습니다.\" <-> [8] \"Abi in malam crucem!\" : 0.7151\n",
      "[1] \"안녕하세요? 반갑습니다.\" <-> [9] \"ちょっとまって\" : 0.7575\n",
      "[1] \"안녕하세요? 반갑습니다.\" <-> [10] \"你好\" : 0.8256\n",
      "[2] \"안녕하세요? 반갑습니다!\" <-> [3] \"안녕하세요? 만나서 반가워요.\" : 0.9379\n",
      "[2] \"안녕하세요? 반갑습니다!\" <-> [4] \"Hi, nice to meet you.\" : 0.8360\n",
      "[2] \"안녕하세요? 반갑습니다!\" <-> [5] \"I like to eat apples.\" : 0.7266\n",
      "[2] \"안녕하세요? 반갑습니다!\" <-> [6] \"아침 못먹었어요\" : 0.8118\n",
      "[2] \"안녕하세요? 반갑습니다!\" <-> [7] \"吃羊肉串的时候, 我超喜欢喝啤酒\" : 0.7183\n",
      "[2] \"안녕하세요? 반갑습니다!\" <-> [8] \"Abi in malam crucem!\" : 0.7315\n",
      "[2] \"안녕하세요? 반갑습니다!\" <-> [9] \"ちょっとまって\" : 0.7539\n",
      "[2] \"안녕하세요? 반갑습니다!\" <-> [10] \"你好\" : 0.8238\n",
      "[3] \"안녕하세요? 만나서 반가워요.\" <-> [4] \"Hi, nice to meet you.\" : 0.8372\n",
      "[3] \"안녕하세요? 만나서 반가워요.\" <-> [5] \"I like to eat apples.\" : 0.7126\n",
      "[3] \"안녕하세요? 만나서 반가워요.\" <-> [6] \"아침 못먹었어요\" : 0.8157\n",
      "[3] \"안녕하세요? 만나서 반가워요.\" <-> [7] \"吃羊肉串的时候, 我超喜欢喝啤酒\" : 0.7053\n",
      "[3] \"안녕하세요? 만나서 반가워요.\" <-> [8] \"Abi in malam crucem!\" : 0.7098\n",
      "[3] \"안녕하세요? 만나서 반가워요.\" <-> [9] \"ちょっとまって\" : 0.7559\n",
      "[3] \"안녕하세요? 만나서 반가워요.\" <-> [10] \"你好\" : 0.8137\n",
      "[4] \"Hi, nice to meet you.\" <-> [5] \"I like to eat apples.\" : 0.7776\n",
      "[4] \"Hi, nice to meet you.\" <-> [6] \"아침 못먹었어요\" : 0.7306\n",
      "[4] \"Hi, nice to meet you.\" <-> [7] \"吃羊肉串的时候, 我超喜欢喝啤酒\" : 0.7330\n",
      "[4] \"Hi, nice to meet you.\" <-> [8] \"Abi in malam crucem!\" : 0.7395\n",
      "[4] \"Hi, nice to meet you.\" <-> [9] \"ちょっとまって\" : 0.7601\n",
      "[4] \"Hi, nice to meet you.\" <-> [10] \"你好\" : 0.8549\n",
      "[5] \"I like to eat apples.\" <-> [6] \"아침 못먹었어요\" : 0.7577\n",
      "[5] \"I like to eat apples.\" <-> [7] \"吃羊肉串的时候, 我超喜欢喝啤酒\" : 0.7972\n",
      "[5] \"I like to eat apples.\" <-> [8] \"Abi in malam crucem!\" : 0.7298\n",
      "[5] \"I like to eat apples.\" <-> [9] \"ちょっとまって\" : 0.7225\n",
      "[5] \"I like to eat apples.\" <-> [10] \"你好\" : 0.7476\n",
      "[6] \"아침 못먹었어요\" <-> [7] \"吃羊肉串的时候, 我超喜欢喝啤酒\" : 0.7420\n",
      "[6] \"아침 못먹었어요\" <-> [8] \"Abi in malam crucem!\" : 0.7305\n",
      "[6] \"아침 못먹었어요\" <-> [9] \"ちょっとまって\" : 0.7504\n",
      "[6] \"아침 못먹었어요\" <-> [10] \"你好\" : 0.7572\n",
      "[7] \"吃羊肉串的时候, 我超喜欢喝啤酒\" <-> [8] \"Abi in malam crucem!\" : 0.7498\n",
      "[7] \"吃羊肉串的时候, 我超喜欢喝啤酒\" <-> [9] \"ちょっとまって\" : 0.7555\n",
      "[7] \"吃羊肉串的时候, 我超喜欢喝啤酒\" <-> [10] \"你好\" : 0.7847\n",
      "[8] \"Abi in malam crucem!\" <-> [9] \"ちょっとまって\" : 0.7427\n",
      "[8] \"Abi in malam crucem!\" <-> [10] \"你好\" : 0.7450\n",
      "[9] \"ちょっとまって\" <-> [10] \"你好\" : 0.8053\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "#1. 임베딩 생성기 준비\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "#2. 문장 리스트\n",
    "sentences = [\n",
    "    \"안녕하세요? 반갑습니다.\",\n",
    "    \"안녕하세요? 반갑습니다!\",\n",
    "    \"안녕하세요? 만나서 반가워요.\",\n",
    "    \"Hi, nice to meet you.\",\n",
    "    \"I like to eat apples.\",\n",
    "    \"아침 못먹었어요\",\n",
    "    \"吃羊肉串的时候, 我超喜欢喝啤酒\",\n",
    "    \"Abi in malam crucem!\",\n",
    "    \"ちょっとまって\",\n",
    "    \"你好\"\n",
    "]\n",
    "\n",
    "#3. 각 문장을 임베딩 벡터로 변환\n",
    "sentence_vectors = [embeddings.embed_query(sentence) for sentence in sentences]\n",
    "\n",
    "#4. 코사인 유사도 함수 정의\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    vec1 = np.array(vec1)\n",
    "    vec2 = np.array(vec2)\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "#5. 모든 문장 쌍에 대해 코사인 유사도 계산 및 출력\n",
    "print(\"문장 쌍별 코사인 유사도:\")\n",
    "for (i, j) in combinations(range(len(sentences)), 2):\n",
    "    sim = cosine_similarity(sentence_vectors[i], sentence_vectors[j])\n",
    "    print(f\"[{i+1}] \\\"{sentences[i]}\\\" <-> [{j+1}] \\\"{sentences[j]}\\\" : {sim:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
